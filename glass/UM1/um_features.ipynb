{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features.shape: (25456, 84)\n",
      "train_labels.shape (25456, 1)\n",
      "test_features.shape: (5920, 84)\n",
      "test_labels.shape (5920, 1)\n"
     ]
    }
   ],
   "source": [
    "train_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\um\\\\um_train_features.npy')\n",
    "train_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\um\\\\um_train_labels.npy')\n",
    "train_features = np.squeeze(train_features)\n",
    "print(\"train_features.shape:\",train_features.shape)\n",
    "print(\"train_labels.shape\", train_labels.shape)\n",
    "\n",
    "test_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\um\\\\um_test_features.npy')\n",
    "test_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\um\\\\um_test_labels.npy')\n",
    "test_features = np.squeeze(test_features)\n",
    "print(\"test_features.shape:\",test_features.shape)\n",
    "print(\"test_labels.shape\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7923986486486486"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "classifier = svm.SVC()\n",
    "classifier.fit(train_features, train_labels)\n",
    "classifier.score(test_features,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_train.shape: (25456, 20)\n",
      "new_test.shape: (5920, 20)\n"
     ]
    }
   ],
   "source": [
    "#使用pca降维\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=20)\n",
    "pca_train = pca.fit_transform(train_features)\n",
    "pca_test = pca.fit_transform(test_features)\n",
    "print(\"new_train.shape:\", pca_train.shape)\n",
    "print(\"new_test.shape:\", pca_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7886824324324324"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "classifier = svm.SVC()\n",
    "classifier.fit(pca_train, train_labels)\n",
    "classifier.score(pca_test,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_new.shape: (25456, 12)\n",
      "test_new.shape: (5920, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58.87646484375, tolerance: 0.6363999843597412\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso           # 此处以L1正则化的线性模型Lasso为例\n",
    "lasso = Lasso(alpha=0.0005).fit(train_features, train_labels) \n",
    "model = SelectFromModel(lasso, prefit=True)\n",
    "\n",
    "train_new = model.transform(train_features)\n",
    "test_new = model.transform(test_features)\n",
    "\n",
    "print(\"train_new.shape:\", train_new.shape)\n",
    "print(\"test_new.shape:\", test_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.79375"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "classifier = svm.SVC()\n",
    "classifier.fit(train_new, train_labels)\n",
    "classifier.score(test_new,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "addfeatures_train = []\n",
    "addfeatures_test = []\n",
    "\n",
    "for i in range(86):\n",
    "    min_train = train_features[i*296:(i+1)*296]\n",
    "    addfeatures_train.append(min_train)\n",
    "    \n",
    "for i in range(20):\n",
    "    min_test = test_features[i*296:(i+1)*296]\n",
    "    addfeatures_test.append(min_test)\n",
    "    \n",
    "addfeatures_train = np.squeeze(np.array(addfeatures_train))\n",
    "#addfeatures_train = addfeatures_train.transpose(0,2,1)\n",
    "addfeatures_test = np.squeeze(np.array(addfeatures_test))\n",
    "#addfeatures_test = addfeatures_test.transpose(0,2,1)\n",
    "    \n",
    "addtrain_labels = np.array([0]*43+[1]*43)\n",
    "addtest_labels = np.array([0]*10+[1]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86 samples, validate on 20 samples\n",
      "Epoch 1/500\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.6942 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 2/500\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6926 - val_accuracy: 0.5000\n",
      "Epoch 3/500\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6924 - accuracy: 0.5116 - val_loss: 0.6917 - val_accuracy: 0.5000\n",
      "Epoch 4/500\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6915 - accuracy: 0.5233 - val_loss: 0.6916 - val_accuracy: 0.5500\n",
      "Epoch 5/500\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6913 - accuracy: 0.5814 - val_loss: 0.6917 - val_accuracy: 0.5000\n",
      "Epoch 6/500\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6921 - accuracy: 0.5465 - val_loss: 0.6916 - val_accuracy: 0.5000\n",
      "Epoch 7/500\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6914 - accuracy: 0.5349 - val_loss: 0.6916 - val_accuracy: 0.5000\n",
      "Epoch 8/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6919 - accuracy: 0.5233 - val_loss: 0.6915 - val_accuracy: 0.5500\n",
      "Epoch 9/500\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6924 - accuracy: 0.5233 - val_loss: 0.6915 - val_accuracy: 0.5500\n",
      "Epoch 10/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6906 - accuracy: 0.5814 - val_loss: 0.6915 - val_accuracy: 0.5500\n",
      "Epoch 11/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6930 - accuracy: 0.5000 - val_loss: 0.6915 - val_accuracy: 0.4500\n",
      "Epoch 12/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6905 - accuracy: 0.5349 - val_loss: 0.6914 - val_accuracy: 0.6000\n",
      "Epoch 13/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6903 - accuracy: 0.6047 - val_loss: 0.6914 - val_accuracy: 0.6500\n",
      "Epoch 14/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6906 - accuracy: 0.5698 - val_loss: 0.6914 - val_accuracy: 0.5000\n",
      "Epoch 15/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6914 - accuracy: 0.4884 - val_loss: 0.6914 - val_accuracy: 0.5000\n",
      "Epoch 16/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6924 - accuracy: 0.4884 - val_loss: 0.6914 - val_accuracy: 0.5500\n",
      "Epoch 17/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6902 - accuracy: 0.5581 - val_loss: 0.6913 - val_accuracy: 0.7500\n",
      "Epoch 18/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6900 - accuracy: 0.6047 - val_loss: 0.6913 - val_accuracy: 0.5500\n",
      "Epoch 19/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6903 - accuracy: 0.5465 - val_loss: 0.6912 - val_accuracy: 0.5500\n",
      "Epoch 20/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6900 - accuracy: 0.5465 - val_loss: 0.6912 - val_accuracy: 0.5500\n",
      "Epoch 21/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6908 - accuracy: 0.6047 - val_loss: 0.6911 - val_accuracy: 0.6500\n",
      "Epoch 22/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6899 - accuracy: 0.6163 - val_loss: 0.6911 - val_accuracy: 0.6500\n",
      "Epoch 23/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6897 - accuracy: 0.5814 - val_loss: 0.6910 - val_accuracy: 0.7000\n",
      "Epoch 24/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6902 - accuracy: 0.6163 - val_loss: 0.6910 - val_accuracy: 0.6500\n",
      "Epoch 25/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6924 - accuracy: 0.5814 - val_loss: 0.6910 - val_accuracy: 0.6000\n",
      "Epoch 26/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6898 - accuracy: 0.6279 - val_loss: 0.6909 - val_accuracy: 0.6500\n",
      "Epoch 27/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6912 - accuracy: 0.5698 - val_loss: 0.6909 - val_accuracy: 0.6000\n",
      "Epoch 28/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6893 - accuracy: 0.6279 - val_loss: 0.6908 - val_accuracy: 0.6500\n",
      "Epoch 29/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6896 - accuracy: 0.5465 - val_loss: 0.6907 - val_accuracy: 0.6500\n",
      "Epoch 30/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6893 - accuracy: 0.6047 - val_loss: 0.6907 - val_accuracy: 0.6000\n",
      "Epoch 31/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6889 - accuracy: 0.6047 - val_loss: 0.6906 - val_accuracy: 0.6000\n",
      "Epoch 32/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6899 - accuracy: 0.5233 - val_loss: 0.6906 - val_accuracy: 0.6500\n",
      "Epoch 33/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6887 - accuracy: 0.6163 - val_loss: 0.6905 - val_accuracy: 0.6000\n",
      "Epoch 34/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6942 - accuracy: 0.5116 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 35/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6896 - accuracy: 0.5233 - val_loss: 0.6904 - val_accuracy: 0.6000\n",
      "Epoch 36/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6914 - accuracy: 0.5233 - val_loss: 0.6903 - val_accuracy: 0.6500\n",
      "Epoch 37/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6893 - accuracy: 0.5698 - val_loss: 0.6904 - val_accuracy: 0.5500\n",
      "Epoch 38/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6884 - accuracy: 0.5814 - val_loss: 0.6902 - val_accuracy: 0.5500\n",
      "Epoch 39/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6881 - accuracy: 0.6047 - val_loss: 0.6902 - val_accuracy: 0.6500\n",
      "Epoch 40/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6909 - accuracy: 0.5465 - val_loss: 0.6902 - val_accuracy: 0.5500\n",
      "Epoch 41/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6880 - accuracy: 0.5698 - val_loss: 0.6900 - val_accuracy: 0.6500\n",
      "Epoch 42/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6881 - accuracy: 0.5349 - val_loss: 0.6899 - val_accuracy: 0.5500\n",
      "Epoch 43/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6877 - accuracy: 0.5814 - val_loss: 0.6898 - val_accuracy: 0.6500\n",
      "Epoch 44/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6877 - accuracy: 0.6512 - val_loss: 0.6897 - val_accuracy: 0.7000\n",
      "Epoch 45/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6874 - accuracy: 0.6047 - val_loss: 0.6896 - val_accuracy: 0.6500\n",
      "Epoch 46/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6888 - accuracy: 0.5814 - val_loss: 0.6895 - val_accuracy: 0.7000\n",
      "Epoch 47/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6887 - accuracy: 0.5349 - val_loss: 0.6894 - val_accuracy: 0.7000\n",
      "Epoch 48/500\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.6876 - accuracy: 0.6163 - val_loss: 0.6893 - val_accuracy: 0.6000\n",
      "Epoch 49/500\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.6867 - accuracy: 0.6279 - val_loss: 0.6891 - val_accuracy: 0.6500\n",
      "Epoch 50/500\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.6905 - accuracy: 0.5465 - val_loss: 0.6894 - val_accuracy: 0.5500\n",
      "Epoch 51/500\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.6870 - accuracy: 0.5930 - val_loss: 0.6889 - val_accuracy: 0.6500\n",
      "Epoch 52/500\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.6869 - accuracy: 0.6279 - val_loss: 0.6887 - val_accuracy: 0.6000\n",
      "Epoch 53/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6865 - accuracy: 0.6163 - val_loss: 0.6886 - val_accuracy: 0.5500\n",
      "Epoch 54/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6858 - accuracy: 0.6047 - val_loss: 0.6884 - val_accuracy: 0.7000\n",
      "Epoch 55/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6857 - accuracy: 0.6047 - val_loss: 0.6882 - val_accuracy: 0.6500\n",
      "Epoch 56/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6911 - accuracy: 0.5233 - val_loss: 0.6880 - val_accuracy: 0.6000\n",
      "Epoch 57/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6869 - accuracy: 0.5930 - val_loss: 0.6878 - val_accuracy: 0.7000\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6906 - accuracy: 0.5233 - val_loss: 0.6878 - val_accuracy: 0.5500\n",
      "Epoch 59/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6890 - accuracy: 0.5116 - val_loss: 0.6875 - val_accuracy: 0.6500\n",
      "Epoch 60/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6848 - accuracy: 0.6047 - val_loss: 0.6879 - val_accuracy: 0.5500\n",
      "Epoch 61/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6848 - accuracy: 0.6279 - val_loss: 0.6871 - val_accuracy: 0.6500\n",
      "Epoch 62/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6845 - accuracy: 0.5814 - val_loss: 0.6871 - val_accuracy: 0.7000\n",
      "Epoch 63/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6945 - accuracy: 0.5116 - val_loss: 0.6868 - val_accuracy: 0.7000\n",
      "Epoch 64/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6837 - accuracy: 0.6395 - val_loss: 0.6870 - val_accuracy: 0.6000\n",
      "Epoch 65/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6854 - accuracy: 0.5814 - val_loss: 0.6879 - val_accuracy: 0.5500\n",
      "Epoch 66/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6859 - accuracy: 0.5465 - val_loss: 0.6870 - val_accuracy: 0.5500\n",
      "Epoch 67/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6838 - accuracy: 0.5698 - val_loss: 0.6858 - val_accuracy: 0.7000\n",
      "Epoch 68/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6827 - accuracy: 0.6163 - val_loss: 0.6855 - val_accuracy: 0.7000\n",
      "Epoch 69/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6840 - accuracy: 0.5581 - val_loss: 0.6857 - val_accuracy: 0.6000\n",
      "Epoch 70/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6911 - accuracy: 0.5581 - val_loss: 0.6848 - val_accuracy: 0.6500\n",
      "Epoch 71/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6819 - accuracy: 0.6628 - val_loss: 0.6845 - val_accuracy: 0.7000\n",
      "Epoch 72/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6837 - accuracy: 0.5465 - val_loss: 0.6866 - val_accuracy: 0.4500\n",
      "Epoch 73/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7020 - accuracy: 0.4419 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
      "Epoch 74/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6893 - val_accuracy: 0.5000\n",
      "Epoch 75/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6864 - accuracy: 0.5349 - val_loss: 0.6969 - val_accuracy: 0.5000\n",
      "Epoch 76/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6974 - accuracy: 0.5000 - val_loss: 0.6974 - val_accuracy: 0.5000\n",
      "Epoch 77/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6974 - accuracy: 0.5000 - val_loss: 0.6967 - val_accuracy: 0.5000\n",
      "Epoch 78/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6980 - accuracy: 0.5000 - val_loss: 0.6957 - val_accuracy: 0.5000\n",
      "Epoch 79/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6956 - accuracy: 0.5000 - val_loss: 0.6950 - val_accuracy: 0.5000\n",
      "Epoch 80/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6949 - accuracy: 0.5000 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
      "Epoch 81/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6947 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 82/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
      "Epoch 83/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6939 - accuracy: 0.5000 - val_loss: 0.6924 - val_accuracy: 0.5000\n",
      "Epoch 84/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6929 - accuracy: 0.5000 - val_loss: 0.6923 - val_accuracy: 0.5000\n",
      "Epoch 85/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6922 - val_accuracy: 0.5500\n",
      "Epoch 86/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6923 - accuracy: 0.5581 - val_loss: 0.6922 - val_accuracy: 0.5500\n",
      "Epoch 87/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6922 - accuracy: 0.5465 - val_loss: 0.6923 - val_accuracy: 0.5000\n",
      "Epoch 88/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6924 - accuracy: 0.5000 - val_loss: 0.6923 - val_accuracy: 0.5000\n",
      "Epoch 89/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6924 - accuracy: 0.5116 - val_loss: 0.6923 - val_accuracy: 0.4500\n",
      "Epoch 90/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6923 - accuracy: 0.5233 - val_loss: 0.6923 - val_accuracy: 0.5000\n",
      "Epoch 91/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6925 - accuracy: 0.4884 - val_loss: 0.6923 - val_accuracy: 0.4500\n",
      "Epoch 92/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6932 - accuracy: 0.5116 - val_loss: 0.6923 - val_accuracy: 0.4500\n",
      "Epoch 93/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6924 - accuracy: 0.5000 - val_loss: 0.6923 - val_accuracy: 0.5000\n",
      "Epoch 94/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6922 - val_accuracy: 0.5000\n",
      "Epoch 95/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6922 - accuracy: 0.5116 - val_loss: 0.6922 - val_accuracy: 0.5500\n",
      "Epoch 96/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6924 - accuracy: 0.5116 - val_loss: 0.6921 - val_accuracy: 0.5500\n",
      "Epoch 97/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6926 - accuracy: 0.5000 - val_loss: 0.6921 - val_accuracy: 0.5500\n",
      "Epoch 98/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6928 - accuracy: 0.5000 - val_loss: 0.6921 - val_accuracy: 0.5500\n",
      "Epoch 99/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6921 - accuracy: 0.4767 - val_loss: 0.6921 - val_accuracy: 0.5500\n",
      "Epoch 100/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6920 - accuracy: 0.5465 - val_loss: 0.6921 - val_accuracy: 0.6000\n",
      "Epoch 101/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6921 - accuracy: 0.5465 - val_loss: 0.6921 - val_accuracy: 0.6000\n",
      "Epoch 102/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6922 - accuracy: 0.5349 - val_loss: 0.6921 - val_accuracy: 0.6000\n",
      "Epoch 103/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6921 - accuracy: 0.5698 - val_loss: 0.6921 - val_accuracy: 0.6000\n",
      "Epoch 104/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6920 - accuracy: 0.5349 - val_loss: 0.6921 - val_accuracy: 0.6000\n",
      "Epoch 105/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6921 - accuracy: 0.5000 - val_loss: 0.6920 - val_accuracy: 0.5500\n",
      "Epoch 106/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6920 - accuracy: 0.5000 - val_loss: 0.6920 - val_accuracy: 0.5500\n",
      "Epoch 107/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6921 - accuracy: 0.5465 - val_loss: 0.6920 - val_accuracy: 0.6000\n",
      "Epoch 108/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6920 - val_accuracy: 0.5500\n",
      "Epoch 109/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6923 - accuracy: 0.5233 - val_loss: 0.6920 - val_accuracy: 0.5000\n",
      "Epoch 110/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6923 - accuracy: 0.5000 - val_loss: 0.6920 - val_accuracy: 0.5000\n",
      "Epoch 111/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6919 - accuracy: 0.5000 - val_loss: 0.6920 - val_accuracy: 0.5000\n",
      "Epoch 112/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6923 - accuracy: 0.5000 - val_loss: 0.6920 - val_accuracy: 0.5500\n",
      "Epoch 113/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6919 - accuracy: 0.5233 - val_loss: 0.6920 - val_accuracy: 0.5500\n",
      "Epoch 114/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6919 - accuracy: 0.5233 - val_loss: 0.6920 - val_accuracy: 0.5500\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6919 - accuracy: 0.5116 - val_loss: 0.6920 - val_accuracy: 0.5000\n",
      "Epoch 116/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6919 - accuracy: 0.5349 - val_loss: 0.6919 - val_accuracy: 0.5000\n",
      "Epoch 117/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6920 - accuracy: 0.5116 - val_loss: 0.6919 - val_accuracy: 0.5500\n",
      "Epoch 118/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6919 - accuracy: 0.5349 - val_loss: 0.6919 - val_accuracy: 0.5000\n",
      "Epoch 119/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6918 - accuracy: 0.5465 - val_loss: 0.6919 - val_accuracy: 0.5000\n",
      "Epoch 120/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6918 - accuracy: 0.5349 - val_loss: 0.6919 - val_accuracy: 0.5500\n",
      "Epoch 121/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6918 - accuracy: 0.5349 - val_loss: 0.6919 - val_accuracy: 0.5500\n",
      "Epoch 122/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6918 - accuracy: 0.5349 - val_loss: 0.6919 - val_accuracy: 0.5500\n",
      "Epoch 123/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6918 - accuracy: 0.5349 - val_loss: 0.6919 - val_accuracy: 0.5500\n",
      "Epoch 124/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6921 - accuracy: 0.4884 - val_loss: 0.6919 - val_accuracy: 0.5500\n",
      "Epoch 125/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6923 - accuracy: 0.5000 - val_loss: 0.6919 - val_accuracy: 0.6000\n",
      "Epoch 126/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6923 - accuracy: 0.4884 - val_loss: 0.6919 - val_accuracy: 0.6000\n",
      "Epoch 127/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6924 - accuracy: 0.5116 - val_loss: 0.6918 - val_accuracy: 0.5000\n",
      "Epoch 128/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6917 - accuracy: 0.5465 - val_loss: 0.6918 - val_accuracy: 0.5500\n",
      "Epoch 129/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6917 - accuracy: 0.5349 - val_loss: 0.6918 - val_accuracy: 0.5500\n",
      "Epoch 130/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6918 - accuracy: 0.5116 - val_loss: 0.6918 - val_accuracy: 0.5000\n",
      "Epoch 131/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6918 - accuracy: 0.4884 - val_loss: 0.6918 - val_accuracy: 0.5000\n",
      "Epoch 132/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6920 - accuracy: 0.4884 - val_loss: 0.6918 - val_accuracy: 0.5000\n",
      "Epoch 133/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6920 - accuracy: 0.5465 - val_loss: 0.6918 - val_accuracy: 0.5500\n",
      "Epoch 134/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6916 - accuracy: 0.5116 - val_loss: 0.6918 - val_accuracy: 0.5500\n",
      "Epoch 135/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6916 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5500\n",
      "Epoch 136/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6917 - accuracy: 0.5465 - val_loss: 0.6918 - val_accuracy: 0.5500\n",
      "Epoch 137/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6916 - accuracy: 0.5349 - val_loss: 0.6918 - val_accuracy: 0.5500\n",
      "Epoch 138/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6919 - accuracy: 0.5116 - val_loss: 0.6917 - val_accuracy: 0.5000\n",
      "Epoch 139/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6920 - accuracy: 0.5465 - val_loss: 0.6917 - val_accuracy: 0.5500\n",
      "Epoch 140/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6916 - accuracy: 0.5465 - val_loss: 0.6917 - val_accuracy: 0.5500\n",
      "Epoch 141/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6916 - accuracy: 0.5233 - val_loss: 0.6917 - val_accuracy: 0.5500\n",
      "Epoch 142/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6916 - accuracy: 0.5233 - val_loss: 0.6917 - val_accuracy: 0.5500\n",
      "Epoch 143/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6922 - accuracy: 0.5000 - val_loss: 0.6917 - val_accuracy: 0.5500\n",
      "Epoch 144/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6915 - accuracy: 0.5349 - val_loss: 0.6917 - val_accuracy: 0.5500\n",
      "Epoch 145/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6914 - accuracy: 0.5233 - val_loss: 0.6917 - val_accuracy: 0.5500\n",
      "Epoch 146/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6919 - accuracy: 0.5000 - val_loss: 0.6916 - val_accuracy: 0.5500\n",
      "Epoch 147/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6914 - accuracy: 0.5116 - val_loss: 0.6916 - val_accuracy: 0.5000\n",
      "Epoch 148/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6916 - val_accuracy: 0.5500\n",
      "Epoch 149/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6914 - accuracy: 0.5465 - val_loss: 0.6916 - val_accuracy: 0.5500\n",
      "Epoch 150/500\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.6913 - accuracy: 0.5116 - val_loss: 0.6916 - val_accuracy: 0.5000\n",
      "Epoch 151/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6913 - accuracy: 0.5233 - val_loss: 0.6916 - val_accuracy: 0.5500\n",
      "Epoch 152/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6913 - accuracy: 0.5349 - val_loss: 0.6916 - val_accuracy: 0.5000\n",
      "Epoch 153/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6921 - accuracy: 0.4884 - val_loss: 0.6916 - val_accuracy: 0.5500\n",
      "Epoch 154/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6913 - accuracy: 0.5349 - val_loss: 0.6916 - val_accuracy: 0.6000\n",
      "Epoch 155/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6913 - accuracy: 0.5349 - val_loss: 0.6915 - val_accuracy: 0.6000\n",
      "Epoch 156/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6914 - accuracy: 0.5116 - val_loss: 0.6915 - val_accuracy: 0.6000\n",
      "Epoch 157/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6913 - accuracy: 0.5581 - val_loss: 0.6915 - val_accuracy: 0.5500\n",
      "Epoch 158/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6911 - accuracy: 0.5349 - val_loss: 0.6915 - val_accuracy: 0.6000\n",
      "Epoch 159/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6911 - accuracy: 0.5465 - val_loss: 0.6914 - val_accuracy: 0.5500\n",
      "Epoch 160/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6911 - accuracy: 0.5581 - val_loss: 0.6914 - val_accuracy: 0.5000\n",
      "Epoch 161/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6910 - accuracy: 0.5581 - val_loss: 0.6914 - val_accuracy: 0.5500\n",
      "Epoch 162/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6910 - accuracy: 0.5465 - val_loss: 0.6914 - val_accuracy: 0.5000\n",
      "Epoch 163/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6908 - accuracy: 0.5581 - val_loss: 0.6914 - val_accuracy: 0.5000\n",
      "Epoch 164/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6908 - accuracy: 0.5581 - val_loss: 0.6914 - val_accuracy: 0.6000\n",
      "Epoch 165/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6908 - accuracy: 0.5581 - val_loss: 0.6913 - val_accuracy: 0.5500\n",
      "Epoch 166/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6908 - accuracy: 0.5465 - val_loss: 0.6913 - val_accuracy: 0.5500\n",
      "Epoch 167/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6908 - accuracy: 0.5465 - val_loss: 0.6913 - val_accuracy: 0.5500\n",
      "Epoch 168/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6909 - accuracy: 0.5233 - val_loss: 0.6913 - val_accuracy: 0.5000\n",
      "Epoch 169/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6909 - accuracy: 0.5581 - val_loss: 0.6913 - val_accuracy: 0.5500\n",
      "Epoch 170/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6906 - accuracy: 0.5698 - val_loss: 0.6913 - val_accuracy: 0.5000\n",
      "Epoch 171/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6909 - accuracy: 0.5233 - val_loss: 0.6913 - val_accuracy: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6912 - accuracy: 0.4767 - val_loss: 0.6912 - val_accuracy: 0.5500\n",
      "Epoch 173/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6906 - accuracy: 0.5349 - val_loss: 0.6912 - val_accuracy: 0.5000\n",
      "Epoch 174/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6905 - accuracy: 0.5233 - val_loss: 0.6912 - val_accuracy: 0.5500\n",
      "Epoch 175/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6904 - accuracy: 0.5465 - val_loss: 0.6912 - val_accuracy: 0.5000\n",
      "Epoch 176/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6912 - accuracy: 0.5000 - val_loss: 0.6912 - val_accuracy: 0.5500\n",
      "Epoch 177/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6905 - accuracy: 0.5233 - val_loss: 0.6912 - val_accuracy: 0.5500\n",
      "Epoch 178/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6905 - accuracy: 0.5349 - val_loss: 0.6912 - val_accuracy: 0.5000\n",
      "Epoch 179/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6905 - accuracy: 0.5581 - val_loss: 0.6912 - val_accuracy: 0.5000\n",
      "Epoch 180/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6904 - accuracy: 0.5581 - val_loss: 0.6912 - val_accuracy: 0.5000\n",
      "Epoch 181/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6903 - accuracy: 0.5698 - val_loss: 0.6912 - val_accuracy: 0.5000\n",
      "Epoch 182/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6904 - accuracy: 0.5581 - val_loss: 0.6912 - val_accuracy: 0.5500\n",
      "Epoch 183/500\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.6904 - accuracy: 0.5465 - val_loss: 0.6912 - val_accuracy: 0.5500\n",
      "Epoch 184/500\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.6906 - accuracy: 0.5698 - val_loss: 0.6912 - val_accuracy: 0.5500\n",
      "Epoch 185/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6909 - accuracy: 0.5930 - val_loss: 0.6912 - val_accuracy: 0.5500\n",
      "Epoch 186/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6901 - accuracy: 0.5581 - val_loss: 0.6911 - val_accuracy: 0.5000\n",
      "Epoch 187/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6901 - accuracy: 0.5349 - val_loss: 0.6911 - val_accuracy: 0.5000\n",
      "Epoch 188/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6910 - accuracy: 0.5233 - val_loss: 0.6912 - val_accuracy: 0.6000\n",
      "Epoch 189/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6900 - accuracy: 0.5465 - val_loss: 0.6911 - val_accuracy: 0.6000\n",
      "Epoch 190/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6902 - accuracy: 0.5233 - val_loss: 0.6911 - val_accuracy: 0.6000\n",
      "Epoch 191/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6901 - accuracy: 0.5349 - val_loss: 0.6911 - val_accuracy: 0.5500\n",
      "Epoch 192/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6908 - accuracy: 0.5233 - val_loss: 0.6911 - val_accuracy: 0.5500\n",
      "Epoch 193/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6906 - accuracy: 0.5581 - val_loss: 0.6911 - val_accuracy: 0.5000\n",
      "Epoch 194/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6898 - accuracy: 0.5698 - val_loss: 0.6911 - val_accuracy: 0.5500\n",
      "Epoch 195/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6898 - accuracy: 0.5698 - val_loss: 0.6911 - val_accuracy: 0.5500\n",
      "Epoch 196/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6900 - accuracy: 0.5581 - val_loss: 0.6911 - val_accuracy: 0.5500\n",
      "Epoch 197/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6902 - accuracy: 0.5465 - val_loss: 0.6911 - val_accuracy: 0.5500\n",
      "Epoch 198/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6899 - accuracy: 0.5465 - val_loss: 0.6911 - val_accuracy: 0.5000\n",
      "Epoch 199/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6897 - accuracy: 0.5698 - val_loss: 0.6911 - val_accuracy: 0.5000\n",
      "Epoch 200/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6898 - accuracy: 0.5581 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 201/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6896 - accuracy: 0.5581 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 202/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6898 - accuracy: 0.5465 - val_loss: 0.6911 - val_accuracy: 0.5500\n",
      "Epoch 203/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6897 - accuracy: 0.5233 - val_loss: 0.6910 - val_accuracy: 0.5500\n",
      "Epoch 204/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6900 - accuracy: 0.5233 - val_loss: 0.6911 - val_accuracy: 0.6000\n",
      "Epoch 205/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6897 - accuracy: 0.5465 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 206/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6894 - accuracy: 0.5581 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 207/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6894 - accuracy: 0.6047 - val_loss: 0.6910 - val_accuracy: 0.4500\n",
      "Epoch 208/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6893 - accuracy: 0.5930 - val_loss: 0.6910 - val_accuracy: 0.4500\n",
      "Epoch 209/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6899 - accuracy: 0.5581 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 210/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6894 - accuracy: 0.5581 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 211/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6892 - accuracy: 0.5814 - val_loss: 0.6910 - val_accuracy: 0.4500\n",
      "Epoch 212/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6905 - accuracy: 0.5581 - val_loss: 0.6910 - val_accuracy: 0.5500\n",
      "Epoch 213/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6893 - accuracy: 0.5698 - val_loss: 0.6910 - val_accuracy: 0.4500\n",
      "Epoch 214/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6905 - accuracy: 0.5233 - val_loss: 0.6910 - val_accuracy: 0.5500\n",
      "Epoch 215/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6903 - accuracy: 0.5116 - val_loss: 0.6910 - val_accuracy: 0.5500\n",
      "Epoch 216/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6894 - accuracy: 0.5349 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 217/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6918 - accuracy: 0.5349 - val_loss: 0.6910 - val_accuracy: 0.5500\n",
      "Epoch 218/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6933 - accuracy: 0.4767 - val_loss: 0.6911 - val_accuracy: 0.5500\n",
      "Epoch 219/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6914 - accuracy: 0.5465 - val_loss: 0.6912 - val_accuracy: 0.5500\n",
      "Epoch 220/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6890 - accuracy: 0.5465 - val_loss: 0.6911 - val_accuracy: 0.6000\n",
      "Epoch 221/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6897 - accuracy: 0.5465 - val_loss: 0.6910 - val_accuracy: 0.4500\n",
      "Epoch 222/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6897 - accuracy: 0.5581 - val_loss: 0.6910 - val_accuracy: 0.4500\n",
      "Epoch 223/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6885 - accuracy: 0.5581 - val_loss: 0.6910 - val_accuracy: 0.5500\n",
      "Epoch 224/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6885 - accuracy: 0.5581 - val_loss: 0.6910 - val_accuracy: 0.5500\n",
      "Epoch 225/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6892 - accuracy: 0.5698 - val_loss: 0.6910 - val_accuracy: 0.5500\n",
      "Epoch 226/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6893 - accuracy: 0.5581 - val_loss: 0.6911 - val_accuracy: 0.6000\n",
      "Epoch 227/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6893 - accuracy: 0.5698 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 228/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6885 - accuracy: 0.5698 - val_loss: 0.6910 - val_accuracy: 0.4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6911 - accuracy: 0.5116 - val_loss: 0.6910 - val_accuracy: 0.6000\n",
      "Epoch 230/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6882 - accuracy: 0.5814 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 231/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6881 - accuracy: 0.5698 - val_loss: 0.6910 - val_accuracy: 0.4500\n",
      "Epoch 232/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6880 - accuracy: 0.6047 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 233/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6897 - accuracy: 0.5465 - val_loss: 0.6910 - val_accuracy: 0.5500\n",
      "Epoch 234/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6900 - accuracy: 0.5116 - val_loss: 0.6910 - val_accuracy: 0.4500\n",
      "Epoch 235/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6878 - accuracy: 0.5930 - val_loss: 0.6910 - val_accuracy: 0.4500\n",
      "Epoch 236/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6877 - accuracy: 0.5814 - val_loss: 0.6910 - val_accuracy: 0.4500\n",
      "Epoch 237/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6876 - accuracy: 0.5930 - val_loss: 0.6910 - val_accuracy: 0.4500\n",
      "Epoch 238/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6876 - accuracy: 0.5930 - val_loss: 0.6910 - val_accuracy: 0.4500\n",
      "Epoch 239/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6948 - accuracy: 0.5116 - val_loss: 0.6910 - val_accuracy: 0.6000\n",
      "Epoch 240/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6875 - accuracy: 0.5698 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 241/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6879 - accuracy: 0.5930 - val_loss: 0.6911 - val_accuracy: 0.5500\n",
      "Epoch 242/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6877 - accuracy: 0.5930 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 243/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6879 - accuracy: 0.5698 - val_loss: 0.6910 - val_accuracy: 0.5500\n",
      "Epoch 244/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6883 - accuracy: 0.5581 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 245/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6874 - accuracy: 0.5581 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 246/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6871 - accuracy: 0.5698 - val_loss: 0.6910 - val_accuracy: 0.4500\n",
      "Epoch 247/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6869 - accuracy: 0.5814 - val_loss: 0.6910 - val_accuracy: 0.5500\n",
      "Epoch 248/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6868 - accuracy: 0.6047 - val_loss: 0.6910 - val_accuracy: 0.5500\n",
      "Epoch 249/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6865 - accuracy: 0.6047 - val_loss: 0.6910 - val_accuracy: 0.4500\n",
      "Epoch 250/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6891 - accuracy: 0.5581 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 251/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6869 - accuracy: 0.5116 - val_loss: 0.6910 - val_accuracy: 0.6000\n",
      "Epoch 252/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6889 - accuracy: 0.5349 - val_loss: 0.6910 - val_accuracy: 0.6000\n",
      "Epoch 253/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6864 - accuracy: 0.5698 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 254/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6921 - accuracy: 0.5349 - val_loss: 0.6914 - val_accuracy: 0.5500\n",
      "Epoch 255/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6861 - accuracy: 0.5581 - val_loss: 0.6909 - val_accuracy: 0.5000\n",
      "Epoch 256/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6859 - accuracy: 0.6047 - val_loss: 0.6910 - val_accuracy: 0.6000\n",
      "Epoch 257/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6918 - accuracy: 0.4884 - val_loss: 0.6914 - val_accuracy: 0.6000\n",
      "Epoch 258/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6888 - accuracy: 0.5349 - val_loss: 0.6909 - val_accuracy: 0.6000\n",
      "Epoch 259/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6924 - accuracy: 0.5116 - val_loss: 0.6915 - val_accuracy: 0.5500\n",
      "Epoch 260/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6862 - accuracy: 0.5581 - val_loss: 0.6911 - val_accuracy: 0.6000\n",
      "Epoch 261/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6926 - accuracy: 0.5233 - val_loss: 0.6908 - val_accuracy: 0.5000\n",
      "Epoch 262/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6868 - accuracy: 0.5465 - val_loss: 0.6909 - val_accuracy: 0.5000\n",
      "Epoch 263/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6853 - accuracy: 0.5930 - val_loss: 0.6908 - val_accuracy: 0.5000\n",
      "Epoch 264/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6891 - accuracy: 0.5698 - val_loss: 0.6908 - val_accuracy: 0.6000\n",
      "Epoch 265/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6848 - accuracy: 0.5465 - val_loss: 0.6909 - val_accuracy: 0.5000\n",
      "Epoch 266/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6916 - accuracy: 0.5698 - val_loss: 0.6914 - val_accuracy: 0.5500\n",
      "Epoch 267/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6879 - accuracy: 0.5116 - val_loss: 0.6908 - val_accuracy: 0.5000\n",
      "Epoch 268/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6873 - accuracy: 0.5465 - val_loss: 0.6907 - val_accuracy: 0.5000\n",
      "Epoch 269/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6877 - accuracy: 0.5581 - val_loss: 0.6909 - val_accuracy: 0.5500\n",
      "Epoch 270/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6912 - accuracy: 0.5814 - val_loss: 0.6911 - val_accuracy: 0.5500\n",
      "Epoch 271/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6839 - accuracy: 0.6047 - val_loss: 0.6907 - val_accuracy: 0.6000\n",
      "Epoch 272/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6841 - accuracy: 0.5930 - val_loss: 0.6907 - val_accuracy: 0.6000\n",
      "Epoch 273/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6866 - accuracy: 0.5116 - val_loss: 0.6907 - val_accuracy: 0.6000\n",
      "Epoch 274/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6859 - accuracy: 0.5116 - val_loss: 0.6905 - val_accuracy: 0.5500\n",
      "Epoch 275/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6860 - accuracy: 0.5349 - val_loss: 0.6908 - val_accuracy: 0.6000\n",
      "Epoch 276/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6895 - accuracy: 0.5233 - val_loss: 0.6906 - val_accuracy: 0.5000\n",
      "Epoch 277/500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6886 - accuracy: 0.5581 - val_loss: 0.6903 - val_accuracy: 0.6000\n",
      "Epoch 278/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-164-3546b2232ae8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m his = model.fit(x=addfeatures_train, y=addtrain_labels,batch_size=43, epochs=500,shuffle=True, verbose=1, \n\u001b[1;32m---> 24\u001b[1;33m                validation_data=(addfeatures_test,addtest_labels))\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "data_dim = 84\n",
    "timesteps = 296\n",
    "num_classes = 1\n",
    "\n",
    "# 期望输入数据尺寸: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(84, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # 返回维度为 32 的向量序列\n",
    "model.add(LSTM(42, return_sequences=True))  # 返回维度为 32 的向量序列\n",
    "model.add(LSTM(21))  # 返回维度为 32 的单个向量\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "his = model.fit(x=addfeatures_train, y=addtrain_labels,batch_size=43, epochs=500,shuffle=True, verbose=1, \n",
    "               validation_data=(addfeatures_test,addtest_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from nilearn.connectome import sym_matrix_to_vec\n",
    "\n",
    "conn_est = ConnectivityMeasure(kind = 'covariance')\n",
    "addfeatures_train = conn_est.fit_transform(addfeatures_train)\n",
    "addfeatures_train = sym_matrix_to_vec(addfeatures_train)\n",
    "\n",
    "addfeatures_test = conn_est.fit_transform(addfeatures_test)\n",
    "addfeatures_test = sym_matrix_to_vec(addfeatures_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 3570)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addfeatures_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from nilearn.connectome import sym_matrix_to_vec\n",
    "\n",
    "conn_est = ConnectivityMeasure(kind = 'covariance')\n",
    "addfeatures_train = conn_est.fit_transform(addfeatures_train)\n",
    "addfeatures_train = sym_matrix_to_vec(addfeatures_train)\n",
    "\n",
    "addfeatures_test = conn_est.fit_transform(addfeatures_test)\n",
    "addfeatures_test = sym_matrix_to_vec(addfeatures_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 43956)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addfeatures_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_new.shape: (86, 101)\n",
      "test_new.shape: (20, 101)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0028285631472965292, tolerance: 0.00215\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso           # 此处以L1正则化的线性模型Lasso为例\n",
    "lasso = Lasso(alpha=0.0001).fit(addfeatures_train, addtrain_labels) \n",
    "model = SelectFromModel(lasso, prefit=True)\n",
    "\n",
    "train_new = model.transform(addfeatures_train)\n",
    "test_new = model.transform(addfeatures_test)\n",
    "\n",
    "print(\"train_new.shape:\", train_new.shape)\n",
    "print(\"test_new.shape:\", test_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "classifier = svm.SVC( )\n",
    "classifier.fit(train_new, addtrain_labels)\n",
    "classifier.score(test_new,addtest_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisherscore(data, labels, num):\n",
    "\n",
    "    high = len(data)  # 向量个数\n",
    "    weight = len(data[0])  # 向量长度\n",
    "    P_num = np.sum(labels == 0)  # 正样本\n",
    "    N_num = np.sum(labels == 1)  # 负样本\n",
    "\n",
    "    # 计算Fisher score\n",
    "\n",
    "    fisherscore = []\n",
    "    for i in range(weight):\n",
    "        p = []\n",
    "        n = []\n",
    "        p_var = []\n",
    "        n_var = []\n",
    "        for j in range(high):\n",
    "            if labels[j] == 0:\n",
    "                p.append(data[j, i])\n",
    "            if labels[j] == 1:\n",
    "                n.append(data[j, i])\n",
    "\n",
    "        p_average = np.sum(p) / len(p)\n",
    "        n_average = np.sum(n) / len(n)\n",
    "        average = (np.sum(p) + np.sum(n)) / (len(p) + len(n))\n",
    "\n",
    "        for j in range(high):\n",
    "            if labels[j] == 0:\n",
    "                p_var.append((data[j, i] - p_average) ** 2)\n",
    "            if labels[j] == 1:\n",
    "                n_var.append((data[j, i] - n_average) ** 2)\n",
    "\n",
    "        score = ((p_average - average) ** 2 + (n_average - average) ** 2) / (\n",
    "                    np.sum(p_var) / len(p) + np.sum(n_var) / len(n))\n",
    "\n",
    "        fisherscore.append(score)\n",
    "\n",
    "    index = np.argsort(-np.array(fisherscore))  # 返回索引\n",
    "    new_data = []\n",
    "    for i in range(num):\n",
    "        new_data.append(data[:, index[i]])\n",
    "\n",
    "    new_data = np.array(new_data)\n",
    "    new_data = new_data.transpose(1, 0)\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_train = fisherscore(addfeatures_train, addtrain_labels, 2)\n",
    "fisher_test = fisherscore(addfeatures_test, addtest_labels, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "classifier = svm.LinearSVC()\n",
    "classifier.fit(fisher_train, addtrain_labels)\n",
    "classifier.score(fisher_test,addtest_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x171cc2cd788>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(fisher_train[:, 0], fisher_train[:, 1], c=addtrain_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x171d9cc0088>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(fisher_test[:, 0], fisher_test[:, 1], c=addtest_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
