{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisherscore(data, labels, num):\n",
    "\n",
    "    high = len(data)  # 向量个数\n",
    "    weight = len(data[0])  # 向量长度\n",
    "    P_num = np.sum(labels == 0)  # 正样本\n",
    "    N_num = np.sum(labels == 1)  # 负样本\n",
    "\n",
    "    # 计算Fisher score\n",
    "\n",
    "    fisherscore = []\n",
    "    for i in range(weight):\n",
    "        p = []\n",
    "        n = []\n",
    "        p_var = []\n",
    "        n_var = []\n",
    "        for j in range(high):\n",
    "            if labels[j] == 0:\n",
    "                p.append(data[j, i])\n",
    "            if labels[j] == 1:\n",
    "                n.append(data[j, i])\n",
    "\n",
    "        p_average = np.sum(p) / len(p)\n",
    "        n_average = np.sum(n) / len(n)\n",
    "        average = (np.sum(p) + np.sum(n)) / (len(p) + len(n))\n",
    "\n",
    "        for j in range(high):\n",
    "            if labels[j] == 0:\n",
    "                p_var.append((data[j, i] - p_average) ** 2)\n",
    "            if labels[j] == 1:\n",
    "                n_var.append((data[j, i] - n_average) ** 2)\n",
    "\n",
    "        score = ((p_average - average) ** 2 + (n_average - average) ** 2) / (\n",
    "                    np.sum(p_var) / len(p) + np.sum(n_var) / len(n))\n",
    "\n",
    "        fisherscore.append(score)\n",
    "\n",
    "    index = np.argsort(-np.array(fisherscore))  # 返回索引\n",
    "    new_data = []\n",
    "    for i in range(num):\n",
    "        new_data.append(data[:, index[i]])\n",
    "\n",
    "    new_data = np.array(new_data)\n",
    "    new_data = new_data.transpose(1, 0)\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caltech: (30, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:33: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caltech: (7, 2000)\n",
      "leuven: (52, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leuven: (11, 2000)\n",
      "nyu: (139, 2000)\n",
      "nyu: (35, 2000)\n",
      "ohsu: (22, 2000)\n",
      "ohsu: (4, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olin: (28, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olin: (6, 2000)\n",
      "pitt: (46, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pitt: (10, 2000)\n",
      "sbl: (24, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbl: (5, 2000)\n",
      "sdsu: (30, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdsu: (6, 2000)\n",
      "um: (86, 2000)\n",
      "um: (20, 2000)\n",
      "usm: (57, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:33: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usm: (14, 2000)\n",
      "train_data: (514, 2000)\n",
      "train_label: (514,)\n",
      "test_data: (118, 2000)\n",
      "test_label: (118,)\n",
      "data (632, 2000)\n",
      "label (632,)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from nilearn.connectome import sym_matrix_to_vec\n",
    "\n",
    "\n",
    "'''\n",
    "加载提取出来的特征数据集\n",
    "'''\n",
    "\n",
    "'''\n",
    "加载caltech数据\n",
    "'''\n",
    "caltech_train_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\caltech\\\\caltech_train_features.npy')\n",
    "caltech_train_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\caltech\\\\caltech_train_labels.npy')\n",
    "caltech_train_features = np.squeeze(caltech_train_features)\n",
    "#print(\"caltech_train_features.shape:\", caltech_train_features.shape)\n",
    "#print(\"caltech_train_labels.shape\", caltech_train_labels.shape)\n",
    "\n",
    "caltech_test_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\caltech\\\\caltech_test_features.npy')\n",
    "caltech_test_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\caltech\\\\caltech_test_labels.npy')\n",
    "caltech_test_features = np.squeeze(caltech_test_features)\n",
    "#print(\"caltech_test_features.shape:\", caltech_test_features.shape)\n",
    "#print(\"caltech_test_labels.shape\", caltech_test_labels.shape)\n",
    "\n",
    "\n",
    "#caltech构建皮尔逊矩阵\n",
    "caltech_addfeatures_train = []\n",
    "caltech_addfeatures_test = []\n",
    "\n",
    "for i in range(30):\n",
    "    min_train = caltech_train_features[i * 146:(i + 1) * 146]\n",
    "    caltech_addfeatures_train.append(min_train)\n",
    "\n",
    "for i in range(7):\n",
    "    min_test = caltech_test_features[i * 146:(i + 1) * 146]\n",
    "    caltech_addfeatures_test.append(min_test)\n",
    "\n",
    "caltech_addfeatures_train = np.squeeze(np.array(caltech_addfeatures_train))\n",
    "caltech_addfeatures_train = caltech_addfeatures_train.transpose(0,2,1)\n",
    "caltech_addfeatures_test = np.squeeze(np.array(caltech_addfeatures_test))\n",
    "caltech_addfeatures_test = caltech_addfeatures_test.transpose(0,2,1)\n",
    "\n",
    "caltech_addtrain_labels = np.array([0] * 15 + [1] * 15)\n",
    "caltech_addtest_labels = np.array([0] * 4 + [1] * 3)\n",
    "\n",
    "\n",
    "conn_est = ConnectivityMeasure(kind='partial correlation')\n",
    "caltech_addfeatures_train = conn_est.fit_transform(caltech_addfeatures_train)\n",
    "caltech_addfeatures_train = sym_matrix_to_vec(caltech_addfeatures_train)\n",
    "caltech_addfeatures_train = fisherscore(caltech_addfeatures_train, caltech_addtrain_labels, 2000)\n",
    "print('caltech:',caltech_addfeatures_train.shape)\n",
    "\n",
    "caltech_addfeatures_test = conn_est.fit_transform(caltech_addfeatures_test)\n",
    "caltech_addfeatures_test = sym_matrix_to_vec(caltech_addfeatures_test)\n",
    "caltech_addfeatures_test = fisherscore(caltech_addfeatures_test, caltech_addtest_labels, 2000)\n",
    "print('caltech:',caltech_addfeatures_test.shape)\n",
    "\n",
    "'''\n",
    "加载leuven数据\n",
    "'''\n",
    "leuven_train_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\leuven\\\\leuven_train_features.npy')\n",
    "leuven_train_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\leuven\\\\leuven_train_labels.npy')\n",
    "leuven_train_features = np.squeeze(leuven_train_features)\n",
    "#print(\"leuven_train_features.shape:\", leuven_train_features.shape)\n",
    "#print(\"leuven_train_labels.shape\", leuven_train_labels.shape)\n",
    "\n",
    "leuven_test_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\leuven\\\\leuven_test_features.npy')\n",
    "leuven_test_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\leuven\\\\leuven_test_labels.npy')\n",
    "leuven_test_features = np.squeeze(leuven_test_features)\n",
    "#print(\"leuven_test_features.shape:\", leuven_test_features.shape)\n",
    "#print(\"leuven_test_labels.shape\", leuven_test_labels.shape)\n",
    "\n",
    "#leuven构建皮尔逊矩阵\n",
    "leuven_addfeatures_train = []\n",
    "leuven_addfeatures_test = []\n",
    "\n",
    "for i in range(52):\n",
    "    min_train = leuven_train_features[i * 246:(i + 1) * 246]\n",
    "    leuven_addfeatures_train.append(min_train)\n",
    "\n",
    "for i in range(11):\n",
    "    min_test = leuven_test_features[i * 246:(i + 1) * 246]\n",
    "    leuven_addfeatures_test.append(min_test)\n",
    "\n",
    "leuven_addfeatures_train = np.squeeze(np.array(leuven_addfeatures_train))\n",
    "leuven_addfeatures_train = leuven_addfeatures_train.transpose(0,2,1)\n",
    "leuven_addfeatures_test = np.squeeze(np.array(leuven_addfeatures_test))\n",
    "leuven_addfeatures_test = leuven_addfeatures_test.transpose(0,2,1)\n",
    "leuven_addtrain_labels = np.array([0] * 24 + [1] * 28)\n",
    "leuven_addtest_labels = np.array([0] * 5 + [1] * 6)\n",
    "\n",
    "\n",
    "#conn_est = ConnectivityMeasure(kind='tangent')\n",
    "leuven_addfeatures_train = conn_est.fit_transform(leuven_addfeatures_train)\n",
    "leuven_addfeatures_train = sym_matrix_to_vec(leuven_addfeatures_train)\n",
    "leuven_addfeatures_train = fisherscore(leuven_addfeatures_train, leuven_addtrain_labels, 2000)\n",
    "print('leuven:',leuven_addfeatures_train.shape)\n",
    "\n",
    "leuven_addfeatures_test = conn_est.fit_transform(leuven_addfeatures_test)\n",
    "leuven_addfeatures_test = sym_matrix_to_vec(leuven_addfeatures_test)\n",
    "leuven_addfeatures_test = fisherscore(leuven_addfeatures_test, leuven_addtest_labels, 2000)\n",
    "print('leuven:',leuven_addfeatures_test.shape)\n",
    "\n",
    "'''\n",
    "加载nyu数据\n",
    "'''\n",
    "nyu_train_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\nyu\\\\nyu_train_features.npy')\n",
    "nyu_train_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\nyu\\\\nyu_train_labels.npy')\n",
    "nyu_train_features = np.squeeze(nyu_train_features)\n",
    "# print(\"ohsu_train_features.shape:\", nyu_train_features.shape)\n",
    "# print(\"ohsu_train_labels.shape\", nyu_train_labels.shape)\n",
    "\n",
    "nyu_test_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\nyu\\\\nyu_test_features.npy')\n",
    "nyu_test_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\nyu\\\\nyu_test_labels.npy')\n",
    "nyu_test_features = np.squeeze(nyu_test_features)\n",
    "# print(\"ohsu_test_features.shape:\", nyu_test_features.shape)\n",
    "# print(\"ohsu_test_labels.shape\", nyu_test_labels.shape)\n",
    "\n",
    "#nyu构建皮尔逊矩阵\n",
    "nyu_addfeatures_train = []\n",
    "nyu_addfeatures_test = []\n",
    "\n",
    "for i in range(139):\n",
    "    min_train = nyu_train_features[i * 176:(i + 1) * 176]\n",
    "    nyu_addfeatures_train.append(min_train)\n",
    "\n",
    "for i in range(35):\n",
    "    min_test = nyu_test_features[i * 176:(i + 1) * 176]\n",
    "    nyu_addfeatures_test.append(min_test)\n",
    "\n",
    "nyu_addfeatures_train = np.squeeze(np.array(nyu_addfeatures_train))\n",
    "nyu_addfeatures_train = nyu_addfeatures_train.transpose(0,2,1)\n",
    "nyu_addfeatures_test = np.squeeze(np.array(nyu_addfeatures_test))\n",
    "nyu_addfeatures_test = nyu_addfeatures_test.transpose(0,2,1)\n",
    "nyu_addtrain_labels = np.array([0] * 60 + [1] * 79)\n",
    "nyu_addtest_labels = np.array([0] * 15 + [1] * 20)\n",
    "\n",
    "\n",
    "#conn_est = ConnectivityMeasure(kind='tangent')\n",
    "nyu_addfeatures_train = conn_est.fit_transform(nyu_addfeatures_train)\n",
    "nyu_addfeatures_train = sym_matrix_to_vec(nyu_addfeatures_train)\n",
    "nyu_addfeatures_train = fisherscore(nyu_addfeatures_train, nyu_addtrain_labels, 2000)\n",
    "print('nyu:',nyu_addfeatures_train.shape)\n",
    "\n",
    "nyu_addfeatures_test = conn_est.fit_transform(nyu_addfeatures_test)\n",
    "nyu_addfeatures_test = sym_matrix_to_vec(nyu_addfeatures_test)\n",
    "nyu_addfeatures_test = fisherscore(nyu_addfeatures_test, nyu_addtest_labels, 2000)\n",
    "print('nyu:',nyu_addfeatures_test.shape)\n",
    "\n",
    "'''\n",
    "加载ohsu数据\n",
    "'''\n",
    "ohsu_train_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\ohsu\\\\ohsu_train_features.npy')\n",
    "ohsu_train_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\ohsu\\\\ohsu_train_labels.npy')\n",
    "ohsu_train_features = np.squeeze(ohsu_train_features)\n",
    "# print(\"ohsu_train_features.shape:\", ohsu_train_features.shape)\n",
    "# print(\"ohsu_train_labels.shape\", ohsu_train_labels.shape)\n",
    "\n",
    "ohsu_test_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\ohsu\\\\ohsu_test_features.npy')\n",
    "ohsu_test_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\ohsu\\\\ohsu_test_labels.npy')\n",
    "ohsu_test_features = np.squeeze(ohsu_test_features)\n",
    "# print(\"ohsu_test_features.shape:\", ohsu_test_features.shape)\n",
    "# print(\"ohsu_test_labels.shape\", ohsu_test_labels.shape)\n",
    "\n",
    "#ohsu构建皮尔逊矩阵\n",
    "ohsu_addfeatures_train = []\n",
    "ohsu_addfeatures_test = []\n",
    "\n",
    "for i in range(22):\n",
    "    min_train = ohsu_train_features[i * 78:(i + 1) * 78]\n",
    "    ohsu_addfeatures_train.append(min_train)\n",
    "\n",
    "for i in range(4):\n",
    "    min_test = ohsu_test_features[i * 78:(i + 1) * 78]\n",
    "    ohsu_addfeatures_test.append(min_test)\n",
    "\n",
    "ohsu_addfeatures_train = np.squeeze(np.array(ohsu_addfeatures_train))\n",
    "ohsu_addfeatures_train = ohsu_addfeatures_train.transpose(0,2,1)\n",
    "ohsu_addfeatures_test = np.squeeze(np.array(ohsu_addfeatures_test))\n",
    "ohsu_addfeatures_test = ohsu_addfeatures_test.transpose(0,2,1)\n",
    "ohsu_addtrain_labels = np.array([0] * 10 + [1] * 12)\n",
    "ohsu_addtest_labels = np.array([0] * 2 + [1] * 2)\n",
    "\n",
    "\n",
    "#conn_est = ConnectivityMeasure(kind='tangent')\n",
    "ohsu_addfeatures_train = conn_est.fit_transform(ohsu_addfeatures_train)\n",
    "ohsu_addfeatures_train = sym_matrix_to_vec(ohsu_addfeatures_train)\n",
    "ohsu_addfeatures_train = fisherscore(ohsu_addfeatures_train, ohsu_addtrain_labels, 2000)\n",
    "print('ohsu:',ohsu_addfeatures_train.shape)\n",
    "\n",
    "ohsu_addfeatures_test = conn_est.fit_transform(ohsu_addfeatures_test)\n",
    "ohsu_addfeatures_test = sym_matrix_to_vec(ohsu_addfeatures_test)\n",
    "ohsu_addfeatures_test = fisherscore(ohsu_addfeatures_test, ohsu_addtest_labels, 2000)\n",
    "print('ohsu:',ohsu_addfeatures_test.shape)\n",
    "\n",
    "'''\n",
    "加载olin数据\n",
    "'''\n",
    "olin_train_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\olin\\\\olin_train_features.npy')\n",
    "olin_train_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\olin\\\\olin_train_labels.npy')\n",
    "olin_train_features = np.squeeze(olin_train_features)\n",
    "# print(\"olin_train_features.shape:\", olin_train_features.shape)\n",
    "# print(\"olin_train_labels.shape\", olin_train_labels.shape)\n",
    "\n",
    "olin_test_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\olin\\\\olin_test_features.npy')\n",
    "olin_test_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\olin\\\\olin_test_labels.npy')\n",
    "olin_test_features = np.squeeze(olin_test_features)\n",
    "# print(\"olin_test_features.shape:\", olin_test_features.shape)\n",
    "# print(\"olin_test_labels.shape\", olin_test_labels.shape)\n",
    "\n",
    "\n",
    "#olin构建皮尔逊矩阵\n",
    "olin_addfeatures_train = []\n",
    "olin_addfeatures_test = []\n",
    "\n",
    "for i in range(28):\n",
    "    min_train = olin_train_features[i * 206:(i + 1) * 206]\n",
    "    olin_addfeatures_train.append(min_train)\n",
    "\n",
    "for i in range(6):\n",
    "    min_test = olin_test_features[i * 206:(i + 1) * 206]\n",
    "    olin_addfeatures_test.append(min_test)\n",
    "\n",
    "olin_addfeatures_train = np.squeeze(np.array(olin_addfeatures_train))\n",
    "olin_addfeatures_train = olin_addfeatures_train.transpose(0,2,1)\n",
    "olin_addfeatures_test = np.squeeze(np.array(olin_addfeatures_test))\n",
    "olin_addfeatures_test = olin_addfeatures_test.transpose(0,2,1)\n",
    "olin_addtrain_labels = np.array([0] * 16 + [1] * 12)\n",
    "olin_addtest_labels = np.array([0] * 3 + [1] * 3)\n",
    "\n",
    "\n",
    "#conn_est = ConnectivityMeasure(kind='tangent')\n",
    "olin_addfeatures_train = conn_est.fit_transform(olin_addfeatures_train)\n",
    "olin_addfeatures_train = sym_matrix_to_vec(olin_addfeatures_train)\n",
    "olin_addfeatures_train = fisherscore(olin_addfeatures_train, olin_addtrain_labels, 2000)\n",
    "print('olin:',olin_addfeatures_train.shape)\n",
    "\n",
    "olin_addfeatures_test = conn_est.fit_transform(olin_addfeatures_test)\n",
    "olin_addfeatures_test = sym_matrix_to_vec(olin_addfeatures_test)\n",
    "olin_addfeatures_test = fisherscore(olin_addfeatures_test, olin_addtest_labels, 2000)\n",
    "print('olin:',olin_addfeatures_test.shape)\n",
    "\n",
    "'''\n",
    "加载pitt数据\n",
    "'''\n",
    "pitt_train_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\pitt\\\\pitt_train_features.npy')\n",
    "pitt_train_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\pitt\\\\pitt_train_labels.npy')\n",
    "pitt_train_features = np.squeeze(pitt_train_features)\n",
    "# print(\"pitt_train_features.shape:\", pitt_train_features.shape)\n",
    "# print(\"pitt_train_labels.shape\", pitt_train_labels.shape)\n",
    "\n",
    "pitt_test_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\pitt\\\\pitt_test_features.npy')\n",
    "pitt_test_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\pitt\\\\pitt_test_labels.npy')\n",
    "pitt_test_features = np.squeeze(pitt_test_features)\n",
    "# print(\"pitt_test_features.shape:\", pitt_test_features.shape)\n",
    "# print(\"pitt_test_labels.shape\", pitt_test_labels.shape)\n",
    "\n",
    "#pitt构建皮尔逊矩阵\n",
    "pitt_addfeatures_train = []\n",
    "pitt_addfeatures_test = []\n",
    "\n",
    "for i in range(46):\n",
    "    min_train = pitt_train_features[i * 196:(i + 1) * 196]\n",
    "    pitt_addfeatures_train.append(min_train)\n",
    "\n",
    "for i in range(10):\n",
    "    min_test = pitt_test_features[i * 196:(i + 1) * 196]\n",
    "    pitt_addfeatures_test.append(min_test)\n",
    "\n",
    "pitt_addfeatures_train = np.squeeze(np.array(pitt_addfeatures_train))\n",
    "pitt_addfeatures_train = pitt_addfeatures_train.transpose(0,2,1)\n",
    "pitt_addfeatures_test = np.squeeze(np.array(pitt_addfeatures_test))\n",
    "pitt_addfeatures_test = pitt_addfeatures_test.transpose(0,2,1)\n",
    "pitt_addtrain_labels = np.array([0] * 24 + [1] * 22)\n",
    "pitt_addtest_labels = np.array([0] * 5 + [1] * 5)\n",
    "\n",
    "\n",
    "#conn_est = ConnectivityMeasure(kind='tangent')\n",
    "pitt_addfeatures_train = conn_est.fit_transform(pitt_addfeatures_train)\n",
    "pitt_addfeatures_train = sym_matrix_to_vec(pitt_addfeatures_train)\n",
    "pitt_addfeatures_train = fisherscore(pitt_addfeatures_train, pitt_addtrain_labels, 2000)\n",
    "print('pitt:',pitt_addfeatures_train.shape)\n",
    "\n",
    "pitt_addfeatures_test = conn_est.fit_transform(pitt_addfeatures_test)\n",
    "pitt_addfeatures_test = sym_matrix_to_vec(pitt_addfeatures_test)\n",
    "pitt_addfeatures_test = fisherscore(pitt_addfeatures_test, pitt_addtest_labels, 2000)\n",
    "print('pitt:',pitt_addfeatures_test.shape)\n",
    "\n",
    "\n",
    "'''\n",
    "加载sbl数据\n",
    "'''\n",
    "sbl_train_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\sbl\\\\sbl_train_features.npy')\n",
    "sbl_train_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\sbl\\\\sbl_train_labels.npy')\n",
    "sbl_train_features = np.squeeze(sbl_train_features)\n",
    "# print(\"sbl_train_features.shape:\", sbl_train_features.shape)\n",
    "# print(\"sbl_train_labels.shape\", sbl_train_labels.shape)\n",
    "\n",
    "sbl_test_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\sbl\\\\sbl_test_features.npy')\n",
    "sbl_test_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\sbl\\\\sbl_test_labels.npy')\n",
    "sbl_test_features = np.squeeze(sbl_test_features)\n",
    "# print(\"sbl_test_features.shape:\", sbl_test_features.shape)\n",
    "# print(\"sbl_test_labels.shape\", sbl_test_labels.shape)\n",
    "\n",
    "#sbl构建皮尔逊矩阵\n",
    "sbl_addfeatures_train = []\n",
    "sbl_addfeatures_test = []\n",
    "\n",
    "for i in range(24):\n",
    "    min_train = sbl_train_features[i * 196:(i + 1) * 196]\n",
    "    sbl_addfeatures_train.append(min_train)\n",
    "\n",
    "for i in range(5):\n",
    "    min_test = sbl_test_features[i * 196:(i + 1) * 196]\n",
    "    sbl_addfeatures_test.append(min_test)\n",
    "\n",
    "sbl_addfeatures_train = np.squeeze(np.array(sbl_addfeatures_train))\n",
    "sbl_addfeatures_train = sbl_addfeatures_train.transpose(0,2,1)\n",
    "sbl_addfeatures_test = np.squeeze(np.array(sbl_addfeatures_test))\n",
    "sbl_addfeatures_test = sbl_addfeatures_test.transpose(0,2,1)\n",
    "sbl_addtrain_labels = np.array([0] * 12 + [1] * 12)\n",
    "sbl_addtest_labels = np.array([0] * 2 + [1] * 3)\n",
    "\n",
    "\n",
    "#conn_est = ConnectivityMeasure(kind='tangent')\n",
    "sbl_addfeatures_train = conn_est.fit_transform(sbl_addfeatures_train)\n",
    "sbl_addfeatures_train = sym_matrix_to_vec(sbl_addfeatures_train)\n",
    "sbl_addfeatures_train = fisherscore(sbl_addfeatures_train, sbl_addtrain_labels, 2000)\n",
    "print('sbl:',sbl_addfeatures_train.shape)\n",
    "\n",
    "sbl_addfeatures_test = conn_est.fit_transform(sbl_addfeatures_test)\n",
    "sbl_addfeatures_test = sym_matrix_to_vec(sbl_addfeatures_test)\n",
    "sbl_addfeatures_test = fisherscore(sbl_addfeatures_test, sbl_addtest_labels, 2000)\n",
    "print('sbl:',sbl_addfeatures_test.shape)\n",
    "\n",
    "'''\n",
    "加载sdsu数据\n",
    "'''\n",
    "sdsu_train_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\sdsu\\\\sdsu_train_features.npy')\n",
    "sdsu_train_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\sdsu\\\\sdsu_train_labels.npy')\n",
    "sdsu_train_features = np.squeeze(sdsu_train_features)\n",
    "# print(\"sdsu_train_features.shape:\", sdsu_train_features.shape)\n",
    "# print(\"sdsu_train_labels.shape\", sdsu_train_labels.shape)\n",
    "\n",
    "sdsu_test_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\sdsu\\\\sdsu_test_features.npy')\n",
    "sdsu_test_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\sdsu\\\\sdsu_test_labels.npy')\n",
    "sdsu_test_features = np.squeeze(sdsu_test_features)\n",
    "# print(\"sdsu_test_features.shape:\", sdsu_test_features.shape)\n",
    "# print(\"sdsu_test_labels.shape\", sdsu_test_labels.shape)\n",
    "\n",
    "#sdsu构建皮尔逊矩阵\n",
    "sdsu_addfeatures_train = []\n",
    "sdsu_addfeatures_test = []\n",
    "\n",
    "for i in range(30):\n",
    "    min_train = sdsu_train_features[i * 176:(i + 1) * 176]\n",
    "    sdsu_addfeatures_train.append(min_train)\n",
    "\n",
    "for i in range(6):\n",
    "    min_test = sdsu_test_features[i * 176:(i + 1) * 176]\n",
    "    sdsu_addfeatures_test.append(min_test)\n",
    "\n",
    "sdsu_addfeatures_train = np.squeeze(np.array(sdsu_addfeatures_train))\n",
    "sdsu_addfeatures_train = sdsu_addfeatures_train.transpose(0,2,1)\n",
    "sdsu_addfeatures_test = np.squeeze(np.array(sdsu_addfeatures_test))\n",
    "sdsu_addfeatures_test = sdsu_addfeatures_test.transpose(0,2,1)\n",
    "sdsu_addtrain_labels = np.array([0] * 12 + [1] * 18)\n",
    "sdsu_addtest_labels = np.array([0] * 2 + [1] * 4)\n",
    "\n",
    "\n",
    "#conn_est = ConnectivityMeasure(kind='tangent')\n",
    "sdsu_addfeatures_train = conn_est.fit_transform(sdsu_addfeatures_train)\n",
    "sdsu_addfeatures_train = sym_matrix_to_vec(sdsu_addfeatures_train)\n",
    "sdsu_addfeatures_train = fisherscore(sdsu_addfeatures_train, sdsu_addtrain_labels, 2000)\n",
    "print('sdsu:',sdsu_addfeatures_train.shape)\n",
    "\n",
    "sdsu_addfeatures_test = conn_est.fit_transform(sdsu_addfeatures_test)\n",
    "sdsu_addfeatures_test = sym_matrix_to_vec(sdsu_addfeatures_test)\n",
    "sdsu_addfeatures_test = fisherscore(sdsu_addfeatures_test, sdsu_addtest_labels, 2000)\n",
    "print('sdsu:',sdsu_addfeatures_test.shape)\n",
    "\n",
    "'''\n",
    "加载um数据\n",
    "'''\n",
    "um_train_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\um\\\\um_train_features.npy')\n",
    "um_train_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\um\\\\um_train_labels.npy')\n",
    "um_train_features = np.squeeze(um_train_features)\n",
    "# print(\"um_train_features.shape:\", um_train_features.shape)\n",
    "# print(\"um_train_labels.shape\", um_train_labels.shape)\n",
    "\n",
    "um_test_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\um\\\\um_test_features.npy')\n",
    "um_test_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\um\\\\um_test_labels.npy')\n",
    "um_test_features = np.squeeze(um_test_features)\n",
    "# print(\"um_test_features.shape:\", um_test_features.shape)\n",
    "# print(\"um_test_labels.shape\", um_test_labels.shape)\n",
    "\n",
    "#um构建皮尔逊矩阵\n",
    "um_addfeatures_train = []\n",
    "um_addfeatures_test = []\n",
    "\n",
    "for i in range(86):\n",
    "    min_train = um_train_features[i * 296:(i + 1) * 296]\n",
    "    um_addfeatures_train.append(min_train)\n",
    "\n",
    "for i in range(20):\n",
    "    min_test = um_test_features[i * 296:(i + 1) * 296]\n",
    "    um_addfeatures_test.append(min_test)\n",
    "\n",
    "um_addfeatures_train = np.squeeze(np.array(um_addfeatures_train))\n",
    "um_addfeatures_train = um_addfeatures_train.transpose(0,2,1)\n",
    "um_addfeatures_test = np.squeeze(np.array(um_addfeatures_test))\n",
    "um_addfeatures_test = um_addfeatures_test.transpose(0,2,1)\n",
    "um_addtrain_labels = np.array([0] * 43 + [1] * 43)\n",
    "um_addtest_labels = np.array([0] * 10 + [1] * 10)\n",
    "\n",
    "\n",
    "#conn_est = ConnectivityMeasure(kind='tangent')\n",
    "um_addfeatures_train = conn_est.fit_transform(um_addfeatures_train)\n",
    "um_addfeatures_train = sym_matrix_to_vec(um_addfeatures_train)\n",
    "um_addfeatures_train = fisherscore(um_addfeatures_train, um_addtrain_labels, 2000)\n",
    "print('um:',um_addfeatures_train.shape)\n",
    "\n",
    "um_addfeatures_test = conn_est.fit_transform(um_addfeatures_test)\n",
    "um_addfeatures_test = sym_matrix_to_vec(um_addfeatures_test)\n",
    "um_addfeatures_test = fisherscore(um_addfeatures_test, um_addtest_labels, 2000)\n",
    "print('um:',um_addfeatures_test.shape)\n",
    "\n",
    "'''\n",
    "加载usm数据\n",
    "'''\n",
    "usm_train_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\usm\\\\usm_train_features.npy')\n",
    "usm_train_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\usm\\\\usm_train_labels.npy')\n",
    "usm_train_features = np.squeeze(usm_train_features)\n",
    "# print(\"usm_train_features.shape:\", usm_train_features.shape)\n",
    "# print(\"usm_train_labels.shape\", usm_train_labels.shape)\n",
    "\n",
    "usm_test_features = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\usm\\\\usm_test_features.npy')\n",
    "usm_test_labels = np.load('C:\\\\Users\\\\atr\\\\Desktop\\\\save\\\\single\\\\usm\\\\usm_test_labels.npy')\n",
    "usm_test_features = np.squeeze(usm_test_features)\n",
    "# print(\"usm_test_features.shape:\", usm_test_features.shape)\n",
    "# print(\"usm_test_labels.shape\", usm_test_labels.shape)\n",
    "\n",
    "#usm构建皮尔逊矩阵\n",
    "usm_addfeatures_train = []\n",
    "usm_addfeatures_test = []\n",
    "\n",
    "for i in range(57):\n",
    "    min_train = usm_train_features[i * 236:(i + 1) * 236]\n",
    "    usm_addfeatures_train.append(min_train)\n",
    "\n",
    "for i in range(14):\n",
    "    min_test = usm_test_features[i * 236:(i + 1) * 236]\n",
    "    usm_addfeatures_test.append(min_test)\n",
    "\n",
    "usm_addfeatures_train = np.squeeze(np.array(usm_addfeatures_train))\n",
    "usm_addfeatures_train = usm_addfeatures_train.transpose(0,2,1)\n",
    "usm_addfeatures_test = np.squeeze(np.array(usm_addfeatures_test))\n",
    "usm_addfeatures_test = usm_addfeatures_test.transpose(0,2,1)\n",
    "usm_addtrain_labels = np.array([0] * 37 + [1] * 20)\n",
    "usm_addtest_labels = np.array([0] * 9 + [1] * 5)\n",
    "\n",
    "\n",
    "#conn_est = ConnectivityMeasure(kind='tangent')\n",
    "usm_addfeatures_train = conn_est.fit_transform(usm_addfeatures_train)\n",
    "usm_addfeatures_train = sym_matrix_to_vec(usm_addfeatures_train)\n",
    "usm_addfeatures_train = fisherscore(usm_addfeatures_train, usm_addtrain_labels, 2000)\n",
    "print('usm:',usm_addfeatures_train.shape)\n",
    "\n",
    "usm_addfeatures_test = conn_est.fit_transform(usm_addfeatures_test)\n",
    "usm_addfeatures_test = sym_matrix_to_vec(usm_addfeatures_test)\n",
    "usm_addfeatures_test = fisherscore(usm_addfeatures_test, usm_addtest_labels, 2000)\n",
    "print('usm:',usm_addfeatures_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "构建多站点数据集\n",
    "'''\n",
    "\n",
    "train_data = np.vstack((caltech_addfeatures_train,\n",
    "                        leuven_addfeatures_train,\n",
    "                        nyu_addfeatures_train,\n",
    "                        ohsu_addfeatures_train,\n",
    "                        olin_addfeatures_train,\n",
    "                        pitt_addfeatures_train,\n",
    "                        sbl_addfeatures_train,\n",
    "                        sdsu_addfeatures_train,\n",
    "                        um_addfeatures_train,\n",
    "                        usm_addfeatures_train,\n",
    "                        ))\n",
    "train_label = np.hstack((caltech_addtrain_labels,\n",
    "                         leuven_addtrain_labels,\n",
    "                         nyu_addtrain_labels,\n",
    "                         ohsu_addtrain_labels,\n",
    "                         olin_addtrain_labels,\n",
    "                         pitt_addtrain_labels,\n",
    "                         sbl_addtrain_labels,\n",
    "                         sdsu_addtrain_labels,\n",
    "                         um_addtrain_labels,\n",
    "                         usm_addtrain_labels,\n",
    "                         ))\n",
    "\n",
    "test_data = np.vstack((caltech_addfeatures_test,\n",
    "                       leuven_addfeatures_test,\n",
    "                       nyu_addfeatures_test,\n",
    "                       ohsu_addfeatures_test,\n",
    "                       olin_addfeatures_test,\n",
    "                       pitt_addfeatures_test,\n",
    "                       sbl_addfeatures_test,\n",
    "                       sdsu_addfeatures_test,\n",
    "                       um_addfeatures_test,\n",
    "                       usm_addfeatures_test,\n",
    "                       ))\n",
    "test_label = np.hstack((caltech_addtest_labels,\n",
    "                        leuven_addtest_labels,\n",
    "                        nyu_addtest_labels,\n",
    "                        ohsu_addtest_labels,\n",
    "                        olin_addtest_labels,\n",
    "                        pitt_addtest_labels,\n",
    "                        sbl_addtest_labels,\n",
    "                        sdsu_addtest_labels,\n",
    "                        um_addtest_labels,\n",
    "                        usm_addtest_labels,\n",
    "                        ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"train_data:\", train_data.shape)\n",
    "print(\"train_label:\", train_label.shape)\n",
    "print(\"test_data:\", test_data.shape)\n",
    "print(\"test_label:\", test_label.shape)\n",
    "\n",
    "\n",
    "\n",
    "data = np.vstack((train_data, test_data))\n",
    "label = np.hstack((train_label,test_label))\n",
    "print('data', data.shape)\n",
    "print('label', label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 2000)\n",
      "(458, 2000)\n",
      "(115, 2000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_val, x_test, y_val, y_test = train_test_split(test_data, test_label, test_size=0.5)\n",
    "new_data = np.vstack((x_test, train_data))\n",
    "new_label = np.hstack((y_test, train_label))\n",
    "x_train, x_test, y_train, y_test = train_test_split(new_data, new_label, test_size=0.2)\n",
    "print(x_val.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 505 samples, validate on 59 samples\n",
      "Epoch 1/2000\n",
      "505/505 [==============================] - 0s 588us/step - loss: 0.6969 - accuracy: 0.5050 - val_loss: 0.6896 - val_accuracy: 0.6102\n",
      "Epoch 2/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.7073 - accuracy: 0.4931 - val_loss: 0.6879 - val_accuracy: 0.5254\n",
      "Epoch 3/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6901 - accuracy: 0.4851 - val_loss: 0.6876 - val_accuracy: 0.5254\n",
      "Epoch 4/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6943 - accuracy: 0.5129 - val_loss: 0.6863 - val_accuracy: 0.5085\n",
      "Epoch 5/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.7012 - accuracy: 0.5248 - val_loss: 0.6861 - val_accuracy: 0.5254\n",
      "Epoch 6/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.7055 - accuracy: 0.5010 - val_loss: 0.6863 - val_accuracy: 0.5254\n",
      "Epoch 7/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.6902 - accuracy: 0.5505 - val_loss: 0.6856 - val_accuracy: 0.5254\n",
      "Epoch 8/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6901 - accuracy: 0.5426 - val_loss: 0.6855 - val_accuracy: 0.5254\n",
      "Epoch 9/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6896 - accuracy: 0.5366 - val_loss: 0.6861 - val_accuracy: 0.5254\n",
      "Epoch 10/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6951 - accuracy: 0.5485 - val_loss: 0.6859 - val_accuracy: 0.5254\n",
      "Epoch 11/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.7000 - accuracy: 0.4970 - val_loss: 0.6854 - val_accuracy: 0.5254\n",
      "Epoch 12/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.7023 - accuracy: 0.5149 - val_loss: 0.6856 - val_accuracy: 0.5254\n",
      "Epoch 13/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6936 - accuracy: 0.5347 - val_loss: 0.6852 - val_accuracy: 0.5254\n",
      "Epoch 14/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6917 - accuracy: 0.5446 - val_loss: 0.6854 - val_accuracy: 0.5254\n",
      "Epoch 15/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6964 - accuracy: 0.5228 - val_loss: 0.6856 - val_accuracy: 0.5254\n",
      "Epoch 16/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6885 - accuracy: 0.5446 - val_loss: 0.6850 - val_accuracy: 0.5254\n",
      "Epoch 17/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6911 - accuracy: 0.5564 - val_loss: 0.6846 - val_accuracy: 0.5254\n",
      "Epoch 18/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6936 - accuracy: 0.5386 - val_loss: 0.6850 - val_accuracy: 0.5254\n",
      "Epoch 19/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.7010 - accuracy: 0.5149 - val_loss: 0.6852 - val_accuracy: 0.5254\n",
      "Epoch 20/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6920 - accuracy: 0.5347 - val_loss: 0.6857 - val_accuracy: 0.5254\n",
      "Epoch 21/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6839 - accuracy: 0.5485 - val_loss: 0.6856 - val_accuracy: 0.5254\n",
      "Epoch 22/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6937 - accuracy: 0.5386 - val_loss: 0.6853 - val_accuracy: 0.5254\n",
      "Epoch 23/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6955 - accuracy: 0.5287 - val_loss: 0.6848 - val_accuracy: 0.5254\n",
      "Epoch 24/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.6957 - accuracy: 0.5545 - val_loss: 0.6856 - val_accuracy: 0.5254\n",
      "Epoch 25/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6920 - accuracy: 0.5426 - val_loss: 0.6854 - val_accuracy: 0.5254\n",
      "Epoch 26/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6913 - accuracy: 0.5426 - val_loss: 0.6858 - val_accuracy: 0.5254\n",
      "Epoch 27/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6912 - accuracy: 0.5465 - val_loss: 0.6858 - val_accuracy: 0.5254\n",
      "Epoch 28/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6884 - accuracy: 0.5505 - val_loss: 0.6853 - val_accuracy: 0.5254\n",
      "Epoch 29/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6946 - accuracy: 0.5406 - val_loss: 0.6862 - val_accuracy: 0.5254\n",
      "Epoch 30/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6929 - accuracy: 0.5426 - val_loss: 0.6858 - val_accuracy: 0.5254\n",
      "Epoch 31/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6873 - accuracy: 0.5584 - val_loss: 0.6855 - val_accuracy: 0.5254\n",
      "Epoch 32/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6856 - accuracy: 0.5366 - val_loss: 0.6852 - val_accuracy: 0.5254\n",
      "Epoch 33/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6861 - accuracy: 0.5703 - val_loss: 0.6852 - val_accuracy: 0.5254\n",
      "Epoch 34/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6871 - accuracy: 0.5307 - val_loss: 0.6853 - val_accuracy: 0.5254\n",
      "Epoch 35/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6952 - accuracy: 0.5287 - val_loss: 0.6852 - val_accuracy: 0.5254\n",
      "Epoch 36/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6839 - accuracy: 0.5545 - val_loss: 0.6848 - val_accuracy: 0.5254\n",
      "Epoch 37/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6975 - accuracy: 0.5307 - val_loss: 0.6848 - val_accuracy: 0.5254\n",
      "Epoch 38/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6838 - accuracy: 0.5426 - val_loss: 0.6850 - val_accuracy: 0.5254\n",
      "Epoch 39/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.7012 - accuracy: 0.5129 - val_loss: 0.6849 - val_accuracy: 0.5254\n",
      "Epoch 40/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6956 - accuracy: 0.5248 - val_loss: 0.6846 - val_accuracy: 0.5254\n",
      "Epoch 41/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6932 - accuracy: 0.5248 - val_loss: 0.6846 - val_accuracy: 0.5254\n",
      "Epoch 42/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6936 - accuracy: 0.5327 - val_loss: 0.6851 - val_accuracy: 0.5254\n",
      "Epoch 43/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6886 - accuracy: 0.5426 - val_loss: 0.6849 - val_accuracy: 0.5254\n",
      "Epoch 44/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6836 - accuracy: 0.5564 - val_loss: 0.6850 - val_accuracy: 0.5254\n",
      "Epoch 45/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6882 - accuracy: 0.5426 - val_loss: 0.6851 - val_accuracy: 0.5254\n",
      "Epoch 46/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6946 - accuracy: 0.5208 - val_loss: 0.6848 - val_accuracy: 0.5254\n",
      "Epoch 47/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6922 - accuracy: 0.5426 - val_loss: 0.6847 - val_accuracy: 0.5254\n",
      "Epoch 48/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6860 - accuracy: 0.5545 - val_loss: 0.6841 - val_accuracy: 0.5254\n",
      "Epoch 49/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6845 - accuracy: 0.5465 - val_loss: 0.6840 - val_accuracy: 0.5254\n",
      "Epoch 50/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6913 - accuracy: 0.5465 - val_loss: 0.6845 - val_accuracy: 0.5254\n",
      "Epoch 51/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6821 - accuracy: 0.5683 - val_loss: 0.6846 - val_accuracy: 0.5254\n",
      "Epoch 52/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6830 - accuracy: 0.5525 - val_loss: 0.6842 - val_accuracy: 0.5254\n",
      "Epoch 53/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6903 - accuracy: 0.5505 - val_loss: 0.6840 - val_accuracy: 0.5254\n",
      "Epoch 54/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6852 - accuracy: 0.5485 - val_loss: 0.6839 - val_accuracy: 0.5254\n",
      "Epoch 55/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6851 - accuracy: 0.5505 - val_loss: 0.6840 - val_accuracy: 0.5254\n",
      "Epoch 56/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 342us/step - loss: 0.6823 - accuracy: 0.5505 - val_loss: 0.6842 - val_accuracy: 0.5254\n",
      "Epoch 57/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6870 - accuracy: 0.5485 - val_loss: 0.6841 - val_accuracy: 0.5254\n",
      "Epoch 58/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6827 - accuracy: 0.5545 - val_loss: 0.6839 - val_accuracy: 0.5254\n",
      "Epoch 59/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6824 - accuracy: 0.5545 - val_loss: 0.6841 - val_accuracy: 0.5254\n",
      "Epoch 60/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6839 - accuracy: 0.5446 - val_loss: 0.6838 - val_accuracy: 0.5254\n",
      "Epoch 61/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6900 - accuracy: 0.5168 - val_loss: 0.6839 - val_accuracy: 0.5254\n",
      "Epoch 62/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6878 - accuracy: 0.5386 - val_loss: 0.6835 - val_accuracy: 0.5254\n",
      "Epoch 63/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.6878 - accuracy: 0.5327 - val_loss: 0.6833 - val_accuracy: 0.5254\n",
      "Epoch 64/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6869 - accuracy: 0.5525 - val_loss: 0.6832 - val_accuracy: 0.5254\n",
      "Epoch 65/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6891 - accuracy: 0.5465 - val_loss: 0.6831 - val_accuracy: 0.5254\n",
      "Epoch 66/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6821 - accuracy: 0.5584 - val_loss: 0.6834 - val_accuracy: 0.5254\n",
      "Epoch 67/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6893 - accuracy: 0.5386 - val_loss: 0.6833 - val_accuracy: 0.5254\n",
      "Epoch 68/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6787 - accuracy: 0.5624 - val_loss: 0.6829 - val_accuracy: 0.5254\n",
      "Epoch 69/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.6921 - accuracy: 0.5366 - val_loss: 0.6826 - val_accuracy: 0.5254\n",
      "Epoch 70/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6901 - accuracy: 0.5248 - val_loss: 0.6828 - val_accuracy: 0.5254\n",
      "Epoch 71/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6879 - accuracy: 0.5386 - val_loss: 0.6826 - val_accuracy: 0.5254\n",
      "Epoch 72/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6886 - accuracy: 0.5505 - val_loss: 0.6829 - val_accuracy: 0.5254\n",
      "Epoch 73/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6814 - accuracy: 0.5505 - val_loss: 0.6826 - val_accuracy: 0.5254\n",
      "Epoch 74/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6928 - accuracy: 0.5267 - val_loss: 0.6823 - val_accuracy: 0.5254\n",
      "Epoch 75/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6821 - accuracy: 0.5564 - val_loss: 0.6823 - val_accuracy: 0.5254\n",
      "Epoch 76/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6856 - accuracy: 0.5465 - val_loss: 0.6826 - val_accuracy: 0.5254\n",
      "Epoch 77/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6925 - accuracy: 0.5307 - val_loss: 0.6829 - val_accuracy: 0.5254\n",
      "Epoch 78/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6894 - accuracy: 0.5327 - val_loss: 0.6827 - val_accuracy: 0.5254\n",
      "Epoch 79/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6899 - accuracy: 0.5347 - val_loss: 0.6829 - val_accuracy: 0.5254\n",
      "Epoch 80/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6827 - accuracy: 0.5624 - val_loss: 0.6828 - val_accuracy: 0.5254\n",
      "Epoch 81/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6843 - accuracy: 0.5525 - val_loss: 0.6828 - val_accuracy: 0.5254\n",
      "Epoch 82/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6806 - accuracy: 0.5545 - val_loss: 0.6832 - val_accuracy: 0.5254\n",
      "Epoch 83/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6906 - accuracy: 0.5347 - val_loss: 0.6830 - val_accuracy: 0.5254\n",
      "Epoch 84/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6812 - accuracy: 0.5564 - val_loss: 0.6827 - val_accuracy: 0.5254\n",
      "Epoch 85/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6800 - accuracy: 0.5525 - val_loss: 0.6830 - val_accuracy: 0.5254\n",
      "Epoch 86/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6831 - accuracy: 0.5545 - val_loss: 0.6830 - val_accuracy: 0.5254\n",
      "Epoch 87/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6854 - accuracy: 0.5485 - val_loss: 0.6831 - val_accuracy: 0.5254\n",
      "Epoch 88/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6869 - accuracy: 0.5347 - val_loss: 0.6832 - val_accuracy: 0.5254\n",
      "Epoch 89/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6876 - accuracy: 0.5505 - val_loss: 0.6830 - val_accuracy: 0.5254\n",
      "Epoch 90/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6806 - accuracy: 0.5644 - val_loss: 0.6832 - val_accuracy: 0.5254\n",
      "Epoch 91/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6820 - accuracy: 0.5564 - val_loss: 0.6832 - val_accuracy: 0.5254\n",
      "Epoch 92/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6854 - accuracy: 0.5545 - val_loss: 0.6825 - val_accuracy: 0.5254\n",
      "Epoch 93/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6876 - accuracy: 0.5386 - val_loss: 0.6828 - val_accuracy: 0.5254\n",
      "Epoch 94/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6895 - accuracy: 0.5465 - val_loss: 0.6822 - val_accuracy: 0.5254\n",
      "Epoch 95/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6789 - accuracy: 0.5604 - val_loss: 0.6822 - val_accuracy: 0.5254\n",
      "Epoch 96/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6853 - accuracy: 0.5347 - val_loss: 0.6824 - val_accuracy: 0.5254\n",
      "Epoch 97/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6785 - accuracy: 0.5644 - val_loss: 0.6820 - val_accuracy: 0.5254\n",
      "Epoch 98/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6849 - accuracy: 0.5426 - val_loss: 0.6820 - val_accuracy: 0.5254\n",
      "Epoch 99/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6874 - accuracy: 0.5248 - val_loss: 0.6819 - val_accuracy: 0.5254\n",
      "Epoch 100/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6847 - accuracy: 0.5485 - val_loss: 0.6819 - val_accuracy: 0.5254\n",
      "Epoch 101/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6816 - accuracy: 0.5446 - val_loss: 0.6819 - val_accuracy: 0.5254\n",
      "Epoch 102/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6798 - accuracy: 0.5564 - val_loss: 0.6822 - val_accuracy: 0.5254\n",
      "Epoch 103/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.6804 - accuracy: 0.5564 - val_loss: 0.6820 - val_accuracy: 0.5254\n",
      "Epoch 104/2000\n",
      "505/505 [==============================] - 0s 373us/step - loss: 0.6860 - accuracy: 0.5406 - val_loss: 0.6819 - val_accuracy: 0.5254\n",
      "Epoch 105/2000\n",
      "505/505 [==============================] - 0s 375us/step - loss: 0.6789 - accuracy: 0.5762 - val_loss: 0.6818 - val_accuracy: 0.5254\n",
      "Epoch 106/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6811 - accuracy: 0.5604 - val_loss: 0.6819 - val_accuracy: 0.5254\n",
      "Epoch 107/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.6845 - accuracy: 0.5584 - val_loss: 0.6819 - val_accuracy: 0.5254\n",
      "Epoch 108/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6825 - accuracy: 0.5465 - val_loss: 0.6819 - val_accuracy: 0.5254\n",
      "Epoch 109/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.6811 - accuracy: 0.5564 - val_loss: 0.6819 - val_accuracy: 0.5254\n",
      "Epoch 110/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6875 - accuracy: 0.5406 - val_loss: 0.6818 - val_accuracy: 0.5254\n",
      "Epoch 111/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6836 - accuracy: 0.5564 - val_loss: 0.6818 - val_accuracy: 0.5254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6792 - accuracy: 0.5564 - val_loss: 0.6817 - val_accuracy: 0.5254\n",
      "Epoch 113/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.6819 - accuracy: 0.5564 - val_loss: 0.6817 - val_accuracy: 0.5254\n",
      "Epoch 114/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6856 - accuracy: 0.5446 - val_loss: 0.6816 - val_accuracy: 0.5254\n",
      "Epoch 115/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6852 - accuracy: 0.5505 - val_loss: 0.6816 - val_accuracy: 0.5254\n",
      "Epoch 116/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6944 - accuracy: 0.5228 - val_loss: 0.6814 - val_accuracy: 0.5254\n",
      "Epoch 117/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6818 - accuracy: 0.5624 - val_loss: 0.6814 - val_accuracy: 0.5254\n",
      "Epoch 118/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6818 - accuracy: 0.5485 - val_loss: 0.6813 - val_accuracy: 0.5254\n",
      "Epoch 119/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6773 - accuracy: 0.5723 - val_loss: 0.6812 - val_accuracy: 0.5254\n",
      "Epoch 120/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.6864 - accuracy: 0.5505 - val_loss: 0.6809 - val_accuracy: 0.5254\n",
      "Epoch 121/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6816 - accuracy: 0.5525 - val_loss: 0.6811 - val_accuracy: 0.5254\n",
      "Epoch 122/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.6869 - accuracy: 0.5327 - val_loss: 0.6814 - val_accuracy: 0.5254\n",
      "Epoch 123/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6807 - accuracy: 0.5485 - val_loss: 0.6814 - val_accuracy: 0.5254\n",
      "Epoch 124/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6791 - accuracy: 0.5584 - val_loss: 0.6812 - val_accuracy: 0.5254\n",
      "Epoch 125/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6793 - accuracy: 0.5485 - val_loss: 0.6812 - val_accuracy: 0.5254\n",
      "Epoch 126/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6814 - accuracy: 0.5644 - val_loss: 0.6816 - val_accuracy: 0.5254\n",
      "Epoch 127/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6815 - accuracy: 0.5564 - val_loss: 0.6817 - val_accuracy: 0.5254\n",
      "Epoch 128/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6776 - accuracy: 0.5584 - val_loss: 0.6816 - val_accuracy: 0.5254\n",
      "Epoch 129/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6814 - accuracy: 0.5386 - val_loss: 0.6817 - val_accuracy: 0.5254\n",
      "Epoch 130/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6826 - accuracy: 0.5545 - val_loss: 0.6817 - val_accuracy: 0.5254\n",
      "Epoch 131/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6852 - accuracy: 0.5347 - val_loss: 0.6815 - val_accuracy: 0.5254\n",
      "Epoch 132/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6847 - accuracy: 0.5426 - val_loss: 0.6814 - val_accuracy: 0.5254\n",
      "Epoch 133/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6865 - accuracy: 0.5465 - val_loss: 0.6815 - val_accuracy: 0.5254\n",
      "Epoch 134/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6849 - accuracy: 0.5505 - val_loss: 0.6814 - val_accuracy: 0.5254\n",
      "Epoch 135/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6787 - accuracy: 0.5604 - val_loss: 0.6815 - val_accuracy: 0.5254\n",
      "Epoch 136/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6798 - accuracy: 0.5584 - val_loss: 0.6812 - val_accuracy: 0.5254\n",
      "Epoch 137/2000\n",
      "505/505 [==============================] - 0s 383us/step - loss: 0.6935 - accuracy: 0.5267 - val_loss: 0.6815 - val_accuracy: 0.5254\n",
      "Epoch 138/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6801 - accuracy: 0.5505 - val_loss: 0.6813 - val_accuracy: 0.5254\n",
      "Epoch 139/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.6817 - accuracy: 0.5624 - val_loss: 0.6811 - val_accuracy: 0.5254\n",
      "Epoch 140/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.6782 - accuracy: 0.5584 - val_loss: 0.6814 - val_accuracy: 0.5254\n",
      "Epoch 141/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.6790 - accuracy: 0.5525 - val_loss: 0.6817 - val_accuracy: 0.5254\n",
      "Epoch 142/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6810 - accuracy: 0.5406 - val_loss: 0.6814 - val_accuracy: 0.5254\n",
      "Epoch 143/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6786 - accuracy: 0.5525 - val_loss: 0.6811 - val_accuracy: 0.5254\n",
      "Epoch 144/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6806 - accuracy: 0.5485 - val_loss: 0.6813 - val_accuracy: 0.5254\n",
      "Epoch 145/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.6830 - accuracy: 0.5485 - val_loss: 0.6811 - val_accuracy: 0.5254\n",
      "Epoch 146/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.6813 - accuracy: 0.5564 - val_loss: 0.6810 - val_accuracy: 0.5254\n",
      "Epoch 147/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.6843 - accuracy: 0.5426 - val_loss: 0.6812 - val_accuracy: 0.5254\n",
      "Epoch 148/2000\n",
      "505/505 [==============================] - 0s 367us/step - loss: 0.6777 - accuracy: 0.5564 - val_loss: 0.6810 - val_accuracy: 0.5254\n",
      "Epoch 149/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.6795 - accuracy: 0.5683 - val_loss: 0.6806 - val_accuracy: 0.5254\n",
      "Epoch 150/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6824 - accuracy: 0.5505 - val_loss: 0.6803 - val_accuracy: 0.5254\n",
      "Epoch 151/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6831 - accuracy: 0.5465 - val_loss: 0.6801 - val_accuracy: 0.5254\n",
      "Epoch 152/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6768 - accuracy: 0.5723 - val_loss: 0.6803 - val_accuracy: 0.5254\n",
      "Epoch 153/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6818 - accuracy: 0.5584 - val_loss: 0.6801 - val_accuracy: 0.5254\n",
      "Epoch 154/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6815 - accuracy: 0.5525 - val_loss: 0.6801 - val_accuracy: 0.5254\n",
      "Epoch 155/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6744 - accuracy: 0.5743 - val_loss: 0.6802 - val_accuracy: 0.5254\n",
      "Epoch 156/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6792 - accuracy: 0.5703 - val_loss: 0.6800 - val_accuracy: 0.5254\n",
      "Epoch 157/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6788 - accuracy: 0.5525 - val_loss: 0.6800 - val_accuracy: 0.5254\n",
      "Epoch 158/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6785 - accuracy: 0.5564 - val_loss: 0.6798 - val_accuracy: 0.5254\n",
      "Epoch 159/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6836 - accuracy: 0.5505 - val_loss: 0.6796 - val_accuracy: 0.5254\n",
      "Epoch 160/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6754 - accuracy: 0.5604 - val_loss: 0.6801 - val_accuracy: 0.5254\n",
      "Epoch 161/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6843 - accuracy: 0.5485 - val_loss: 0.6801 - val_accuracy: 0.5254\n",
      "Epoch 162/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.6787 - accuracy: 0.5584 - val_loss: 0.6800 - val_accuracy: 0.5254\n",
      "Epoch 163/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6837 - accuracy: 0.5505 - val_loss: 0.6800 - val_accuracy: 0.5254\n",
      "Epoch 164/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6859 - accuracy: 0.5366 - val_loss: 0.6798 - val_accuracy: 0.5254\n",
      "Epoch 165/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6815 - accuracy: 0.5426 - val_loss: 0.6798 - val_accuracy: 0.5254\n",
      "Epoch 166/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.6789 - accuracy: 0.5545 - val_loss: 0.6794 - val_accuracy: 0.5254\n",
      "Epoch 167/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 350us/step - loss: 0.6743 - accuracy: 0.5762 - val_loss: 0.6795 - val_accuracy: 0.5254\n",
      "Epoch 168/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6797 - accuracy: 0.5446 - val_loss: 0.6795 - val_accuracy: 0.5254\n",
      "Epoch 169/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6809 - accuracy: 0.5485 - val_loss: 0.6794 - val_accuracy: 0.5254\n",
      "Epoch 170/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6785 - accuracy: 0.5347 - val_loss: 0.6794 - val_accuracy: 0.5254\n",
      "Epoch 171/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.6827 - accuracy: 0.5564 - val_loss: 0.6795 - val_accuracy: 0.5254\n",
      "Epoch 172/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6757 - accuracy: 0.5644 - val_loss: 0.6792 - val_accuracy: 0.5254\n",
      "Epoch 173/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6808 - accuracy: 0.5584 - val_loss: 0.6792 - val_accuracy: 0.5254\n",
      "Epoch 174/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6795 - accuracy: 0.5525 - val_loss: 0.6793 - val_accuracy: 0.5254\n",
      "Epoch 175/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.6810 - accuracy: 0.5426 - val_loss: 0.6791 - val_accuracy: 0.5254\n",
      "Epoch 176/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6782 - accuracy: 0.5545 - val_loss: 0.6789 - val_accuracy: 0.5254\n",
      "Epoch 177/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6798 - accuracy: 0.5465 - val_loss: 0.6791 - val_accuracy: 0.5254\n",
      "Epoch 178/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6817 - accuracy: 0.5604 - val_loss: 0.6789 - val_accuracy: 0.5254\n",
      "Epoch 179/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6868 - accuracy: 0.5366 - val_loss: 0.6791 - val_accuracy: 0.5254\n",
      "Epoch 180/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6826 - accuracy: 0.5406 - val_loss: 0.6787 - val_accuracy: 0.5254\n",
      "Epoch 181/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6856 - accuracy: 0.5406 - val_loss: 0.6788 - val_accuracy: 0.5254\n",
      "Epoch 182/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6829 - accuracy: 0.5584 - val_loss: 0.6785 - val_accuracy: 0.5254\n",
      "Epoch 183/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6801 - accuracy: 0.5525 - val_loss: 0.6785 - val_accuracy: 0.5254\n",
      "Epoch 184/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6778 - accuracy: 0.5584 - val_loss: 0.6782 - val_accuracy: 0.5254\n",
      "Epoch 185/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6742 - accuracy: 0.5624 - val_loss: 0.6782 - val_accuracy: 0.5254\n",
      "Epoch 186/2000\n",
      "505/505 [==============================] - ETA: 0s - loss: 0.6809 - accuracy: 0.52 - 0s 359us/step - loss: 0.6798 - accuracy: 0.5485 - val_loss: 0.6782 - val_accuracy: 0.5254\n",
      "Epoch 187/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6743 - accuracy: 0.5624 - val_loss: 0.6782 - val_accuracy: 0.5254\n",
      "Epoch 188/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6789 - accuracy: 0.5465 - val_loss: 0.6785 - val_accuracy: 0.5254\n",
      "Epoch 189/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6807 - accuracy: 0.5545 - val_loss: 0.6779 - val_accuracy: 0.5254\n",
      "Epoch 190/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6794 - accuracy: 0.5446 - val_loss: 0.6778 - val_accuracy: 0.5254\n",
      "Epoch 191/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6797 - accuracy: 0.5426 - val_loss: 0.6781 - val_accuracy: 0.5254\n",
      "Epoch 192/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6809 - accuracy: 0.5525 - val_loss: 0.6778 - val_accuracy: 0.5254\n",
      "Epoch 193/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6782 - accuracy: 0.5505 - val_loss: 0.6779 - val_accuracy: 0.5254\n",
      "Epoch 194/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6784 - accuracy: 0.5406 - val_loss: 0.6780 - val_accuracy: 0.5254\n",
      "Epoch 195/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6756 - accuracy: 0.5564 - val_loss: 0.6778 - val_accuracy: 0.5254\n",
      "Epoch 196/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6775 - accuracy: 0.5564 - val_loss: 0.6778 - val_accuracy: 0.5254\n",
      "Epoch 197/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.6768 - accuracy: 0.5683 - val_loss: 0.6779 - val_accuracy: 0.5254\n",
      "Epoch 198/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.6748 - accuracy: 0.5604 - val_loss: 0.6777 - val_accuracy: 0.5254\n",
      "Epoch 199/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.6768 - accuracy: 0.5604 - val_loss: 0.6774 - val_accuracy: 0.5254\n",
      "Epoch 200/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6747 - accuracy: 0.5644 - val_loss: 0.6771 - val_accuracy: 0.5254\n",
      "Epoch 201/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.6802 - accuracy: 0.5465 - val_loss: 0.6772 - val_accuracy: 0.5254\n",
      "Epoch 202/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6720 - accuracy: 0.5683 - val_loss: 0.6774 - val_accuracy: 0.5254\n",
      "Epoch 203/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.6764 - accuracy: 0.5644 - val_loss: 0.6771 - val_accuracy: 0.5254\n",
      "Epoch 204/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.6826 - accuracy: 0.5465 - val_loss: 0.6771 - val_accuracy: 0.5254\n",
      "Epoch 205/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6797 - accuracy: 0.5426 - val_loss: 0.6772 - val_accuracy: 0.5254\n",
      "Epoch 206/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6764 - accuracy: 0.5604 - val_loss: 0.6771 - val_accuracy: 0.5254\n",
      "Epoch 207/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6820 - accuracy: 0.5465 - val_loss: 0.6770 - val_accuracy: 0.5254\n",
      "Epoch 208/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6735 - accuracy: 0.5525 - val_loss: 0.6769 - val_accuracy: 0.5254\n",
      "Epoch 209/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6754 - accuracy: 0.5505 - val_loss: 0.6768 - val_accuracy: 0.5254\n",
      "Epoch 210/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6751 - accuracy: 0.5782 - val_loss: 0.6767 - val_accuracy: 0.5254\n",
      "Epoch 211/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.6821 - accuracy: 0.5426 - val_loss: 0.6768 - val_accuracy: 0.5254\n",
      "Epoch 212/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.6826 - accuracy: 0.5426 - val_loss: 0.6767 - val_accuracy: 0.5254\n",
      "Epoch 213/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.6795 - accuracy: 0.5465 - val_loss: 0.6767 - val_accuracy: 0.5254\n",
      "Epoch 214/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6795 - accuracy: 0.5525 - val_loss: 0.6768 - val_accuracy: 0.5254\n",
      "Epoch 215/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6785 - accuracy: 0.5426 - val_loss: 0.6765 - val_accuracy: 0.5254\n",
      "Epoch 216/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6732 - accuracy: 0.5584 - val_loss: 0.6766 - val_accuracy: 0.5254\n",
      "Epoch 217/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6772 - accuracy: 0.5525 - val_loss: 0.6763 - val_accuracy: 0.5254\n",
      "Epoch 218/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6826 - accuracy: 0.5505 - val_loss: 0.6764 - val_accuracy: 0.5254\n",
      "Epoch 219/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6782 - accuracy: 0.5525 - val_loss: 0.6764 - val_accuracy: 0.5254\n",
      "Epoch 220/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6732 - accuracy: 0.5723 - val_loss: 0.6764 - val_accuracy: 0.5254\n",
      "Epoch 221/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6801 - accuracy: 0.5465 - val_loss: 0.6760 - val_accuracy: 0.5254\n",
      "Epoch 222/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 348us/step - loss: 0.6745 - accuracy: 0.5525 - val_loss: 0.6761 - val_accuracy: 0.5254\n",
      "Epoch 223/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6778 - accuracy: 0.5545 - val_loss: 0.6760 - val_accuracy: 0.5254\n",
      "Epoch 224/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6732 - accuracy: 0.5663 - val_loss: 0.6759 - val_accuracy: 0.5254\n",
      "Epoch 225/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6716 - accuracy: 0.5604 - val_loss: 0.6759 - val_accuracy: 0.5254\n",
      "Epoch 226/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.6750 - accuracy: 0.5525 - val_loss: 0.6762 - val_accuracy: 0.5254\n",
      "Epoch 227/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6797 - accuracy: 0.5564 - val_loss: 0.6761 - val_accuracy: 0.5254\n",
      "Epoch 228/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6795 - accuracy: 0.5426 - val_loss: 0.6761 - val_accuracy: 0.5254\n",
      "Epoch 229/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6806 - accuracy: 0.5564 - val_loss: 0.6761 - val_accuracy: 0.5254\n",
      "Epoch 230/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6800 - accuracy: 0.5584 - val_loss: 0.6760 - val_accuracy: 0.5254\n",
      "Epoch 231/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.6764 - accuracy: 0.5624 - val_loss: 0.6760 - val_accuracy: 0.5254\n",
      "Epoch 232/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.6795 - accuracy: 0.5525 - val_loss: 0.6758 - val_accuracy: 0.5254\n",
      "Epoch 233/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6739 - accuracy: 0.5564 - val_loss: 0.6757 - val_accuracy: 0.5254\n",
      "Epoch 234/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6776 - accuracy: 0.5485 - val_loss: 0.6757 - val_accuracy: 0.5254\n",
      "Epoch 235/2000\n",
      "505/505 [==============================] - 0s 369us/step - loss: 0.6714 - accuracy: 0.5723 - val_loss: 0.6758 - val_accuracy: 0.5254\n",
      "Epoch 236/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6752 - accuracy: 0.5663 - val_loss: 0.6758 - val_accuracy: 0.5254\n",
      "Epoch 237/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.6738 - accuracy: 0.5624 - val_loss: 0.6759 - val_accuracy: 0.5254\n",
      "Epoch 238/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6713 - accuracy: 0.5644 - val_loss: 0.6759 - val_accuracy: 0.5254\n",
      "Epoch 239/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6725 - accuracy: 0.5584 - val_loss: 0.6756 - val_accuracy: 0.5254\n",
      "Epoch 240/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6719 - accuracy: 0.5584 - val_loss: 0.6759 - val_accuracy: 0.5254\n",
      "Epoch 241/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6719 - accuracy: 0.5584 - val_loss: 0.6759 - val_accuracy: 0.5254\n",
      "Epoch 242/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6813 - accuracy: 0.5406 - val_loss: 0.6756 - val_accuracy: 0.5254\n",
      "Epoch 243/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6798 - accuracy: 0.5426 - val_loss: 0.6754 - val_accuracy: 0.5254\n",
      "Epoch 244/2000\n",
      "505/505 [==============================] - 0s 369us/step - loss: 0.6722 - accuracy: 0.5465 - val_loss: 0.6756 - val_accuracy: 0.5254\n",
      "Epoch 245/2000\n",
      "505/505 [==============================] - 0s 377us/step - loss: 0.6709 - accuracy: 0.5604 - val_loss: 0.6750 - val_accuracy: 0.5254\n",
      "Epoch 246/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.6785 - accuracy: 0.5564 - val_loss: 0.6748 - val_accuracy: 0.5254\n",
      "Epoch 247/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6748 - accuracy: 0.5644 - val_loss: 0.6750 - val_accuracy: 0.5254\n",
      "Epoch 248/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.6819 - accuracy: 0.5406 - val_loss: 0.6750 - val_accuracy: 0.5254\n",
      "Epoch 249/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.6791 - accuracy: 0.5287 - val_loss: 0.6749 - val_accuracy: 0.5254\n",
      "Epoch 250/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.6704 - accuracy: 0.5525 - val_loss: 0.6749 - val_accuracy: 0.5254\n",
      "Epoch 251/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6720 - accuracy: 0.5525 - val_loss: 0.6748 - val_accuracy: 0.5254\n",
      "Epoch 252/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6714 - accuracy: 0.5644 - val_loss: 0.6748 - val_accuracy: 0.5254\n",
      "Epoch 253/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6754 - accuracy: 0.5465 - val_loss: 0.6748 - val_accuracy: 0.5254\n",
      "Epoch 254/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6719 - accuracy: 0.5683 - val_loss: 0.6746 - val_accuracy: 0.5254\n",
      "Epoch 255/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6791 - accuracy: 0.5545 - val_loss: 0.6746 - val_accuracy: 0.5254\n",
      "Epoch 256/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6724 - accuracy: 0.5683 - val_loss: 0.6746 - val_accuracy: 0.5254\n",
      "Epoch 257/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.6663 - accuracy: 0.5604 - val_loss: 0.6747 - val_accuracy: 0.5254\n",
      "Epoch 258/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6728 - accuracy: 0.5624 - val_loss: 0.6749 - val_accuracy: 0.5254\n",
      "Epoch 259/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6761 - accuracy: 0.5525 - val_loss: 0.6748 - val_accuracy: 0.5254\n",
      "Epoch 260/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6763 - accuracy: 0.5545 - val_loss: 0.6746 - val_accuracy: 0.5254\n",
      "Epoch 261/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.6747 - accuracy: 0.5545 - val_loss: 0.6747 - val_accuracy: 0.5254\n",
      "Epoch 262/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6682 - accuracy: 0.5683 - val_loss: 0.6744 - val_accuracy: 0.5254\n",
      "Epoch 263/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6769 - accuracy: 0.5584 - val_loss: 0.6739 - val_accuracy: 0.5254\n",
      "Epoch 264/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6728 - accuracy: 0.5545 - val_loss: 0.6737 - val_accuracy: 0.5254\n",
      "Epoch 265/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6709 - accuracy: 0.5663 - val_loss: 0.6739 - val_accuracy: 0.5254\n",
      "Epoch 266/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6685 - accuracy: 0.5762 - val_loss: 0.6740 - val_accuracy: 0.5254\n",
      "Epoch 267/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6751 - accuracy: 0.5485 - val_loss: 0.6737 - val_accuracy: 0.5254\n",
      "Epoch 268/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6758 - accuracy: 0.5624 - val_loss: 0.6736 - val_accuracy: 0.5254\n",
      "Epoch 269/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6705 - accuracy: 0.5485 - val_loss: 0.6735 - val_accuracy: 0.5254\n",
      "Epoch 270/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6756 - accuracy: 0.5564 - val_loss: 0.6732 - val_accuracy: 0.5254\n",
      "Epoch 271/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6752 - accuracy: 0.5564 - val_loss: 0.6733 - val_accuracy: 0.5254\n",
      "Epoch 272/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6705 - accuracy: 0.5604 - val_loss: 0.6732 - val_accuracy: 0.5254\n",
      "Epoch 273/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6761 - accuracy: 0.5564 - val_loss: 0.6731 - val_accuracy: 0.5254\n",
      "Epoch 274/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6693 - accuracy: 0.5624 - val_loss: 0.6728 - val_accuracy: 0.5254\n",
      "Epoch 275/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6745 - accuracy: 0.5584 - val_loss: 0.6728 - val_accuracy: 0.5254\n",
      "Epoch 276/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6719 - accuracy: 0.5683 - val_loss: 0.6730 - val_accuracy: 0.5254\n",
      "Epoch 277/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 338us/step - loss: 0.6717 - accuracy: 0.5624 - val_loss: 0.6729 - val_accuracy: 0.5254\n",
      "Epoch 278/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6671 - accuracy: 0.5802 - val_loss: 0.6730 - val_accuracy: 0.5254\n",
      "Epoch 279/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6701 - accuracy: 0.5624 - val_loss: 0.6728 - val_accuracy: 0.5254\n",
      "Epoch 280/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6758 - accuracy: 0.5703 - val_loss: 0.6726 - val_accuracy: 0.5254\n",
      "Epoch 281/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6781 - accuracy: 0.5525 - val_loss: 0.6723 - val_accuracy: 0.5254\n",
      "Epoch 282/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6670 - accuracy: 0.5624 - val_loss: 0.6723 - val_accuracy: 0.5254\n",
      "Epoch 283/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6738 - accuracy: 0.5564 - val_loss: 0.6723 - val_accuracy: 0.5424\n",
      "Epoch 284/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6704 - accuracy: 0.5723 - val_loss: 0.6721 - val_accuracy: 0.5254\n",
      "Epoch 285/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6698 - accuracy: 0.5624 - val_loss: 0.6720 - val_accuracy: 0.5254\n",
      "Epoch 286/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6726 - accuracy: 0.5564 - val_loss: 0.6723 - val_accuracy: 0.5424\n",
      "Epoch 287/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6701 - accuracy: 0.5723 - val_loss: 0.6721 - val_accuracy: 0.5254\n",
      "Epoch 288/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.6753 - accuracy: 0.5406 - val_loss: 0.6720 - val_accuracy: 0.5254\n",
      "Epoch 289/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.6685 - accuracy: 0.5485 - val_loss: 0.6720 - val_accuracy: 0.5254\n",
      "Epoch 290/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6611 - accuracy: 0.5861 - val_loss: 0.6721 - val_accuracy: 0.5254\n",
      "Epoch 291/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6741 - accuracy: 0.5624 - val_loss: 0.6720 - val_accuracy: 0.5254\n",
      "Epoch 292/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6714 - accuracy: 0.5663 - val_loss: 0.6720 - val_accuracy: 0.5254\n",
      "Epoch 293/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.6701 - accuracy: 0.5663 - val_loss: 0.6714 - val_accuracy: 0.5254\n",
      "Epoch 294/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.6689 - accuracy: 0.5743 - val_loss: 0.6711 - val_accuracy: 0.5254\n",
      "Epoch 295/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6690 - accuracy: 0.5743 - val_loss: 0.6713 - val_accuracy: 0.5254\n",
      "Epoch 296/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.6668 - accuracy: 0.5564 - val_loss: 0.6711 - val_accuracy: 0.5254\n",
      "Epoch 297/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6695 - accuracy: 0.5644 - val_loss: 0.6713 - val_accuracy: 0.5254\n",
      "Epoch 298/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6707 - accuracy: 0.5505 - val_loss: 0.6714 - val_accuracy: 0.5254\n",
      "Epoch 299/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6690 - accuracy: 0.5624 - val_loss: 0.6713 - val_accuracy: 0.5254\n",
      "Epoch 300/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6729 - accuracy: 0.5525 - val_loss: 0.6712 - val_accuracy: 0.5254\n",
      "Epoch 301/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6673 - accuracy: 0.5683 - val_loss: 0.6708 - val_accuracy: 0.5254\n",
      "Epoch 302/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6683 - accuracy: 0.5624 - val_loss: 0.6705 - val_accuracy: 0.5254\n",
      "Epoch 303/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6728 - accuracy: 0.5604 - val_loss: 0.6704 - val_accuracy: 0.5254\n",
      "Epoch 304/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6704 - accuracy: 0.5584 - val_loss: 0.6704 - val_accuracy: 0.5254\n",
      "Epoch 305/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6648 - accuracy: 0.5782 - val_loss: 0.6705 - val_accuracy: 0.5254\n",
      "Epoch 306/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6735 - accuracy: 0.5545 - val_loss: 0.6704 - val_accuracy: 0.5254\n",
      "Epoch 307/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6672 - accuracy: 0.5822 - val_loss: 0.6705 - val_accuracy: 0.5254\n",
      "Epoch 308/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6678 - accuracy: 0.5723 - val_loss: 0.6705 - val_accuracy: 0.5254\n",
      "Epoch 309/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6705 - accuracy: 0.5465 - val_loss: 0.6703 - val_accuracy: 0.5254\n",
      "Epoch 310/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6670 - accuracy: 0.5584 - val_loss: 0.6705 - val_accuracy: 0.5254\n",
      "Epoch 311/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.6729 - accuracy: 0.5604 - val_loss: 0.6703 - val_accuracy: 0.5254\n",
      "Epoch 312/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6624 - accuracy: 0.5822 - val_loss: 0.6704 - val_accuracy: 0.5254\n",
      "Epoch 313/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6673 - accuracy: 0.5505 - val_loss: 0.6700 - val_accuracy: 0.5254\n",
      "Epoch 314/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.6713 - accuracy: 0.5584 - val_loss: 0.6697 - val_accuracy: 0.5254\n",
      "Epoch 315/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.6745 - accuracy: 0.5564 - val_loss: 0.6695 - val_accuracy: 0.5254\n",
      "Epoch 316/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6686 - accuracy: 0.5743 - val_loss: 0.6690 - val_accuracy: 0.5254\n",
      "Epoch 317/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6747 - accuracy: 0.5446 - val_loss: 0.6689 - val_accuracy: 0.5254\n",
      "Epoch 318/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6726 - accuracy: 0.5426 - val_loss: 0.6689 - val_accuracy: 0.5254\n",
      "Epoch 319/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6675 - accuracy: 0.5723 - val_loss: 0.6685 - val_accuracy: 0.5254\n",
      "Epoch 320/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6699 - accuracy: 0.5683 - val_loss: 0.6684 - val_accuracy: 0.5254\n",
      "Epoch 321/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.6693 - accuracy: 0.5644 - val_loss: 0.6685 - val_accuracy: 0.5254\n",
      "Epoch 322/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6658 - accuracy: 0.5762 - val_loss: 0.6685 - val_accuracy: 0.5254\n",
      "Epoch 323/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6708 - accuracy: 0.5644 - val_loss: 0.6686 - val_accuracy: 0.5254\n",
      "Epoch 324/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6641 - accuracy: 0.5802 - val_loss: 0.6686 - val_accuracy: 0.5254\n",
      "Epoch 325/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6649 - accuracy: 0.5683 - val_loss: 0.6684 - val_accuracy: 0.5254\n",
      "Epoch 326/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6722 - accuracy: 0.5624 - val_loss: 0.6682 - val_accuracy: 0.5254\n",
      "Epoch 327/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6644 - accuracy: 0.5663 - val_loss: 0.6680 - val_accuracy: 0.5254\n",
      "Epoch 328/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6677 - accuracy: 0.5584 - val_loss: 0.6677 - val_accuracy: 0.5254\n",
      "Epoch 329/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6666 - accuracy: 0.5723 - val_loss: 0.6675 - val_accuracy: 0.5254\n",
      "Epoch 330/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.6729 - accuracy: 0.5644 - val_loss: 0.6677 - val_accuracy: 0.5254\n",
      "Epoch 331/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6658 - accuracy: 0.5703 - val_loss: 0.6676 - val_accuracy: 0.5254\n",
      "Epoch 332/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 346us/step - loss: 0.6653 - accuracy: 0.5822 - val_loss: 0.6677 - val_accuracy: 0.5424\n",
      "Epoch 333/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6702 - accuracy: 0.5743 - val_loss: 0.6677 - val_accuracy: 0.5424\n",
      "Epoch 334/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6612 - accuracy: 0.5941 - val_loss: 0.6676 - val_accuracy: 0.5424\n",
      "Epoch 335/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6700 - accuracy: 0.5683 - val_loss: 0.6678 - val_accuracy: 0.5085\n",
      "Epoch 336/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6615 - accuracy: 0.5802 - val_loss: 0.6680 - val_accuracy: 0.5085\n",
      "Epoch 337/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6659 - accuracy: 0.5743 - val_loss: 0.6677 - val_accuracy: 0.5085\n",
      "Epoch 338/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6632 - accuracy: 0.5505 - val_loss: 0.6678 - val_accuracy: 0.5085\n",
      "Epoch 339/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6644 - accuracy: 0.5901 - val_loss: 0.6670 - val_accuracy: 0.5254\n",
      "Epoch 340/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6693 - accuracy: 0.5663 - val_loss: 0.6668 - val_accuracy: 0.5254\n",
      "Epoch 341/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6626 - accuracy: 0.5782 - val_loss: 0.6668 - val_accuracy: 0.5424\n",
      "Epoch 342/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.6649 - accuracy: 0.5723 - val_loss: 0.6665 - val_accuracy: 0.5254\n",
      "Epoch 343/2000\n",
      "505/505 [==============================] - 0s 367us/step - loss: 0.6682 - accuracy: 0.5723 - val_loss: 0.6663 - val_accuracy: 0.5254\n",
      "Epoch 344/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.6590 - accuracy: 0.5901 - val_loss: 0.6661 - val_accuracy: 0.5254\n",
      "Epoch 345/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6657 - accuracy: 0.5743 - val_loss: 0.6660 - val_accuracy: 0.5424\n",
      "Epoch 346/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6688 - accuracy: 0.5782 - val_loss: 0.6661 - val_accuracy: 0.5254\n",
      "Epoch 347/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6637 - accuracy: 0.5723 - val_loss: 0.6657 - val_accuracy: 0.5424\n",
      "Epoch 348/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6650 - accuracy: 0.5861 - val_loss: 0.6658 - val_accuracy: 0.5424\n",
      "Epoch 349/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6665 - accuracy: 0.5723 - val_loss: 0.6658 - val_accuracy: 0.5254\n",
      "Epoch 350/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6610 - accuracy: 0.5663 - val_loss: 0.6659 - val_accuracy: 0.5254\n",
      "Epoch 351/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.6626 - accuracy: 0.5723 - val_loss: 0.6656 - val_accuracy: 0.5254\n",
      "Epoch 352/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.6619 - accuracy: 0.5921 - val_loss: 0.6653 - val_accuracy: 0.5254\n",
      "Epoch 353/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.6606 - accuracy: 0.6099 - val_loss: 0.6655 - val_accuracy: 0.5254\n",
      "Epoch 354/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6588 - accuracy: 0.6119 - val_loss: 0.6654 - val_accuracy: 0.5254\n",
      "Epoch 355/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6648 - accuracy: 0.5762 - val_loss: 0.6655 - val_accuracy: 0.5424\n",
      "Epoch 356/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.6590 - accuracy: 0.6059 - val_loss: 0.6652 - val_accuracy: 0.5254\n",
      "Epoch 357/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6593 - accuracy: 0.5921 - val_loss: 0.6648 - val_accuracy: 0.5254\n",
      "Epoch 358/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6645 - accuracy: 0.5980 - val_loss: 0.6644 - val_accuracy: 0.5254\n",
      "Epoch 359/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6544 - accuracy: 0.6139 - val_loss: 0.6645 - val_accuracy: 0.5254\n",
      "Epoch 360/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6643 - accuracy: 0.5723 - val_loss: 0.6641 - val_accuracy: 0.5254\n",
      "Epoch 361/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6665 - accuracy: 0.5881 - val_loss: 0.6642 - val_accuracy: 0.5424\n",
      "Epoch 362/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6632 - accuracy: 0.6198 - val_loss: 0.6638 - val_accuracy: 0.5254\n",
      "Epoch 363/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6600 - accuracy: 0.5881 - val_loss: 0.6636 - val_accuracy: 0.5254\n",
      "Epoch 364/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6655 - accuracy: 0.5703 - val_loss: 0.6633 - val_accuracy: 0.5254\n",
      "Epoch 365/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.6554 - accuracy: 0.6000 - val_loss: 0.6635 - val_accuracy: 0.5424\n",
      "Epoch 366/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6635 - accuracy: 0.5802 - val_loss: 0.6632 - val_accuracy: 0.5424\n",
      "Epoch 367/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6608 - accuracy: 0.5802 - val_loss: 0.6633 - val_accuracy: 0.5593\n",
      "Epoch 368/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6625 - accuracy: 0.5941 - val_loss: 0.6631 - val_accuracy: 0.5424\n",
      "Epoch 369/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6632 - accuracy: 0.5881 - val_loss: 0.6629 - val_accuracy: 0.5424\n",
      "Epoch 370/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6600 - accuracy: 0.6040 - val_loss: 0.6622 - val_accuracy: 0.5424\n",
      "Epoch 371/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.6615 - accuracy: 0.5921 - val_loss: 0.6624 - val_accuracy: 0.5593\n",
      "Epoch 372/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6585 - accuracy: 0.6158 - val_loss: 0.6628 - val_accuracy: 0.5593\n",
      "Epoch 373/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6677 - accuracy: 0.5723 - val_loss: 0.6629 - val_accuracy: 0.5424\n",
      "Epoch 374/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6605 - accuracy: 0.5921 - val_loss: 0.6633 - val_accuracy: 0.5254\n",
      "Epoch 375/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6547 - accuracy: 0.5960 - val_loss: 0.6633 - val_accuracy: 0.5254\n",
      "Epoch 376/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6603 - accuracy: 0.6059 - val_loss: 0.6623 - val_accuracy: 0.5254\n",
      "Epoch 377/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6632 - accuracy: 0.5842 - val_loss: 0.6626 - val_accuracy: 0.5254\n",
      "Epoch 378/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6673 - accuracy: 0.5822 - val_loss: 0.6622 - val_accuracy: 0.5593\n",
      "Epoch 379/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.6591 - accuracy: 0.6079 - val_loss: 0.6615 - val_accuracy: 0.5424\n",
      "Epoch 380/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6664 - accuracy: 0.5960 - val_loss: 0.6615 - val_accuracy: 0.5593\n",
      "Epoch 381/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6640 - accuracy: 0.5802 - val_loss: 0.6611 - val_accuracy: 0.5593\n",
      "Epoch 382/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6576 - accuracy: 0.6158 - val_loss: 0.6612 - val_accuracy: 0.5424\n",
      "Epoch 383/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6602 - accuracy: 0.5861 - val_loss: 0.6616 - val_accuracy: 0.5254\n",
      "Epoch 384/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6623 - accuracy: 0.6139 - val_loss: 0.6611 - val_accuracy: 0.5424\n",
      "Epoch 385/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6563 - accuracy: 0.6158 - val_loss: 0.6613 - val_accuracy: 0.5593\n",
      "Epoch 386/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6570 - accuracy: 0.6059 - val_loss: 0.6613 - val_accuracy: 0.5593\n",
      "Epoch 387/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 330us/step - loss: 0.6536 - accuracy: 0.6040 - val_loss: 0.6612 - val_accuracy: 0.5424\n",
      "Epoch 388/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6614 - accuracy: 0.6099 - val_loss: 0.6611 - val_accuracy: 0.5593\n",
      "Epoch 389/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.6594 - accuracy: 0.6139 - val_loss: 0.6606 - val_accuracy: 0.5254\n",
      "Epoch 390/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6578 - accuracy: 0.5881 - val_loss: 0.6601 - val_accuracy: 0.5424\n",
      "Epoch 391/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6566 - accuracy: 0.5960 - val_loss: 0.6597 - val_accuracy: 0.5424\n",
      "Epoch 392/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6566 - accuracy: 0.6119 - val_loss: 0.6594 - val_accuracy: 0.5424\n",
      "Epoch 393/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6653 - accuracy: 0.6139 - val_loss: 0.6597 - val_accuracy: 0.5254\n",
      "Epoch 394/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.6617 - accuracy: 0.6119 - val_loss: 0.6596 - val_accuracy: 0.5254\n",
      "Epoch 395/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6605 - accuracy: 0.6337 - val_loss: 0.6594 - val_accuracy: 0.5254\n",
      "Epoch 396/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6551 - accuracy: 0.6554 - val_loss: 0.6590 - val_accuracy: 0.5254\n",
      "Epoch 397/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6557 - accuracy: 0.6297 - val_loss: 0.6588 - val_accuracy: 0.5593\n",
      "Epoch 398/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6605 - accuracy: 0.6040 - val_loss: 0.6587 - val_accuracy: 0.5593\n",
      "Epoch 399/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6550 - accuracy: 0.6158 - val_loss: 0.6586 - val_accuracy: 0.5593\n",
      "Epoch 400/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6595 - accuracy: 0.5842 - val_loss: 0.6586 - val_accuracy: 0.5593\n",
      "Epoch 401/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6638 - accuracy: 0.5941 - val_loss: 0.6584 - val_accuracy: 0.5254\n",
      "Epoch 402/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6558 - accuracy: 0.6455 - val_loss: 0.6583 - val_accuracy: 0.5254\n",
      "Epoch 403/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6575 - accuracy: 0.6119 - val_loss: 0.6578 - val_accuracy: 0.5254\n",
      "Epoch 404/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6627 - accuracy: 0.6277 - val_loss: 0.6581 - val_accuracy: 0.5254\n",
      "Epoch 405/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6550 - accuracy: 0.6416 - val_loss: 0.6573 - val_accuracy: 0.5424\n",
      "Epoch 406/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6567 - accuracy: 0.6178 - val_loss: 0.6571 - val_accuracy: 0.5593\n",
      "Epoch 407/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6581 - accuracy: 0.6178 - val_loss: 0.6568 - val_accuracy: 0.5424\n",
      "Epoch 408/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6534 - accuracy: 0.6297 - val_loss: 0.6569 - val_accuracy: 0.5254\n",
      "Epoch 409/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.6547 - accuracy: 0.6158 - val_loss: 0.6572 - val_accuracy: 0.5254\n",
      "Epoch 410/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6564 - accuracy: 0.6020 - val_loss: 0.6570 - val_accuracy: 0.5254\n",
      "Epoch 411/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6549 - accuracy: 0.6436 - val_loss: 0.6565 - val_accuracy: 0.5593\n",
      "Epoch 412/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6596 - accuracy: 0.6000 - val_loss: 0.6566 - val_accuracy: 0.5593\n",
      "Epoch 413/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.6507 - accuracy: 0.6416 - val_loss: 0.6564 - val_accuracy: 0.5424\n",
      "Epoch 414/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.6444 - accuracy: 0.6475 - val_loss: 0.6563 - val_accuracy: 0.5424\n",
      "Epoch 415/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6505 - accuracy: 0.6178 - val_loss: 0.6562 - val_accuracy: 0.5424\n",
      "Epoch 416/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6532 - accuracy: 0.6099 - val_loss: 0.6554 - val_accuracy: 0.5593\n",
      "Epoch 417/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.6560 - accuracy: 0.6059 - val_loss: 0.6551 - val_accuracy: 0.6271\n",
      "Epoch 418/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.6540 - accuracy: 0.6574 - val_loss: 0.6550 - val_accuracy: 0.5254\n",
      "Epoch 419/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.6530 - accuracy: 0.6257 - val_loss: 0.6548 - val_accuracy: 0.5254\n",
      "Epoch 420/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6517 - accuracy: 0.6396 - val_loss: 0.6548 - val_accuracy: 0.6441\n",
      "Epoch 421/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6579 - accuracy: 0.6178 - val_loss: 0.6550 - val_accuracy: 0.5254\n",
      "Epoch 422/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6383 - accuracy: 0.6693 - val_loss: 0.6547 - val_accuracy: 0.5254\n",
      "Epoch 423/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.6530 - accuracy: 0.6277 - val_loss: 0.6544 - val_accuracy: 0.5593\n",
      "Epoch 424/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.6556 - accuracy: 0.6198 - val_loss: 0.6539 - val_accuracy: 0.5424\n",
      "Epoch 425/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6449 - accuracy: 0.6792 - val_loss: 0.6538 - val_accuracy: 0.5593\n",
      "Epoch 426/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6617 - accuracy: 0.6475 - val_loss: 0.6544 - val_accuracy: 0.5424\n",
      "Epoch 427/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6537 - accuracy: 0.6416 - val_loss: 0.6543 - val_accuracy: 0.5424\n",
      "Epoch 428/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.6465 - accuracy: 0.6455 - val_loss: 0.6540 - val_accuracy: 0.5763\n",
      "Epoch 429/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.6518 - accuracy: 0.6297 - val_loss: 0.6533 - val_accuracy: 0.6102\n",
      "Epoch 430/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.6510 - accuracy: 0.6297 - val_loss: 0.6531 - val_accuracy: 0.5932\n",
      "Epoch 431/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.6535 - accuracy: 0.6337 - val_loss: 0.6531 - val_accuracy: 0.5932\n",
      "Epoch 432/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6453 - accuracy: 0.6356 - val_loss: 0.6529 - val_accuracy: 0.5763\n",
      "Epoch 433/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6520 - accuracy: 0.6376 - val_loss: 0.6521 - val_accuracy: 0.5932\n",
      "Epoch 434/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6491 - accuracy: 0.6634 - val_loss: 0.6519 - val_accuracy: 0.6271\n",
      "Epoch 435/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6523 - accuracy: 0.6376 - val_loss: 0.6515 - val_accuracy: 0.6271\n",
      "Epoch 436/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6537 - accuracy: 0.6396 - val_loss: 0.6515 - val_accuracy: 0.5763\n",
      "Epoch 437/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6431 - accuracy: 0.6594 - val_loss: 0.6520 - val_accuracy: 0.5932\n",
      "Epoch 438/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.6391 - accuracy: 0.6574 - val_loss: 0.6517 - val_accuracy: 0.5932\n",
      "Epoch 439/2000\n",
      "505/505 [==============================] - 0s 371us/step - loss: 0.6530 - accuracy: 0.6436 - val_loss: 0.6514 - val_accuracy: 0.5932\n",
      "Epoch 440/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.6483 - accuracy: 0.6356 - val_loss: 0.6514 - val_accuracy: 0.6271\n",
      "Epoch 441/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6446 - accuracy: 0.6614 - val_loss: 0.6512 - val_accuracy: 0.6102\n",
      "Epoch 442/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 342us/step - loss: 0.6556 - accuracy: 0.6455 - val_loss: 0.6504 - val_accuracy: 0.6271\n",
      "Epoch 443/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6493 - accuracy: 0.6812 - val_loss: 0.6500 - val_accuracy: 0.6271\n",
      "Epoch 444/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6492 - accuracy: 0.6812 - val_loss: 0.6499 - val_accuracy: 0.6271\n",
      "Epoch 445/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6435 - accuracy: 0.6713 - val_loss: 0.6495 - val_accuracy: 0.6271\n",
      "Epoch 446/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6413 - accuracy: 0.6752 - val_loss: 0.6489 - val_accuracy: 0.6271\n",
      "Epoch 447/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6469 - accuracy: 0.6574 - val_loss: 0.6487 - val_accuracy: 0.6271\n",
      "Epoch 448/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6488 - accuracy: 0.6851 - val_loss: 0.6487 - val_accuracy: 0.6271\n",
      "Epoch 449/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6515 - accuracy: 0.6634 - val_loss: 0.6481 - val_accuracy: 0.6610\n",
      "Epoch 450/2000\n",
      "505/505 [==============================] - 0s 375us/step - loss: 0.6514 - accuracy: 0.6317 - val_loss: 0.6479 - val_accuracy: 0.6271\n",
      "Epoch 451/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6408 - accuracy: 0.6911 - val_loss: 0.6478 - val_accuracy: 0.6271\n",
      "Epoch 452/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6519 - accuracy: 0.6733 - val_loss: 0.6470 - val_accuracy: 0.6441\n",
      "Epoch 453/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.6409 - accuracy: 0.6970 - val_loss: 0.6474 - val_accuracy: 0.6610\n",
      "Epoch 454/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6506 - accuracy: 0.6733 - val_loss: 0.6471 - val_accuracy: 0.6271\n",
      "Epoch 455/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6458 - accuracy: 0.6693 - val_loss: 0.6467 - val_accuracy: 0.6271\n",
      "Epoch 456/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6520 - accuracy: 0.6574 - val_loss: 0.6465 - val_accuracy: 0.6271\n",
      "Epoch 457/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6371 - accuracy: 0.6832 - val_loss: 0.6462 - val_accuracy: 0.6441\n",
      "Epoch 458/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6389 - accuracy: 0.6792 - val_loss: 0.6466 - val_accuracy: 0.6271\n",
      "Epoch 459/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.6402 - accuracy: 0.7030 - val_loss: 0.6458 - val_accuracy: 0.6441\n",
      "Epoch 460/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6395 - accuracy: 0.6911 - val_loss: 0.6450 - val_accuracy: 0.6271\n",
      "Epoch 461/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.6345 - accuracy: 0.7050 - val_loss: 0.6452 - val_accuracy: 0.6271\n",
      "Epoch 462/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.6343 - accuracy: 0.7188 - val_loss: 0.6452 - val_accuracy: 0.6271\n",
      "Epoch 463/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.6403 - accuracy: 0.6812 - val_loss: 0.6445 - val_accuracy: 0.6610\n",
      "Epoch 464/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.6411 - accuracy: 0.7188 - val_loss: 0.6438 - val_accuracy: 0.6441\n",
      "Epoch 465/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.6432 - accuracy: 0.6653 - val_loss: 0.6439 - val_accuracy: 0.6441\n",
      "Epoch 466/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6409 - accuracy: 0.6911 - val_loss: 0.6437 - val_accuracy: 0.6441\n",
      "Epoch 467/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.6377 - accuracy: 0.6950 - val_loss: 0.6442 - val_accuracy: 0.6610\n",
      "Epoch 468/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6415 - accuracy: 0.6871 - val_loss: 0.6436 - val_accuracy: 0.6441\n",
      "Epoch 469/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6405 - accuracy: 0.7109 - val_loss: 0.6437 - val_accuracy: 0.6780\n",
      "Epoch 470/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.6372 - accuracy: 0.6871 - val_loss: 0.6427 - val_accuracy: 0.6780\n",
      "Epoch 471/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.6415 - accuracy: 0.7050 - val_loss: 0.6420 - val_accuracy: 0.7458\n",
      "Epoch 472/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6442 - accuracy: 0.6851 - val_loss: 0.6413 - val_accuracy: 0.6780\n",
      "Epoch 473/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6390 - accuracy: 0.7248 - val_loss: 0.6409 - val_accuracy: 0.6610\n",
      "Epoch 474/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.6358 - accuracy: 0.6772 - val_loss: 0.6407 - val_accuracy: 0.6610\n",
      "Epoch 475/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.6341 - accuracy: 0.6851 - val_loss: 0.6402 - val_accuracy: 0.7119\n",
      "Epoch 476/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6356 - accuracy: 0.7307 - val_loss: 0.6402 - val_accuracy: 0.6949\n",
      "Epoch 477/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6372 - accuracy: 0.7129 - val_loss: 0.6398 - val_accuracy: 0.6780\n",
      "Epoch 478/2000\n",
      "505/505 [==============================] - 0s 383us/step - loss: 0.6349 - accuracy: 0.6752 - val_loss: 0.6393 - val_accuracy: 0.6780\n",
      "Epoch 479/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.6397 - accuracy: 0.6970 - val_loss: 0.6394 - val_accuracy: 0.6780\n",
      "Epoch 480/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6368 - accuracy: 0.7089 - val_loss: 0.6390 - val_accuracy: 0.6780\n",
      "Epoch 481/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6383 - accuracy: 0.7129 - val_loss: 0.6390 - val_accuracy: 0.6780\n",
      "Epoch 482/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6395 - accuracy: 0.7208 - val_loss: 0.6389 - val_accuracy: 0.6780\n",
      "Epoch 483/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6383 - accuracy: 0.6871 - val_loss: 0.6389 - val_accuracy: 0.6780\n",
      "Epoch 484/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.6382 - accuracy: 0.7089 - val_loss: 0.6384 - val_accuracy: 0.6780\n",
      "Epoch 485/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6386 - accuracy: 0.7069 - val_loss: 0.6381 - val_accuracy: 0.6780\n",
      "Epoch 486/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6324 - accuracy: 0.7149 - val_loss: 0.6377 - val_accuracy: 0.6610\n",
      "Epoch 487/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6275 - accuracy: 0.7129 - val_loss: 0.6374 - val_accuracy: 0.6610\n",
      "Epoch 488/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6328 - accuracy: 0.6950 - val_loss: 0.6364 - val_accuracy: 0.6780\n",
      "Epoch 489/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6393 - accuracy: 0.7188 - val_loss: 0.6364 - val_accuracy: 0.6949\n",
      "Epoch 490/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6327 - accuracy: 0.7168 - val_loss: 0.6366 - val_accuracy: 0.6780\n",
      "Epoch 491/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6274 - accuracy: 0.7406 - val_loss: 0.6360 - val_accuracy: 0.6610\n",
      "Epoch 492/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6254 - accuracy: 0.7366 - val_loss: 0.6357 - val_accuracy: 0.6780\n",
      "Epoch 493/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6371 - accuracy: 0.7228 - val_loss: 0.6359 - val_accuracy: 0.6780\n",
      "Epoch 494/2000\n",
      "505/505 [==============================] - 0s 367us/step - loss: 0.6285 - accuracy: 0.7109 - val_loss: 0.6355 - val_accuracy: 0.6780\n",
      "Epoch 495/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.6304 - accuracy: 0.7030 - val_loss: 0.6354 - val_accuracy: 0.7119\n",
      "Epoch 496/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6274 - accuracy: 0.7366 - val_loss: 0.6339 - val_accuracy: 0.6780\n",
      "Epoch 497/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 344us/step - loss: 0.6247 - accuracy: 0.7149 - val_loss: 0.6335 - val_accuracy: 0.6780\n",
      "Epoch 498/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6303 - accuracy: 0.7505 - val_loss: 0.6352 - val_accuracy: 0.6780\n",
      "Epoch 499/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6372 - accuracy: 0.7188 - val_loss: 0.6341 - val_accuracy: 0.6780\n",
      "Epoch 500/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6335 - accuracy: 0.7109 - val_loss: 0.6335 - val_accuracy: 0.6780\n",
      "Epoch 501/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6220 - accuracy: 0.7446 - val_loss: 0.6323 - val_accuracy: 0.7797\n",
      "Epoch 502/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6277 - accuracy: 0.7129 - val_loss: 0.6317 - val_accuracy: 0.7966\n",
      "Epoch 503/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6266 - accuracy: 0.7327 - val_loss: 0.6313 - val_accuracy: 0.7119\n",
      "Epoch 504/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6337 - accuracy: 0.7248 - val_loss: 0.6312 - val_accuracy: 0.7458\n",
      "Epoch 505/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6330 - accuracy: 0.7287 - val_loss: 0.6313 - val_accuracy: 0.6949\n",
      "Epoch 506/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6295 - accuracy: 0.7347 - val_loss: 0.6311 - val_accuracy: 0.6780\n",
      "Epoch 507/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6264 - accuracy: 0.7208 - val_loss: 0.6319 - val_accuracy: 0.6949\n",
      "Epoch 508/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.6184 - accuracy: 0.7584 - val_loss: 0.6313 - val_accuracy: 0.6780\n",
      "Epoch 509/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6311 - accuracy: 0.7069 - val_loss: 0.6298 - val_accuracy: 0.7119\n",
      "Epoch 510/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6197 - accuracy: 0.7604 - val_loss: 0.6286 - val_accuracy: 0.7458\n",
      "Epoch 511/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6278 - accuracy: 0.7267 - val_loss: 0.6302 - val_accuracy: 0.8136\n",
      "Epoch 512/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6286 - accuracy: 0.7287 - val_loss: 0.6288 - val_accuracy: 0.7119\n",
      "Epoch 513/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6267 - accuracy: 0.7228 - val_loss: 0.6282 - val_accuracy: 0.7627\n",
      "Epoch 514/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6238 - accuracy: 0.7366 - val_loss: 0.6275 - val_accuracy: 0.8475\n",
      "Epoch 515/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6246 - accuracy: 0.7644 - val_loss: 0.6278 - val_accuracy: 0.6780\n",
      "Epoch 516/2000\n",
      "505/505 [==============================] - 0s 391us/step - loss: 0.6232 - accuracy: 0.7168 - val_loss: 0.6269 - val_accuracy: 0.7627\n",
      "Epoch 517/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6199 - accuracy: 0.7267 - val_loss: 0.6261 - val_accuracy: 0.7797\n",
      "Epoch 518/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6151 - accuracy: 0.7584 - val_loss: 0.6257 - val_accuracy: 0.7797\n",
      "Epoch 519/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6306 - accuracy: 0.7050 - val_loss: 0.6253 - val_accuracy: 0.8305\n",
      "Epoch 520/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6208 - accuracy: 0.7366 - val_loss: 0.6239 - val_accuracy: 0.8814\n",
      "Epoch 521/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6107 - accuracy: 0.7564 - val_loss: 0.6239 - val_accuracy: 0.8305\n",
      "Epoch 522/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6193 - accuracy: 0.7406 - val_loss: 0.6231 - val_accuracy: 0.8644\n",
      "Epoch 523/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6109 - accuracy: 0.7683 - val_loss: 0.6227 - val_accuracy: 0.7627\n",
      "Epoch 524/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.6226 - accuracy: 0.7604 - val_loss: 0.6226 - val_accuracy: 0.7797\n",
      "Epoch 525/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6154 - accuracy: 0.7485 - val_loss: 0.6225 - val_accuracy: 0.7119\n",
      "Epoch 526/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6224 - accuracy: 0.7485 - val_loss: 0.6217 - val_accuracy: 0.7627\n",
      "Epoch 527/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6136 - accuracy: 0.7604 - val_loss: 0.6223 - val_accuracy: 0.7119\n",
      "Epoch 528/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6153 - accuracy: 0.7663 - val_loss: 0.6214 - val_accuracy: 0.7458\n",
      "Epoch 529/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6188 - accuracy: 0.7426 - val_loss: 0.6213 - val_accuracy: 0.7288\n",
      "Epoch 530/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6141 - accuracy: 0.7584 - val_loss: 0.6203 - val_accuracy: 0.7288\n",
      "Epoch 531/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6164 - accuracy: 0.7604 - val_loss: 0.6200 - val_accuracy: 0.7797\n",
      "Epoch 532/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6228 - accuracy: 0.7505 - val_loss: 0.6192 - val_accuracy: 0.8644\n",
      "Epoch 533/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6150 - accuracy: 0.7624 - val_loss: 0.6192 - val_accuracy: 0.8644\n",
      "Epoch 534/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6140 - accuracy: 0.7782 - val_loss: 0.6182 - val_accuracy: 0.8475\n",
      "Epoch 535/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6084 - accuracy: 0.7426 - val_loss: 0.6183 - val_accuracy: 0.8814\n",
      "Epoch 536/2000\n",
      "505/505 [==============================] - 0s 373us/step - loss: 0.6128 - accuracy: 0.7861 - val_loss: 0.6180 - val_accuracy: 0.7119\n",
      "Epoch 537/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6100 - accuracy: 0.7624 - val_loss: 0.6184 - val_accuracy: 0.7119\n",
      "Epoch 538/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6073 - accuracy: 0.7327 - val_loss: 0.6174 - val_accuracy: 0.7288\n",
      "Epoch 539/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6107 - accuracy: 0.7644 - val_loss: 0.6173 - val_accuracy: 0.7458\n",
      "Epoch 540/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6019 - accuracy: 0.7584 - val_loss: 0.6162 - val_accuracy: 0.9153\n",
      "Epoch 541/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.6053 - accuracy: 0.7861 - val_loss: 0.6138 - val_accuracy: 0.8644\n",
      "Epoch 542/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6041 - accuracy: 0.7644 - val_loss: 0.6136 - val_accuracy: 0.8644\n",
      "Epoch 543/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6077 - accuracy: 0.7703 - val_loss: 0.6137 - val_accuracy: 0.8475\n",
      "Epoch 544/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.6182 - accuracy: 0.7426 - val_loss: 0.6125 - val_accuracy: 0.8644\n",
      "Epoch 545/2000\n",
      "505/505 [==============================] - 0s 369us/step - loss: 0.6141 - accuracy: 0.7525 - val_loss: 0.6115 - val_accuracy: 0.9153\n",
      "Epoch 546/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.6033 - accuracy: 0.7743 - val_loss: 0.6146 - val_accuracy: 0.8814\n",
      "Epoch 547/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6102 - accuracy: 0.7703 - val_loss: 0.6109 - val_accuracy: 0.8475\n",
      "Epoch 548/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6075 - accuracy: 0.7604 - val_loss: 0.6114 - val_accuracy: 0.7288\n",
      "Epoch 549/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.5960 - accuracy: 0.7782 - val_loss: 0.6105 - val_accuracy: 0.7288\n",
      "Epoch 550/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.6066 - accuracy: 0.7762 - val_loss: 0.6095 - val_accuracy: 0.7288\n",
      "Epoch 551/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.6123 - accuracy: 0.7782 - val_loss: 0.6091 - val_accuracy: 0.8475\n",
      "Epoch 552/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 354us/step - loss: 0.5935 - accuracy: 0.7980 - val_loss: 0.6086 - val_accuracy: 0.9153\n",
      "Epoch 553/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.5949 - accuracy: 0.7762 - val_loss: 0.6064 - val_accuracy: 0.9492\n",
      "Epoch 554/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.6018 - accuracy: 0.7960 - val_loss: 0.6063 - val_accuracy: 0.8644\n",
      "Epoch 555/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.5994 - accuracy: 0.8040 - val_loss: 0.6069 - val_accuracy: 0.8814\n",
      "Epoch 556/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.6071 - accuracy: 0.7861 - val_loss: 0.6065 - val_accuracy: 0.7458\n",
      "Epoch 557/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.6039 - accuracy: 0.7663 - val_loss: 0.6057 - val_accuracy: 0.8305\n",
      "Epoch 558/2000\n",
      "505/505 [==============================] - 0s 367us/step - loss: 0.5982 - accuracy: 0.7921 - val_loss: 0.6038 - val_accuracy: 0.9153\n",
      "Epoch 559/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.5969 - accuracy: 0.7901 - val_loss: 0.6035 - val_accuracy: 0.9153\n",
      "Epoch 560/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.5968 - accuracy: 0.7921 - val_loss: 0.6036 - val_accuracy: 0.8475\n",
      "Epoch 561/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.6026 - accuracy: 0.7782 - val_loss: 0.6031 - val_accuracy: 0.7627\n",
      "Epoch 562/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.5933 - accuracy: 0.7822 - val_loss: 0.6022 - val_accuracy: 0.9153\n",
      "Epoch 563/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.6010 - accuracy: 0.7941 - val_loss: 0.6019 - val_accuracy: 0.9153\n",
      "Epoch 564/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.5929 - accuracy: 0.7901 - val_loss: 0.6006 - val_accuracy: 0.9153\n",
      "Epoch 565/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.5972 - accuracy: 0.7822 - val_loss: 0.6025 - val_accuracy: 0.7288\n",
      "Epoch 566/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.6001 - accuracy: 0.7723 - val_loss: 0.5999 - val_accuracy: 0.9153\n",
      "Epoch 567/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.5927 - accuracy: 0.7960 - val_loss: 0.5991 - val_accuracy: 0.9153\n",
      "Epoch 568/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.5983 - accuracy: 0.7901 - val_loss: 0.5985 - val_accuracy: 0.9153\n",
      "Epoch 569/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.5961 - accuracy: 0.7901 - val_loss: 0.5974 - val_accuracy: 0.8644\n",
      "Epoch 570/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.5906 - accuracy: 0.7703 - val_loss: 0.5962 - val_accuracy: 0.9492\n",
      "Epoch 571/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.5835 - accuracy: 0.7960 - val_loss: 0.5958 - val_accuracy: 0.9153\n",
      "Epoch 572/2000\n",
      "505/505 [==============================] - 0s 377us/step - loss: 0.5877 - accuracy: 0.8119 - val_loss: 0.5940 - val_accuracy: 0.9492\n",
      "Epoch 573/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.5914 - accuracy: 0.7901 - val_loss: 0.5938 - val_accuracy: 0.8983\n",
      "Epoch 574/2000\n",
      "505/505 [==============================] - 0s 369us/step - loss: 0.5860 - accuracy: 0.7723 - val_loss: 0.5937 - val_accuracy: 0.7797\n",
      "Epoch 575/2000\n",
      "505/505 [==============================] - 0s 373us/step - loss: 0.5870 - accuracy: 0.8119 - val_loss: 0.5928 - val_accuracy: 0.8136\n",
      "Epoch 576/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.5881 - accuracy: 0.7802 - val_loss: 0.5927 - val_accuracy: 0.8136\n",
      "Epoch 577/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.5868 - accuracy: 0.8000 - val_loss: 0.5918 - val_accuracy: 0.9153\n",
      "Epoch 578/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.5823 - accuracy: 0.7980 - val_loss: 0.5895 - val_accuracy: 0.9322\n",
      "Epoch 579/2000\n",
      "505/505 [==============================] - 0s 385us/step - loss: 0.5934 - accuracy: 0.7941 - val_loss: 0.5904 - val_accuracy: 0.9153\n",
      "Epoch 580/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.5814 - accuracy: 0.7881 - val_loss: 0.5897 - val_accuracy: 0.8136\n",
      "Epoch 581/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.5830 - accuracy: 0.8000 - val_loss: 0.5911 - val_accuracy: 0.7797\n",
      "Epoch 582/2000\n",
      "505/505 [==============================] - 0s 369us/step - loss: 0.5871 - accuracy: 0.7921 - val_loss: 0.5902 - val_accuracy: 0.8983\n",
      "Epoch 583/2000\n",
      "505/505 [==============================] - 0s 369us/step - loss: 0.5890 - accuracy: 0.7881 - val_loss: 0.5880 - val_accuracy: 0.9322\n",
      "Epoch 584/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.5884 - accuracy: 0.7802 - val_loss: 0.5865 - val_accuracy: 0.9492\n",
      "Epoch 585/2000\n",
      "505/505 [==============================] - 0s 373us/step - loss: 0.5716 - accuracy: 0.8218 - val_loss: 0.5866 - val_accuracy: 0.9153\n",
      "Epoch 586/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.5786 - accuracy: 0.8119 - val_loss: 0.5870 - val_accuracy: 0.8136\n",
      "Epoch 587/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.5697 - accuracy: 0.8158 - val_loss: 0.5864 - val_accuracy: 0.8136\n",
      "Epoch 588/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.5822 - accuracy: 0.7881 - val_loss: 0.5862 - val_accuracy: 0.8814\n",
      "Epoch 589/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.5753 - accuracy: 0.7861 - val_loss: 0.5822 - val_accuracy: 0.9492\n",
      "Epoch 590/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.5777 - accuracy: 0.8000 - val_loss: 0.5845 - val_accuracy: 0.9153\n",
      "Epoch 591/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.5792 - accuracy: 0.7960 - val_loss: 0.5834 - val_accuracy: 0.7797\n",
      "Epoch 592/2000\n",
      "505/505 [==============================] - 0s 373us/step - loss: 0.5669 - accuracy: 0.8158 - val_loss: 0.5820 - val_accuracy: 0.7966\n",
      "Epoch 593/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.5757 - accuracy: 0.8059 - val_loss: 0.5803 - val_accuracy: 0.8136\n",
      "Epoch 594/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.5766 - accuracy: 0.8000 - val_loss: 0.5780 - val_accuracy: 0.8814\n",
      "Epoch 595/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.5783 - accuracy: 0.8099 - val_loss: 0.5781 - val_accuracy: 0.8475\n",
      "Epoch 596/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.5689 - accuracy: 0.8178 - val_loss: 0.5764 - val_accuracy: 0.8983\n",
      "Epoch 597/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.5753 - accuracy: 0.7644 - val_loss: 0.5775 - val_accuracy: 0.8475\n",
      "Epoch 598/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.5740 - accuracy: 0.8119 - val_loss: 0.5802 - val_accuracy: 0.7966\n",
      "Epoch 599/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.5628 - accuracy: 0.8238 - val_loss: 0.5764 - val_accuracy: 0.9153\n",
      "Epoch 600/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.5788 - accuracy: 0.8020 - val_loss: 0.5754 - val_accuracy: 0.9153\n",
      "Epoch 601/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.5607 - accuracy: 0.8158 - val_loss: 0.5746 - val_accuracy: 0.9153\n",
      "Epoch 602/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.5631 - accuracy: 0.8000 - val_loss: 0.5735 - val_accuracy: 0.8983\n",
      "Epoch 603/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.5648 - accuracy: 0.8079 - val_loss: 0.5737 - val_accuracy: 0.9153\n",
      "Epoch 604/2000\n",
      "505/505 [==============================] - 0s 367us/step - loss: 0.5580 - accuracy: 0.8297 - val_loss: 0.5731 - val_accuracy: 0.7797\n",
      "Epoch 605/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.5642 - accuracy: 0.7960 - val_loss: 0.5764 - val_accuracy: 0.7797\n",
      "Epoch 606/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.5611 - accuracy: 0.8000 - val_loss: 0.5752 - val_accuracy: 0.9153\n",
      "Epoch 607/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 350us/step - loss: 0.5652 - accuracy: 0.8059 - val_loss: 0.5687 - val_accuracy: 0.9492\n",
      "Epoch 608/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.5662 - accuracy: 0.8059 - val_loss: 0.5717 - val_accuracy: 0.9153\n",
      "Epoch 609/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.5646 - accuracy: 0.8119 - val_loss: 0.5681 - val_accuracy: 0.9153\n",
      "Epoch 610/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.5527 - accuracy: 0.8218 - val_loss: 0.5660 - val_accuracy: 0.9322\n",
      "Epoch 611/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.5601 - accuracy: 0.8178 - val_loss: 0.5693 - val_accuracy: 0.8136\n",
      "Epoch 612/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.5617 - accuracy: 0.7941 - val_loss: 0.5650 - val_accuracy: 0.9153\n",
      "Epoch 613/2000\n",
      "505/505 [==============================] - 0s 377us/step - loss: 0.5560 - accuracy: 0.8139 - val_loss: 0.5661 - val_accuracy: 0.8814\n",
      "Epoch 614/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.5581 - accuracy: 0.8099 - val_loss: 0.5626 - val_accuracy: 0.9153\n",
      "Epoch 615/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.5544 - accuracy: 0.8040 - val_loss: 0.5609 - val_accuracy: 0.9322\n",
      "Epoch 616/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.5629 - accuracy: 0.8020 - val_loss: 0.5637 - val_accuracy: 0.8136\n",
      "Epoch 617/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.5660 - accuracy: 0.8020 - val_loss: 0.5681 - val_accuracy: 0.7797\n",
      "Epoch 618/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.5585 - accuracy: 0.8139 - val_loss: 0.5644 - val_accuracy: 0.7797\n",
      "Epoch 619/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.5507 - accuracy: 0.8178 - val_loss: 0.5674 - val_accuracy: 0.7797\n",
      "Epoch 620/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.5572 - accuracy: 0.7980 - val_loss: 0.5608 - val_accuracy: 0.8983\n",
      "Epoch 621/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.5477 - accuracy: 0.7941 - val_loss: 0.5556 - val_accuracy: 0.9153\n",
      "Epoch 622/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.5531 - accuracy: 0.8158 - val_loss: 0.5560 - val_accuracy: 0.9322\n",
      "Epoch 623/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.5454 - accuracy: 0.8257 - val_loss: 0.5567 - val_accuracy: 0.8136\n",
      "Epoch 624/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.5497 - accuracy: 0.8158 - val_loss: 0.5561 - val_accuracy: 0.7797\n",
      "Epoch 625/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.5424 - accuracy: 0.8277 - val_loss: 0.5592 - val_accuracy: 0.7797\n",
      "Epoch 626/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.5482 - accuracy: 0.8198 - val_loss: 0.5544 - val_accuracy: 0.9153\n",
      "Epoch 627/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.5483 - accuracy: 0.8040 - val_loss: 0.5503 - val_accuracy: 0.9492\n",
      "Epoch 628/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.5553 - accuracy: 0.8000 - val_loss: 0.5527 - val_accuracy: 0.8136\n",
      "Epoch 629/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.5409 - accuracy: 0.8297 - val_loss: 0.5487 - val_accuracy: 0.9322\n",
      "Epoch 630/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.5492 - accuracy: 0.7980 - val_loss: 0.5480 - val_accuracy: 0.9153\n",
      "Epoch 631/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.5417 - accuracy: 0.8277 - val_loss: 0.5498 - val_accuracy: 0.8475\n",
      "Epoch 632/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.5426 - accuracy: 0.8257 - val_loss: 0.5467 - val_accuracy: 0.8983\n",
      "Epoch 633/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.5447 - accuracy: 0.8119 - val_loss: 0.5488 - val_accuracy: 0.9153\n",
      "Epoch 634/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.5324 - accuracy: 0.8178 - val_loss: 0.5451 - val_accuracy: 0.9153\n",
      "Epoch 635/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.5357 - accuracy: 0.8158 - val_loss: 0.5467 - val_accuracy: 0.8136\n",
      "Epoch 636/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.5378 - accuracy: 0.7980 - val_loss: 0.5458 - val_accuracy: 0.9153\n",
      "Epoch 637/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.5302 - accuracy: 0.8079 - val_loss: 0.5423 - val_accuracy: 0.8983\n",
      "Epoch 638/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.5265 - accuracy: 0.8158 - val_loss: 0.5419 - val_accuracy: 0.8983\n",
      "Epoch 639/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.5326 - accuracy: 0.8040 - val_loss: 0.5396 - val_accuracy: 0.9492\n",
      "Epoch 640/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.5347 - accuracy: 0.8277 - val_loss: 0.5402 - val_accuracy: 0.9153\n",
      "Epoch 641/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.5382 - accuracy: 0.8119 - val_loss: 0.5368 - val_accuracy: 0.9153\n",
      "Epoch 642/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.5257 - accuracy: 0.8317 - val_loss: 0.5360 - val_accuracy: 0.9153\n",
      "Epoch 643/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.5294 - accuracy: 0.8257 - val_loss: 0.5342 - val_accuracy: 0.9492\n",
      "Epoch 644/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.5310 - accuracy: 0.8059 - val_loss: 0.5350 - val_accuracy: 0.9153\n",
      "Epoch 645/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.5220 - accuracy: 0.8119 - val_loss: 0.5307 - val_accuracy: 0.9492\n",
      "Epoch 646/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.5305 - accuracy: 0.8337 - val_loss: 0.5331 - val_accuracy: 0.9153\n",
      "Epoch 647/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.5214 - accuracy: 0.8238 - val_loss: 0.5308 - val_accuracy: 0.9153\n",
      "Epoch 648/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.5220 - accuracy: 0.8317 - val_loss: 0.5316 - val_accuracy: 0.8475\n",
      "Epoch 649/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.5171 - accuracy: 0.8455 - val_loss: 0.5394 - val_accuracy: 0.8644\n",
      "Epoch 650/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.5241 - accuracy: 0.8277 - val_loss: 0.5300 - val_accuracy: 0.8475\n",
      "Epoch 651/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.5219 - accuracy: 0.8317 - val_loss: 0.5322 - val_accuracy: 0.9153\n",
      "Epoch 652/2000\n",
      "505/505 [==============================] - 0s 367us/step - loss: 0.5214 - accuracy: 0.8059 - val_loss: 0.5292 - val_accuracy: 0.8136\n",
      "Epoch 653/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.5335 - accuracy: 0.8079 - val_loss: 0.5255 - val_accuracy: 0.9492\n",
      "Epoch 654/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.5160 - accuracy: 0.8238 - val_loss: 0.5262 - val_accuracy: 0.8983\n",
      "Epoch 655/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.5142 - accuracy: 0.8455 - val_loss: 0.5293 - val_accuracy: 0.9322\n",
      "Epoch 656/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.5107 - accuracy: 0.8059 - val_loss: 0.5234 - val_accuracy: 0.9492\n",
      "Epoch 657/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.5148 - accuracy: 0.8376 - val_loss: 0.5248 - val_accuracy: 0.8305\n",
      "Epoch 658/2000\n",
      "505/505 [==============================] - 0s 417us/step - loss: 0.5181 - accuracy: 0.8277 - val_loss: 0.5209 - val_accuracy: 0.9492\n",
      "Epoch 659/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.5147 - accuracy: 0.8178 - val_loss: 0.5210 - val_accuracy: 0.9322\n",
      "Epoch 660/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.5133 - accuracy: 0.8257 - val_loss: 0.5234 - val_accuracy: 0.9153\n",
      "Epoch 661/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.5069 - accuracy: 0.8218 - val_loss: 0.5171 - val_accuracy: 0.9492\n",
      "Epoch 662/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 354us/step - loss: 0.5128 - accuracy: 0.8099 - val_loss: 0.5151 - val_accuracy: 0.9492\n",
      "Epoch 663/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.5100 - accuracy: 0.8356 - val_loss: 0.5151 - val_accuracy: 0.9492\n",
      "Epoch 664/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.5142 - accuracy: 0.8218 - val_loss: 0.5143 - val_accuracy: 0.9153\n",
      "Epoch 665/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.5114 - accuracy: 0.8198 - val_loss: 0.5107 - val_accuracy: 0.9492\n",
      "Epoch 666/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.5034 - accuracy: 0.8535 - val_loss: 0.5154 - val_accuracy: 0.7966\n",
      "Epoch 667/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.4942 - accuracy: 0.8317 - val_loss: 0.5098 - val_accuracy: 0.9153\n",
      "Epoch 668/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.5045 - accuracy: 0.8257 - val_loss: 0.5129 - val_accuracy: 0.8814\n",
      "Epoch 669/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.4934 - accuracy: 0.8475 - val_loss: 0.5118 - val_accuracy: 0.7966\n",
      "Epoch 670/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.5132 - accuracy: 0.8257 - val_loss: 0.5122 - val_accuracy: 0.7797\n",
      "Epoch 671/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.5007 - accuracy: 0.8178 - val_loss: 0.5105 - val_accuracy: 0.8644\n",
      "Epoch 672/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.4973 - accuracy: 0.8277 - val_loss: 0.5087 - val_accuracy: 0.7966\n",
      "Epoch 673/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.5117 - accuracy: 0.7980 - val_loss: 0.5047 - val_accuracy: 0.9153\n",
      "Epoch 674/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.4994 - accuracy: 0.8198 - val_loss: 0.5017 - val_accuracy: 0.8814\n",
      "Epoch 675/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.4949 - accuracy: 0.8337 - val_loss: 0.5098 - val_accuracy: 0.7966\n",
      "Epoch 676/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.5070 - accuracy: 0.8238 - val_loss: 0.4974 - val_accuracy: 0.9492\n",
      "Epoch 677/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.5024 - accuracy: 0.8218 - val_loss: 0.5042 - val_accuracy: 0.8136\n",
      "Epoch 678/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.4918 - accuracy: 0.8396 - val_loss: 0.4969 - val_accuracy: 0.9492\n",
      "Epoch 679/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.4857 - accuracy: 0.8416 - val_loss: 0.4933 - val_accuracy: 0.9492\n",
      "Epoch 680/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.4856 - accuracy: 0.8396 - val_loss: 0.5029 - val_accuracy: 0.7797\n",
      "Epoch 681/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.4928 - accuracy: 0.8158 - val_loss: 0.4946 - val_accuracy: 0.9322\n",
      "Epoch 682/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.4874 - accuracy: 0.8356 - val_loss: 0.5013 - val_accuracy: 0.7966\n",
      "Epoch 683/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.4986 - accuracy: 0.8139 - val_loss: 0.4931 - val_accuracy: 0.9492\n",
      "Epoch 684/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.4928 - accuracy: 0.8178 - val_loss: 0.4925 - val_accuracy: 0.9492\n",
      "Epoch 685/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.4847 - accuracy: 0.8376 - val_loss: 0.4924 - val_accuracy: 0.9153\n",
      "Epoch 686/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.4753 - accuracy: 0.8475 - val_loss: 0.4937 - val_accuracy: 0.8136\n",
      "Epoch 687/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.4848 - accuracy: 0.8238 - val_loss: 0.4898 - val_accuracy: 0.9153\n",
      "Epoch 688/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.4851 - accuracy: 0.8158 - val_loss: 0.4886 - val_accuracy: 0.9153\n",
      "Epoch 689/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.4902 - accuracy: 0.8218 - val_loss: 0.4970 - val_accuracy: 0.8136\n",
      "Epoch 690/2000\n",
      "505/505 [==============================] - 0s 375us/step - loss: 0.4743 - accuracy: 0.8337 - val_loss: 0.4860 - val_accuracy: 0.9492\n",
      "Epoch 691/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.4836 - accuracy: 0.8158 - val_loss: 0.4872 - val_accuracy: 0.8814\n",
      "Epoch 692/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.4742 - accuracy: 0.8218 - val_loss: 0.4826 - val_accuracy: 0.9492\n",
      "Epoch 693/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.4801 - accuracy: 0.8218 - val_loss: 0.4804 - val_accuracy: 0.9492\n",
      "Epoch 694/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.4737 - accuracy: 0.8257 - val_loss: 0.4780 - val_accuracy: 0.9492\n",
      "Epoch 695/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.4761 - accuracy: 0.8475 - val_loss: 0.4820 - val_accuracy: 0.9153\n",
      "Epoch 696/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.4672 - accuracy: 0.8396 - val_loss: 0.4882 - val_accuracy: 0.9153\n",
      "Epoch 697/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.4650 - accuracy: 0.8337 - val_loss: 0.4781 - val_accuracy: 0.9153\n",
      "Epoch 698/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.4774 - accuracy: 0.8099 - val_loss: 0.4775 - val_accuracy: 0.9153\n",
      "Epoch 699/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.4588 - accuracy: 0.8376 - val_loss: 0.4722 - val_accuracy: 0.9492\n",
      "Epoch 700/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.4700 - accuracy: 0.8178 - val_loss: 0.4728 - val_accuracy: 0.9492\n",
      "Epoch 701/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.4736 - accuracy: 0.8337 - val_loss: 0.4757 - val_accuracy: 0.8475\n",
      "Epoch 702/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.4592 - accuracy: 0.8455 - val_loss: 0.4726 - val_accuracy: 0.9153\n",
      "Epoch 703/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.4724 - accuracy: 0.8297 - val_loss: 0.4700 - val_accuracy: 0.9153\n",
      "Epoch 704/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.4762 - accuracy: 0.8158 - val_loss: 0.4716 - val_accuracy: 0.9153\n",
      "Epoch 705/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.4742 - accuracy: 0.8218 - val_loss: 0.4662 - val_accuracy: 0.9322\n",
      "Epoch 706/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.4648 - accuracy: 0.8198 - val_loss: 0.4730 - val_accuracy: 0.8136\n",
      "Epoch 707/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.4674 - accuracy: 0.8297 - val_loss: 0.4704 - val_accuracy: 0.9153\n",
      "Epoch 708/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.4649 - accuracy: 0.8178 - val_loss: 0.4602 - val_accuracy: 0.9492\n",
      "Epoch 709/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.4632 - accuracy: 0.8376 - val_loss: 0.4794 - val_accuracy: 0.7797\n",
      "Epoch 710/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.4618 - accuracy: 0.8119 - val_loss: 0.4586 - val_accuracy: 0.9492\n",
      "Epoch 711/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.4581 - accuracy: 0.8297 - val_loss: 0.4711 - val_accuracy: 0.7797\n",
      "Epoch 712/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.4609 - accuracy: 0.8257 - val_loss: 0.4586 - val_accuracy: 0.9153\n",
      "Epoch 713/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.4591 - accuracy: 0.8218 - val_loss: 0.4575 - val_accuracy: 0.9153\n",
      "Epoch 714/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.4534 - accuracy: 0.8297 - val_loss: 0.4653 - val_accuracy: 0.8305\n",
      "Epoch 715/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.4516 - accuracy: 0.8337 - val_loss: 0.4671 - val_accuracy: 0.7797\n",
      "Epoch 716/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.4565 - accuracy: 0.8178 - val_loss: 0.4556 - val_accuracy: 0.8814\n",
      "Epoch 717/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 348us/step - loss: 0.4549 - accuracy: 0.8337 - val_loss: 0.4638 - val_accuracy: 0.7797\n",
      "Epoch 718/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.4458 - accuracy: 0.8277 - val_loss: 0.4545 - val_accuracy: 0.9153\n",
      "Epoch 719/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.4577 - accuracy: 0.8396 - val_loss: 0.4496 - val_accuracy: 0.9492\n",
      "Epoch 720/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.4524 - accuracy: 0.8099 - val_loss: 0.4483 - val_accuracy: 0.9492\n",
      "Epoch 721/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.4385 - accuracy: 0.8297 - val_loss: 0.4484 - val_accuracy: 0.9492\n",
      "Epoch 722/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.4541 - accuracy: 0.8218 - val_loss: 0.4698 - val_accuracy: 0.7797\n",
      "Epoch 723/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.4444 - accuracy: 0.8277 - val_loss: 0.4480 - val_accuracy: 0.9153\n",
      "Epoch 724/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.4512 - accuracy: 0.8297 - val_loss: 0.4496 - val_accuracy: 0.8305\n",
      "Epoch 725/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.4510 - accuracy: 0.8257 - val_loss: 0.4531 - val_accuracy: 0.8136\n",
      "Epoch 726/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.4383 - accuracy: 0.8218 - val_loss: 0.4434 - val_accuracy: 0.9492\n",
      "Epoch 727/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.4414 - accuracy: 0.8277 - val_loss: 0.4522 - val_accuracy: 0.8136\n",
      "Epoch 728/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.4387 - accuracy: 0.8356 - val_loss: 0.4456 - val_accuracy: 0.8983\n",
      "Epoch 729/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.4272 - accuracy: 0.8495 - val_loss: 0.4378 - val_accuracy: 0.9322\n",
      "Epoch 730/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.4316 - accuracy: 0.8554 - val_loss: 0.4449 - val_accuracy: 0.7797\n",
      "Epoch 731/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.4346 - accuracy: 0.8337 - val_loss: 0.4601 - val_accuracy: 0.7966\n",
      "Epoch 732/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.4285 - accuracy: 0.8416 - val_loss: 0.4468 - val_accuracy: 0.8983\n",
      "Epoch 733/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.4393 - accuracy: 0.8396 - val_loss: 0.4477 - val_accuracy: 0.7797\n",
      "Epoch 734/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.4326 - accuracy: 0.8376 - val_loss: 0.4341 - val_accuracy: 0.9492\n",
      "Epoch 735/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.4326 - accuracy: 0.8297 - val_loss: 0.4565 - val_accuracy: 0.7797\n",
      "Epoch 736/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.4334 - accuracy: 0.8356 - val_loss: 0.4280 - val_accuracy: 0.9492\n",
      "Epoch 737/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.4061 - accuracy: 0.8535 - val_loss: 0.4321 - val_accuracy: 0.9153\n",
      "Epoch 738/2000\n",
      "505/505 [==============================] - ETA: 0s - loss: 0.4205 - accuracy: 0.83 - 0s 354us/step - loss: 0.4296 - accuracy: 0.8317 - val_loss: 0.4318 - val_accuracy: 0.9153\n",
      "Epoch 739/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.4378 - accuracy: 0.8198 - val_loss: 0.4435 - val_accuracy: 0.7797\n",
      "Epoch 740/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.4525 - accuracy: 0.8020 - val_loss: 0.4314 - val_accuracy: 0.9153\n",
      "Epoch 741/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.4272 - accuracy: 0.8475 - val_loss: 0.4263 - val_accuracy: 0.9492\n",
      "Epoch 742/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.4230 - accuracy: 0.8535 - val_loss: 0.4240 - val_accuracy: 0.9322\n",
      "Epoch 743/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.4275 - accuracy: 0.8317 - val_loss: 0.4203 - val_accuracy: 0.9492\n",
      "Epoch 744/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.4174 - accuracy: 0.8396 - val_loss: 0.4281 - val_accuracy: 0.7966\n",
      "Epoch 745/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.4226 - accuracy: 0.8297 - val_loss: 0.4187 - val_accuracy: 0.9322\n",
      "Epoch 746/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.4150 - accuracy: 0.8356 - val_loss: 0.4179 - val_accuracy: 0.9492\n",
      "Epoch 747/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.4223 - accuracy: 0.8535 - val_loss: 0.4215 - val_accuracy: 0.8814\n",
      "Epoch 748/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.4186 - accuracy: 0.8376 - val_loss: 0.4194 - val_accuracy: 0.9322\n",
      "Epoch 749/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.4210 - accuracy: 0.8257 - val_loss: 0.4164 - val_accuracy: 0.9322\n",
      "Epoch 750/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.4173 - accuracy: 0.8416 - val_loss: 0.4139 - val_accuracy: 0.9153\n",
      "Epoch 751/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.4292 - accuracy: 0.8218 - val_loss: 0.4110 - val_accuracy: 0.9492\n",
      "Epoch 752/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.4253 - accuracy: 0.8396 - val_loss: 0.4721 - val_accuracy: 0.8136\n",
      "Epoch 753/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.4314 - accuracy: 0.8238 - val_loss: 0.4111 - val_accuracy: 0.9492\n",
      "Epoch 754/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.4223 - accuracy: 0.8356 - val_loss: 0.4147 - val_accuracy: 0.9153\n",
      "Epoch 755/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.4321 - accuracy: 0.8119 - val_loss: 0.4081 - val_accuracy: 0.9492\n",
      "Epoch 756/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.4175 - accuracy: 0.8356 - val_loss: 0.4273 - val_accuracy: 0.7797\n",
      "Epoch 757/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.4102 - accuracy: 0.8356 - val_loss: 0.4064 - val_accuracy: 0.9492\n",
      "Epoch 758/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.4128 - accuracy: 0.8158 - val_loss: 0.4297 - val_accuracy: 0.7797\n",
      "Epoch 759/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.3945 - accuracy: 0.8416 - val_loss: 0.4008 - val_accuracy: 0.9492\n",
      "Epoch 760/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.4103 - accuracy: 0.8218 - val_loss: 0.3995 - val_accuracy: 0.9492\n",
      "Epoch 761/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.4082 - accuracy: 0.8376 - val_loss: 0.4041 - val_accuracy: 0.9153\n",
      "Epoch 762/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.4069 - accuracy: 0.8356 - val_loss: 0.4022 - val_accuracy: 0.8814\n",
      "Epoch 763/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.4195 - accuracy: 0.8238 - val_loss: 0.4146 - val_accuracy: 0.8136\n",
      "Epoch 764/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.4077 - accuracy: 0.8376 - val_loss: 0.4002 - val_accuracy: 0.9492\n",
      "Epoch 765/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.4087 - accuracy: 0.8257 - val_loss: 0.4323 - val_accuracy: 0.8305\n",
      "Epoch 766/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3962 - accuracy: 0.8495 - val_loss: 0.3963 - val_accuracy: 0.9492\n",
      "Epoch 767/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.4058 - accuracy: 0.8139 - val_loss: 0.4104 - val_accuracy: 0.7966\n",
      "Epoch 768/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.4083 - accuracy: 0.8178 - val_loss: 0.4021 - val_accuracy: 0.8136\n",
      "Epoch 769/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.4104 - accuracy: 0.8277 - val_loss: 0.4115 - val_accuracy: 0.8136\n",
      "Epoch 770/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.4015 - accuracy: 0.8356 - val_loss: 0.3912 - val_accuracy: 0.9322\n",
      "Epoch 771/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.4047 - accuracy: 0.8356 - val_loss: 0.4020 - val_accuracy: 0.8136\n",
      "Epoch 772/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 352us/step - loss: 0.3956 - accuracy: 0.8396 - val_loss: 0.3954 - val_accuracy: 0.9153\n",
      "Epoch 773/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.3968 - accuracy: 0.8376 - val_loss: 0.4023 - val_accuracy: 0.8136\n",
      "Epoch 774/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.3997 - accuracy: 0.8396 - val_loss: 0.3877 - val_accuracy: 0.9153\n",
      "Epoch 775/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.3979 - accuracy: 0.8416 - val_loss: 0.3932 - val_accuracy: 0.8644\n",
      "Epoch 776/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.3916 - accuracy: 0.8337 - val_loss: 0.4120 - val_accuracy: 0.7797\n",
      "Epoch 777/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.3936 - accuracy: 0.8436 - val_loss: 0.3883 - val_accuracy: 0.9153\n",
      "Epoch 778/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.3976 - accuracy: 0.8416 - val_loss: 0.3850 - val_accuracy: 0.9153\n",
      "Epoch 779/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.4069 - accuracy: 0.8317 - val_loss: 0.3841 - val_accuracy: 0.9492\n",
      "Epoch 780/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.3978 - accuracy: 0.8257 - val_loss: 0.3843 - val_accuracy: 0.9322\n",
      "Epoch 781/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3935 - accuracy: 0.8356 - val_loss: 0.4001 - val_accuracy: 0.8136\n",
      "Epoch 782/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.3804 - accuracy: 0.8475 - val_loss: 0.3934 - val_accuracy: 0.7966\n",
      "Epoch 783/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.3861 - accuracy: 0.8495 - val_loss: 0.3888 - val_accuracy: 0.8983\n",
      "Epoch 784/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.3805 - accuracy: 0.8535 - val_loss: 0.3808 - val_accuracy: 0.9492\n",
      "Epoch 785/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.3945 - accuracy: 0.8297 - val_loss: 0.3785 - val_accuracy: 0.9322\n",
      "Epoch 786/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.3961 - accuracy: 0.8277 - val_loss: 0.4144 - val_accuracy: 0.7966\n",
      "Epoch 787/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.3992 - accuracy: 0.8198 - val_loss: 0.3805 - val_accuracy: 0.9322\n",
      "Epoch 788/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.3851 - accuracy: 0.8416 - val_loss: 0.3882 - val_accuracy: 0.8136\n",
      "Epoch 789/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3739 - accuracy: 0.8515 - val_loss: 0.4055 - val_accuracy: 0.8136\n",
      "Epoch 790/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.3899 - accuracy: 0.8416 - val_loss: 0.3739 - val_accuracy: 0.9492\n",
      "Epoch 791/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3902 - accuracy: 0.8337 - val_loss: 0.3967 - val_accuracy: 0.8136\n",
      "Epoch 792/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.3803 - accuracy: 0.8416 - val_loss: 0.3708 - val_accuracy: 0.9492\n",
      "Epoch 793/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.3814 - accuracy: 0.8436 - val_loss: 0.3698 - val_accuracy: 0.9322\n",
      "Epoch 794/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3773 - accuracy: 0.8515 - val_loss: 0.3725 - val_accuracy: 0.9492\n",
      "Epoch 795/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.3869 - accuracy: 0.8515 - val_loss: 0.3672 - val_accuracy: 0.9492\n",
      "Epoch 796/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.3728 - accuracy: 0.8396 - val_loss: 0.3811 - val_accuracy: 0.9153\n",
      "Epoch 797/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.3809 - accuracy: 0.8317 - val_loss: 0.3693 - val_accuracy: 0.9492\n",
      "Epoch 798/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.3978 - accuracy: 0.8139 - val_loss: 0.3991 - val_accuracy: 0.7797\n",
      "Epoch 799/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.3849 - accuracy: 0.8356 - val_loss: 0.3897 - val_accuracy: 0.7966\n",
      "Epoch 800/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.3836 - accuracy: 0.8356 - val_loss: 0.3755 - val_accuracy: 0.8305\n",
      "Epoch 801/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.3816 - accuracy: 0.8376 - val_loss: 0.3621 - val_accuracy: 0.9492\n",
      "Epoch 802/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.3890 - accuracy: 0.8158 - val_loss: 0.3763 - val_accuracy: 0.8983\n",
      "Epoch 803/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.3751 - accuracy: 0.8535 - val_loss: 0.3569 - val_accuracy: 0.9492\n",
      "Epoch 804/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.3803 - accuracy: 0.8317 - val_loss: 0.3624 - val_accuracy: 0.8644\n",
      "Epoch 805/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3595 - accuracy: 0.8574 - val_loss: 0.3763 - val_accuracy: 0.8136\n",
      "Epoch 806/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.3878 - accuracy: 0.8317 - val_loss: 0.3592 - val_accuracy: 0.9153\n",
      "Epoch 807/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.3714 - accuracy: 0.8317 - val_loss: 0.3619 - val_accuracy: 0.9153\n",
      "Epoch 808/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3634 - accuracy: 0.8653 - val_loss: 0.3657 - val_accuracy: 0.9153\n",
      "Epoch 809/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.3686 - accuracy: 0.8356 - val_loss: 0.3779 - val_accuracy: 0.8136\n",
      "Epoch 810/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.3795 - accuracy: 0.8277 - val_loss: 0.3522 - val_accuracy: 0.9492\n",
      "Epoch 811/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.3737 - accuracy: 0.8317 - val_loss: 0.3559 - val_accuracy: 0.9492\n",
      "Epoch 812/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.3742 - accuracy: 0.8257 - val_loss: 0.3488 - val_accuracy: 0.9322\n",
      "Epoch 813/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3611 - accuracy: 0.8475 - val_loss: 0.3576 - val_accuracy: 0.9153\n",
      "Epoch 814/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.3705 - accuracy: 0.8455 - val_loss: 0.3495 - val_accuracy: 0.9492\n",
      "Epoch 815/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.3664 - accuracy: 0.8416 - val_loss: 0.3459 - val_accuracy: 0.9492\n",
      "Epoch 816/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.3715 - accuracy: 0.8297 - val_loss: 0.3441 - val_accuracy: 0.9322\n",
      "Epoch 817/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.3732 - accuracy: 0.8436 - val_loss: 0.3503 - val_accuracy: 0.9322\n",
      "Epoch 818/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.3648 - accuracy: 0.8356 - val_loss: 0.3470 - val_accuracy: 0.9492\n",
      "Epoch 819/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3678 - accuracy: 0.8317 - val_loss: 0.3434 - val_accuracy: 0.9492\n",
      "Epoch 820/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.3610 - accuracy: 0.8495 - val_loss: 0.3531 - val_accuracy: 0.9153\n",
      "Epoch 821/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.3626 - accuracy: 0.8376 - val_loss: 0.3421 - val_accuracy: 0.9492\n",
      "Epoch 822/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.3589 - accuracy: 0.8614 - val_loss: 0.3461 - val_accuracy: 0.9153\n",
      "Epoch 823/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.3664 - accuracy: 0.8317 - val_loss: 0.3460 - val_accuracy: 0.9153\n",
      "Epoch 824/2000\n",
      "505/505 [==============================] - ETA: 0s - loss: 0.3696 - accuracy: 0.84 - 0s 342us/step - loss: 0.3564 - accuracy: 0.8515 - val_loss: 0.3390 - val_accuracy: 0.9492\n",
      "Epoch 825/2000\n",
      "505/505 [==============================] - ETA: 0s - loss: 0.3681 - accuracy: 0.83 - 0s 338us/step - loss: 0.3534 - accuracy: 0.8376 - val_loss: 0.3394 - val_accuracy: 0.9153\n",
      "Epoch 826/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3665 - accuracy: 0.8238 - val_loss: 0.3567 - val_accuracy: 0.7966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 827/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.3664 - accuracy: 0.8356 - val_loss: 0.3413 - val_accuracy: 0.8983\n",
      "Epoch 828/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.3699 - accuracy: 0.8396 - val_loss: 0.3402 - val_accuracy: 0.9153\n",
      "Epoch 829/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3762 - accuracy: 0.8238 - val_loss: 0.3804 - val_accuracy: 0.8136\n",
      "Epoch 830/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3495 - accuracy: 0.8495 - val_loss: 0.3950 - val_accuracy: 0.7966\n",
      "Epoch 831/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.3473 - accuracy: 0.8733 - val_loss: 0.3381 - val_accuracy: 0.9492\n",
      "Epoch 832/2000\n",
      "505/505 [==============================] - 0s 405us/step - loss: 0.3586 - accuracy: 0.8356 - val_loss: 0.3323 - val_accuracy: 0.9492\n",
      "Epoch 833/2000\n",
      "505/505 [==============================] - 0s 407us/step - loss: 0.3671 - accuracy: 0.8158 - val_loss: 0.3335 - val_accuracy: 0.9322\n",
      "Epoch 834/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.3538 - accuracy: 0.8634 - val_loss: 0.3373 - val_accuracy: 0.9153\n",
      "Epoch 835/2000\n",
      "505/505 [==============================] - 0s 409us/step - loss: 0.3554 - accuracy: 0.8238 - val_loss: 0.3729 - val_accuracy: 0.7797\n",
      "Epoch 836/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.3388 - accuracy: 0.8554 - val_loss: 0.3335 - val_accuracy: 0.9153\n",
      "Epoch 837/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.3458 - accuracy: 0.8436 - val_loss: 0.3295 - val_accuracy: 0.9492\n",
      "Epoch 838/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.3486 - accuracy: 0.8495 - val_loss: 0.3432 - val_accuracy: 0.8644\n",
      "Epoch 839/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.3550 - accuracy: 0.8356 - val_loss: 0.3337 - val_accuracy: 0.9153\n",
      "Epoch 840/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3701 - accuracy: 0.8376 - val_loss: 0.3535 - val_accuracy: 0.7797\n",
      "Epoch 841/2000\n",
      "505/505 [==============================] - 0s 387us/step - loss: 0.3631 - accuracy: 0.8158 - val_loss: 0.3875 - val_accuracy: 0.8136\n",
      "Epoch 842/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.3597 - accuracy: 0.8396 - val_loss: 0.3432 - val_accuracy: 0.8305\n",
      "Epoch 843/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.3383 - accuracy: 0.8535 - val_loss: 0.3270 - val_accuracy: 0.9492\n",
      "Epoch 844/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.3500 - accuracy: 0.8416 - val_loss: 0.3276 - val_accuracy: 0.9492\n",
      "Epoch 845/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.3453 - accuracy: 0.8277 - val_loss: 0.3462 - val_accuracy: 0.8136\n",
      "Epoch 846/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.3439 - accuracy: 0.8455 - val_loss: 0.3347 - val_accuracy: 0.9153\n",
      "Epoch 847/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.3478 - accuracy: 0.8475 - val_loss: 0.3621 - val_accuracy: 0.7966\n",
      "Epoch 848/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.3523 - accuracy: 0.8337 - val_loss: 0.3197 - val_accuracy: 0.9492\n",
      "Epoch 849/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.3649 - accuracy: 0.8178 - val_loss: 0.3546 - val_accuracy: 0.7966\n",
      "Epoch 850/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.3508 - accuracy: 0.8416 - val_loss: 0.3222 - val_accuracy: 0.9153\n",
      "Epoch 851/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.3507 - accuracy: 0.8436 - val_loss: 0.3153 - val_accuracy: 0.9322\n",
      "Epoch 852/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.3513 - accuracy: 0.8337 - val_loss: 0.3322 - val_accuracy: 0.8814\n",
      "Epoch 853/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.3511 - accuracy: 0.8376 - val_loss: 0.3201 - val_accuracy: 0.9492\n",
      "Epoch 854/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.3507 - accuracy: 0.8257 - val_loss: 0.3306 - val_accuracy: 0.8305\n",
      "Epoch 855/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.3397 - accuracy: 0.8436 - val_loss: 0.3235 - val_accuracy: 0.9322\n",
      "Epoch 856/2000\n",
      "505/505 [==============================] - 0s 367us/step - loss: 0.3464 - accuracy: 0.8238 - val_loss: 0.3165 - val_accuracy: 0.9492\n",
      "Epoch 857/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.3377 - accuracy: 0.8554 - val_loss: 0.3206 - val_accuracy: 0.9492\n",
      "Epoch 858/2000\n",
      "505/505 [==============================] - 0s 381us/step - loss: 0.3483 - accuracy: 0.8277 - val_loss: 0.3778 - val_accuracy: 0.8136\n",
      "Epoch 859/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.3498 - accuracy: 0.8218 - val_loss: 0.3576 - val_accuracy: 0.7797\n",
      "Epoch 860/2000\n",
      "505/505 [==============================] - 0s 379us/step - loss: 0.3575 - accuracy: 0.8297 - val_loss: 0.3129 - val_accuracy: 0.9492\n",
      "Epoch 861/2000\n",
      "505/505 [==============================] - 0s 405us/step - loss: 0.3316 - accuracy: 0.8574 - val_loss: 0.3369 - val_accuracy: 0.8136\n",
      "Epoch 862/2000\n",
      "505/505 [==============================] - 0s 387us/step - loss: 0.3395 - accuracy: 0.8416 - val_loss: 0.3082 - val_accuracy: 0.9492\n",
      "Epoch 863/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.3554 - accuracy: 0.8198 - val_loss: 0.3812 - val_accuracy: 0.7797\n",
      "Epoch 864/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.3219 - accuracy: 0.8673 - val_loss: 0.3376 - val_accuracy: 0.7966\n",
      "Epoch 865/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.3488 - accuracy: 0.8238 - val_loss: 0.3107 - val_accuracy: 0.9322\n",
      "Epoch 866/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.3466 - accuracy: 0.8277 - val_loss: 0.3135 - val_accuracy: 0.9492\n",
      "Epoch 867/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3469 - accuracy: 0.8297 - val_loss: 0.3080 - val_accuracy: 0.9492\n",
      "Epoch 868/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.3249 - accuracy: 0.8594 - val_loss: 0.3067 - val_accuracy: 0.9492\n",
      "Epoch 869/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3372 - accuracy: 0.8376 - val_loss: 0.3415 - val_accuracy: 0.8136\n",
      "Epoch 870/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3338 - accuracy: 0.8416 - val_loss: 0.3078 - val_accuracy: 0.9492\n",
      "Epoch 871/2000\n",
      "505/505 [==============================] - 0s 371us/step - loss: 0.3364 - accuracy: 0.8554 - val_loss: 0.3067 - val_accuracy: 0.9153\n",
      "Epoch 872/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.3396 - accuracy: 0.8495 - val_loss: 0.3151 - val_accuracy: 0.9322\n",
      "Epoch 873/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.3273 - accuracy: 0.8614 - val_loss: 0.3144 - val_accuracy: 0.9153\n",
      "Epoch 874/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.3442 - accuracy: 0.8396 - val_loss: 0.3075 - val_accuracy: 0.9153\n",
      "Epoch 875/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.3250 - accuracy: 0.8574 - val_loss: 0.4681 - val_accuracy: 0.7797\n",
      "Epoch 876/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.3487 - accuracy: 0.8416 - val_loss: 0.3153 - val_accuracy: 0.9153\n",
      "Epoch 877/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3335 - accuracy: 0.8574 - val_loss: 0.3194 - val_accuracy: 0.8983\n",
      "Epoch 878/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3373 - accuracy: 0.8416 - val_loss: 0.3043 - val_accuracy: 0.9492\n",
      "Epoch 879/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3344 - accuracy: 0.8436 - val_loss: 0.3375 - val_accuracy: 0.8136\n",
      "Epoch 880/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3378 - accuracy: 0.8495 - val_loss: 0.3089 - val_accuracy: 0.9153\n",
      "Epoch 881/2000\n",
      "505/505 [==============================] - 0s 383us/step - loss: 0.3325 - accuracy: 0.8436 - val_loss: 0.3132 - val_accuracy: 0.9153\n",
      "Epoch 882/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 346us/step - loss: 0.3396 - accuracy: 0.8356 - val_loss: 0.3414 - val_accuracy: 0.7797\n",
      "Epoch 883/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.3231 - accuracy: 0.8515 - val_loss: 0.3021 - val_accuracy: 0.9153\n",
      "Epoch 884/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.3329 - accuracy: 0.8475 - val_loss: 0.2996 - val_accuracy: 0.9492\n",
      "Epoch 885/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3372 - accuracy: 0.8317 - val_loss: 0.3051 - val_accuracy: 0.9322\n",
      "Epoch 886/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.3200 - accuracy: 0.8535 - val_loss: 0.2982 - val_accuracy: 0.9492\n",
      "Epoch 887/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.3283 - accuracy: 0.8535 - val_loss: 0.3251 - val_accuracy: 0.8136\n",
      "Epoch 888/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3287 - accuracy: 0.8535 - val_loss: 0.3756 - val_accuracy: 0.7966\n",
      "Epoch 889/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3505 - accuracy: 0.8455 - val_loss: 0.3038 - val_accuracy: 0.9322\n",
      "Epoch 890/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.3226 - accuracy: 0.8574 - val_loss: 0.3149 - val_accuracy: 0.8475\n",
      "Epoch 891/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.3152 - accuracy: 0.8495 - val_loss: 0.3763 - val_accuracy: 0.7797\n",
      "Epoch 892/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.3305 - accuracy: 0.8436 - val_loss: 0.2975 - val_accuracy: 0.9322\n",
      "Epoch 893/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.3392 - accuracy: 0.8297 - val_loss: 0.3186 - val_accuracy: 0.8644\n",
      "Epoch 894/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3255 - accuracy: 0.8416 - val_loss: 0.2931 - val_accuracy: 0.9492\n",
      "Epoch 895/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3265 - accuracy: 0.8475 - val_loss: 0.2886 - val_accuracy: 0.9322\n",
      "Epoch 896/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.3319 - accuracy: 0.8436 - val_loss: 0.3158 - val_accuracy: 0.8305\n",
      "Epoch 897/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.3298 - accuracy: 0.8455 - val_loss: 0.2888 - val_accuracy: 0.9492\n",
      "Epoch 898/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.3234 - accuracy: 0.8396 - val_loss: 0.3051 - val_accuracy: 0.8814\n",
      "Epoch 899/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3329 - accuracy: 0.8356 - val_loss: 0.3056 - val_accuracy: 0.8814\n",
      "Epoch 900/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3277 - accuracy: 0.8574 - val_loss: 0.3520 - val_accuracy: 0.7966\n",
      "Epoch 901/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3260 - accuracy: 0.8535 - val_loss: 0.2947 - val_accuracy: 0.9322\n",
      "Epoch 902/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.3215 - accuracy: 0.8594 - val_loss: 0.4028 - val_accuracy: 0.7797\n",
      "Epoch 903/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.3313 - accuracy: 0.8337 - val_loss: 0.3058 - val_accuracy: 0.8644\n",
      "Epoch 904/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.3209 - accuracy: 0.8356 - val_loss: 0.3794 - val_accuracy: 0.8136\n",
      "Epoch 905/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.3298 - accuracy: 0.8218 - val_loss: 0.3428 - val_accuracy: 0.8136\n",
      "Epoch 906/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.3238 - accuracy: 0.8356 - val_loss: 0.3049 - val_accuracy: 0.8814\n",
      "Epoch 907/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3179 - accuracy: 0.8574 - val_loss: 0.3292 - val_accuracy: 0.8136\n",
      "Epoch 908/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3205 - accuracy: 0.8455 - val_loss: 0.3555 - val_accuracy: 0.8136\n",
      "Epoch 909/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.3290 - accuracy: 0.8277 - val_loss: 0.2800 - val_accuracy: 0.9492\n",
      "Epoch 910/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.3345 - accuracy: 0.8257 - val_loss: 0.2894 - val_accuracy: 0.9492\n",
      "Epoch 911/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.3332 - accuracy: 0.8297 - val_loss: 0.2849 - val_accuracy: 0.9492\n",
      "Epoch 912/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3184 - accuracy: 0.8455 - val_loss: 0.2827 - val_accuracy: 0.9492\n",
      "Epoch 913/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3094 - accuracy: 0.8653 - val_loss: 0.2828 - val_accuracy: 0.9492\n",
      "Epoch 914/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.3215 - accuracy: 0.8495 - val_loss: 0.3660 - val_accuracy: 0.8136\n",
      "Epoch 915/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3134 - accuracy: 0.8574 - val_loss: 0.2756 - val_accuracy: 0.9322\n",
      "Epoch 916/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3266 - accuracy: 0.8376 - val_loss: 0.3687 - val_accuracy: 0.8136\n",
      "Epoch 917/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.3415 - accuracy: 0.8178 - val_loss: 0.3026 - val_accuracy: 0.8814\n",
      "Epoch 918/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3031 - accuracy: 0.8574 - val_loss: 0.2882 - val_accuracy: 0.9492\n",
      "Epoch 919/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.3134 - accuracy: 0.8495 - val_loss: 0.2883 - val_accuracy: 0.9322\n",
      "Epoch 920/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.3131 - accuracy: 0.8475 - val_loss: 0.3000 - val_accuracy: 0.8305\n",
      "Epoch 921/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.3300 - accuracy: 0.8099 - val_loss: 0.2879 - val_accuracy: 0.9322\n",
      "Epoch 922/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3220 - accuracy: 0.8436 - val_loss: 0.3240 - val_accuracy: 0.7797\n",
      "Epoch 923/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.3086 - accuracy: 0.8515 - val_loss: 0.2887 - val_accuracy: 0.9153\n",
      "Epoch 924/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.3160 - accuracy: 0.8495 - val_loss: 0.2744 - val_accuracy: 0.9322\n",
      "Epoch 925/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.3355 - accuracy: 0.8337 - val_loss: 0.2738 - val_accuracy: 0.9492\n",
      "Epoch 926/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.3068 - accuracy: 0.8455 - val_loss: 0.2801 - val_accuracy: 0.9322\n",
      "Epoch 927/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.3233 - accuracy: 0.8337 - val_loss: 0.2820 - val_accuracy: 0.9492\n",
      "Epoch 928/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.3152 - accuracy: 0.8356 - val_loss: 0.2900 - val_accuracy: 0.8983\n",
      "Epoch 929/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.3090 - accuracy: 0.8396 - val_loss: 0.2878 - val_accuracy: 0.9322\n",
      "Epoch 930/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.3050 - accuracy: 0.8515 - val_loss: 0.3209 - val_accuracy: 0.7966\n",
      "Epoch 931/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3179 - accuracy: 0.8376 - val_loss: 0.2700 - val_accuracy: 0.9492\n",
      "Epoch 932/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3215 - accuracy: 0.8218 - val_loss: 0.2712 - val_accuracy: 0.9492\n",
      "Epoch 933/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.3092 - accuracy: 0.8376 - val_loss: 0.2711 - val_accuracy: 0.9492\n",
      "Epoch 934/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.3292 - accuracy: 0.8317 - val_loss: 0.2759 - val_accuracy: 0.9322\n",
      "Epoch 935/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3210 - accuracy: 0.8594 - val_loss: 0.2699 - val_accuracy: 0.9322\n",
      "Epoch 936/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.3193 - accuracy: 0.8475 - val_loss: 0.2754 - val_accuracy: 0.9492\n",
      "Epoch 937/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 340us/step - loss: 0.3131 - accuracy: 0.8475 - val_loss: 0.2689 - val_accuracy: 0.9322\n",
      "Epoch 938/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3257 - accuracy: 0.8297 - val_loss: 0.2763 - val_accuracy: 0.9492\n",
      "Epoch 939/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.3077 - accuracy: 0.8396 - val_loss: 0.3663 - val_accuracy: 0.8136\n",
      "Epoch 940/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.3291 - accuracy: 0.8119 - val_loss: 0.2694 - val_accuracy: 0.9322\n",
      "Epoch 941/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.3135 - accuracy: 0.8356 - val_loss: 0.3129 - val_accuracy: 0.8136\n",
      "Epoch 942/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.3118 - accuracy: 0.8297 - val_loss: 0.2879 - val_accuracy: 0.8983\n",
      "Epoch 943/2000\n",
      "505/505 [==============================] - 0s 373us/step - loss: 0.3118 - accuracy: 0.8455 - val_loss: 0.2890 - val_accuracy: 0.8644\n",
      "Epoch 944/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.3029 - accuracy: 0.8535 - val_loss: 0.3198 - val_accuracy: 0.8136\n",
      "Epoch 945/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.3123 - accuracy: 0.8515 - val_loss: 0.2666 - val_accuracy: 0.9322\n",
      "Epoch 946/2000\n",
      "505/505 [==============================] - 0s 405us/step - loss: 0.3179 - accuracy: 0.8297 - val_loss: 0.2634 - val_accuracy: 0.9492\n",
      "Epoch 947/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.3174 - accuracy: 0.8277 - val_loss: 0.3197 - val_accuracy: 0.8136\n",
      "Epoch 948/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.3115 - accuracy: 0.8495 - val_loss: 0.2619 - val_accuracy: 0.9492\n",
      "Epoch 949/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3131 - accuracy: 0.8396 - val_loss: 0.2633 - val_accuracy: 0.9322\n",
      "Epoch 950/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.3057 - accuracy: 0.8475 - val_loss: 0.2645 - val_accuracy: 0.9492\n",
      "Epoch 951/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2940 - accuracy: 0.8772 - val_loss: 0.2693 - val_accuracy: 0.9492\n",
      "Epoch 952/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.3093 - accuracy: 0.8614 - val_loss: 0.2665 - val_accuracy: 0.9153\n",
      "Epoch 953/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.3046 - accuracy: 0.8535 - val_loss: 0.2793 - val_accuracy: 0.8983\n",
      "Epoch 954/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.3012 - accuracy: 0.8495 - val_loss: 0.3060 - val_accuracy: 0.8136\n",
      "Epoch 955/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.3016 - accuracy: 0.8416 - val_loss: 0.2672 - val_accuracy: 0.9492\n",
      "Epoch 956/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.3250 - accuracy: 0.8277 - val_loss: 0.2946 - val_accuracy: 0.7966\n",
      "Epoch 957/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.3103 - accuracy: 0.8455 - val_loss: 0.2711 - val_accuracy: 0.9322\n",
      "Epoch 958/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.3002 - accuracy: 0.8554 - val_loss: 0.2588 - val_accuracy: 0.9492\n",
      "Epoch 959/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.3092 - accuracy: 0.8356 - val_loss: 0.2792 - val_accuracy: 0.9322\n",
      "Epoch 960/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2962 - accuracy: 0.8535 - val_loss: 0.2777 - val_accuracy: 0.9153\n",
      "Epoch 961/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.3067 - accuracy: 0.8515 - val_loss: 0.2994 - val_accuracy: 0.7797\n",
      "Epoch 962/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3151 - accuracy: 0.8376 - val_loss: 0.3136 - val_accuracy: 0.7966\n",
      "Epoch 963/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.3120 - accuracy: 0.8376 - val_loss: 0.3307 - val_accuracy: 0.8136\n",
      "Epoch 964/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3018 - accuracy: 0.8376 - val_loss: 0.2562 - val_accuracy: 0.9492\n",
      "Epoch 965/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3013 - accuracy: 0.8614 - val_loss: 0.2713 - val_accuracy: 0.9492\n",
      "Epoch 966/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.3020 - accuracy: 0.8554 - val_loss: 0.2721 - val_accuracy: 0.9153\n",
      "Epoch 967/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.3024 - accuracy: 0.8574 - val_loss: 0.2547 - val_accuracy: 0.9153\n",
      "Epoch 968/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3020 - accuracy: 0.8495 - val_loss: 0.2534 - val_accuracy: 0.9153\n",
      "Epoch 969/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.3061 - accuracy: 0.8416 - val_loss: 0.3238 - val_accuracy: 0.7797\n",
      "Epoch 970/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2977 - accuracy: 0.8436 - val_loss: 0.2555 - val_accuracy: 0.9322\n",
      "Epoch 971/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.3120 - accuracy: 0.8317 - val_loss: 0.2770 - val_accuracy: 0.8644\n",
      "Epoch 972/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.3014 - accuracy: 0.8376 - val_loss: 0.2628 - val_accuracy: 0.9153\n",
      "Epoch 973/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3028 - accuracy: 0.8396 - val_loss: 0.2472 - val_accuracy: 0.9322\n",
      "Epoch 974/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3145 - accuracy: 0.8277 - val_loss: 0.3519 - val_accuracy: 0.8136\n",
      "Epoch 975/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.3095 - accuracy: 0.8277 - val_loss: 0.2631 - val_accuracy: 0.9153\n",
      "Epoch 976/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2976 - accuracy: 0.8515 - val_loss: 0.2571 - val_accuracy: 0.9492\n",
      "Epoch 977/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.2996 - accuracy: 0.8455 - val_loss: 0.2487 - val_accuracy: 0.9492\n",
      "Epoch 978/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2937 - accuracy: 0.8475 - val_loss: 0.2500 - val_accuracy: 0.9153\n",
      "Epoch 979/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.3038 - accuracy: 0.8535 - val_loss: 0.2800 - val_accuracy: 0.8475\n",
      "Epoch 980/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2978 - accuracy: 0.8535 - val_loss: 0.2970 - val_accuracy: 0.7966\n",
      "Epoch 981/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.3024 - accuracy: 0.8396 - val_loss: 0.2402 - val_accuracy: 0.9492\n",
      "Epoch 982/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.3023 - accuracy: 0.8356 - val_loss: 0.2474 - val_accuracy: 0.9492\n",
      "Epoch 983/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2951 - accuracy: 0.8455 - val_loss: 0.2579 - val_accuracy: 0.9322\n",
      "Epoch 984/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.2940 - accuracy: 0.8515 - val_loss: 0.2418 - val_accuracy: 0.9492\n",
      "Epoch 985/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.3075 - accuracy: 0.8515 - val_loss: 0.2837 - val_accuracy: 0.8305\n",
      "Epoch 986/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3046 - accuracy: 0.8436 - val_loss: 0.2601 - val_accuracy: 0.9322\n",
      "Epoch 987/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.3033 - accuracy: 0.8416 - val_loss: 0.2771 - val_accuracy: 0.8475\n",
      "Epoch 988/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2996 - accuracy: 0.8257 - val_loss: 0.2426 - val_accuracy: 0.9492\n",
      "Epoch 989/2000\n",
      "505/505 [==============================] - 0s 379us/step - loss: 0.2996 - accuracy: 0.8455 - val_loss: 0.2443 - val_accuracy: 0.9492\n",
      "Epoch 990/2000\n",
      "505/505 [==============================] - 0s 393us/step - loss: 0.3026 - accuracy: 0.8376 - val_loss: 0.2419 - val_accuracy: 0.9492\n",
      "Epoch 991/2000\n",
      "505/505 [==============================] - 0s 367us/step - loss: 0.2929 - accuracy: 0.8574 - val_loss: 0.2443 - val_accuracy: 0.9492\n",
      "Epoch 992/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 354us/step - loss: 0.2946 - accuracy: 0.8515 - val_loss: 0.2644 - val_accuracy: 0.8983\n",
      "Epoch 993/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.2998 - accuracy: 0.8554 - val_loss: 0.2914 - val_accuracy: 0.8136\n",
      "Epoch 994/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.2815 - accuracy: 0.8634 - val_loss: 0.3069 - val_accuracy: 0.8136\n",
      "Epoch 995/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2875 - accuracy: 0.8594 - val_loss: 0.2576 - val_accuracy: 0.8983\n",
      "Epoch 996/2000\n",
      "505/505 [==============================] - 0s 415us/step - loss: 0.2986 - accuracy: 0.8574 - val_loss: 0.2382 - val_accuracy: 0.9492\n",
      "Epoch 997/2000\n",
      "505/505 [==============================] - 0s 381us/step - loss: 0.2865 - accuracy: 0.8475 - val_loss: 0.2863 - val_accuracy: 0.8136\n",
      "Epoch 998/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.3030 - accuracy: 0.8416 - val_loss: 0.2323 - val_accuracy: 0.9322\n",
      "Epoch 999/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2939 - accuracy: 0.8416 - val_loss: 0.2284 - val_accuracy: 0.9492\n",
      "Epoch 1000/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.3095 - accuracy: 0.8297 - val_loss: 0.3487 - val_accuracy: 0.8136\n",
      "Epoch 1001/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.3105 - accuracy: 0.8356 - val_loss: 0.2668 - val_accuracy: 0.9153\n",
      "Epoch 1002/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.2904 - accuracy: 0.8653 - val_loss: 0.2803 - val_accuracy: 0.8305\n",
      "Epoch 1003/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.3052 - accuracy: 0.8317 - val_loss: 0.2560 - val_accuracy: 0.9322\n",
      "Epoch 1004/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.3009 - accuracy: 0.8495 - val_loss: 0.2353 - val_accuracy: 0.9492\n",
      "Epoch 1005/2000\n",
      "505/505 [==============================] - 0s 375us/step - loss: 0.2929 - accuracy: 0.8554 - val_loss: 0.3074 - val_accuracy: 0.8136\n",
      "Epoch 1006/2000\n",
      "505/505 [==============================] - 0s 375us/step - loss: 0.3054 - accuracy: 0.8455 - val_loss: 0.3144 - val_accuracy: 0.7966\n",
      "Epoch 1007/2000\n",
      "505/505 [==============================] - 0s 367us/step - loss: 0.2984 - accuracy: 0.8416 - val_loss: 0.3663 - val_accuracy: 0.7966\n",
      "Epoch 1008/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.3064 - accuracy: 0.8337 - val_loss: 0.2418 - val_accuracy: 0.9322\n",
      "Epoch 1009/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2939 - accuracy: 0.8455 - val_loss: 0.2667 - val_accuracy: 0.8983\n",
      "Epoch 1010/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.2828 - accuracy: 0.8574 - val_loss: 0.2295 - val_accuracy: 0.9492\n",
      "Epoch 1011/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.3057 - accuracy: 0.8277 - val_loss: 0.2278 - val_accuracy: 0.9492\n",
      "Epoch 1012/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.2883 - accuracy: 0.8614 - val_loss: 0.2896 - val_accuracy: 0.8136\n",
      "Epoch 1013/2000\n",
      "505/505 [==============================] - 0s 385us/step - loss: 0.2956 - accuracy: 0.8495 - val_loss: 0.2453 - val_accuracy: 0.9831\n",
      "Epoch 1014/2000\n",
      "505/505 [==============================] - 0s 371us/step - loss: 0.3015 - accuracy: 0.8396 - val_loss: 0.2438 - val_accuracy: 0.9322\n",
      "Epoch 1015/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.2958 - accuracy: 0.8277 - val_loss: 0.2446 - val_accuracy: 0.9492\n",
      "Epoch 1016/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.2956 - accuracy: 0.8554 - val_loss: 0.2323 - val_accuracy: 0.9322\n",
      "Epoch 1017/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.3083 - accuracy: 0.8277 - val_loss: 0.2496 - val_accuracy: 0.9492\n",
      "Epoch 1018/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.2905 - accuracy: 0.8376 - val_loss: 0.2398 - val_accuracy: 0.9492\n",
      "Epoch 1019/2000\n",
      "505/505 [==============================] - 0s 381us/step - loss: 0.2941 - accuracy: 0.8614 - val_loss: 0.2476 - val_accuracy: 0.9492\n",
      "Epoch 1020/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.2861 - accuracy: 0.8356 - val_loss: 0.2507 - val_accuracy: 0.9492\n",
      "Epoch 1021/2000\n",
      "505/505 [==============================] - 0s 401us/step - loss: 0.2887 - accuracy: 0.8594 - val_loss: 0.2449 - val_accuracy: 0.9492\n",
      "Epoch 1022/2000\n",
      "505/505 [==============================] - 0s 434us/step - loss: 0.2938 - accuracy: 0.8455 - val_loss: 0.2425 - val_accuracy: 0.9322\n",
      "Epoch 1023/2000\n",
      "505/505 [==============================] - 0s 367us/step - loss: 0.2891 - accuracy: 0.8297 - val_loss: 0.2413 - val_accuracy: 0.9492\n",
      "Epoch 1024/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.3039 - accuracy: 0.8356 - val_loss: 0.2461 - val_accuracy: 0.9492\n",
      "Epoch 1025/2000\n",
      "505/505 [==============================] - 0s 379us/step - loss: 0.2937 - accuracy: 0.8317 - val_loss: 0.2445 - val_accuracy: 0.9492\n",
      "Epoch 1026/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.2890 - accuracy: 0.8535 - val_loss: 0.2440 - val_accuracy: 0.9492\n",
      "Epoch 1027/2000\n",
      "505/505 [==============================] - 0s 369us/step - loss: 0.3030 - accuracy: 0.8436 - val_loss: 0.2696 - val_accuracy: 0.8305\n",
      "Epoch 1028/2000\n",
      "505/505 [==============================] - 0s 371us/step - loss: 0.3007 - accuracy: 0.8455 - val_loss: 0.2379 - val_accuracy: 0.9322\n",
      "Epoch 1029/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.2979 - accuracy: 0.8396 - val_loss: 0.2455 - val_accuracy: 0.9492\n",
      "Epoch 1030/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.3038 - accuracy: 0.8337 - val_loss: 0.2456 - val_accuracy: 0.9492\n",
      "Epoch 1031/2000\n",
      "505/505 [==============================] - 0s 375us/step - loss: 0.2939 - accuracy: 0.8554 - val_loss: 0.2426 - val_accuracy: 0.9492\n",
      "Epoch 1032/2000\n",
      "505/505 [==============================] - 0s 385us/step - loss: 0.2960 - accuracy: 0.8356 - val_loss: 0.3379 - val_accuracy: 0.8136\n",
      "Epoch 1033/2000\n",
      "505/505 [==============================] - 0s 383us/step - loss: 0.3043 - accuracy: 0.8337 - val_loss: 0.2341 - val_accuracy: 0.9492\n",
      "Epoch 1034/2000\n",
      "505/505 [==============================] - 0s 373us/step - loss: 0.2992 - accuracy: 0.8257 - val_loss: 0.2587 - val_accuracy: 0.9153\n",
      "Epoch 1035/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.2923 - accuracy: 0.8317 - val_loss: 0.2421 - val_accuracy: 0.9492\n",
      "Epoch 1036/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.2901 - accuracy: 0.8594 - val_loss: 0.2592 - val_accuracy: 0.8814\n",
      "Epoch 1037/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.2832 - accuracy: 0.8574 - val_loss: 0.2624 - val_accuracy: 0.8305\n",
      "Epoch 1038/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.2911 - accuracy: 0.8515 - val_loss: 0.2356 - val_accuracy: 0.9492\n",
      "Epoch 1039/2000\n",
      "505/505 [==============================] - 0s 393us/step - loss: 0.2949 - accuracy: 0.8535 - val_loss: 0.2341 - val_accuracy: 0.9492\n",
      "Epoch 1040/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2919 - accuracy: 0.8475 - val_loss: 0.2322 - val_accuracy: 0.9492\n",
      "Epoch 1041/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.2909 - accuracy: 0.8317 - val_loss: 0.2367 - val_accuracy: 0.9153\n",
      "Epoch 1042/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.2924 - accuracy: 0.8475 - val_loss: 0.2338 - val_accuracy: 0.9492\n",
      "Epoch 1043/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2963 - accuracy: 0.8455 - val_loss: 0.2351 - val_accuracy: 0.9322\n",
      "Epoch 1044/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2901 - accuracy: 0.8594 - val_loss: 0.2957 - val_accuracy: 0.8136\n",
      "Epoch 1045/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2860 - accuracy: 0.8554 - val_loss: 0.2324 - val_accuracy: 0.9492\n",
      "Epoch 1046/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.3039 - accuracy: 0.8238 - val_loss: 0.2471 - val_accuracy: 0.9322\n",
      "Epoch 1047/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 354us/step - loss: 0.2928 - accuracy: 0.8455 - val_loss: 0.2350 - val_accuracy: 0.9492\n",
      "Epoch 1048/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2877 - accuracy: 0.8515 - val_loss: 0.2297 - val_accuracy: 0.9492\n",
      "Epoch 1049/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2928 - accuracy: 0.8337 - val_loss: 0.2422 - val_accuracy: 0.9492\n",
      "Epoch 1050/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2991 - accuracy: 0.8376 - val_loss: 0.2831 - val_accuracy: 0.8136\n",
      "Epoch 1051/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.2909 - accuracy: 0.8475 - val_loss: 0.2366 - val_accuracy: 0.9492\n",
      "Epoch 1052/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2862 - accuracy: 0.8436 - val_loss: 0.2867 - val_accuracy: 0.8136\n",
      "Epoch 1053/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.2919 - accuracy: 0.8376 - val_loss: 0.2316 - val_accuracy: 0.9153\n",
      "Epoch 1054/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2866 - accuracy: 0.8554 - val_loss: 0.2626 - val_accuracy: 0.8814\n",
      "Epoch 1055/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.3062 - accuracy: 0.8238 - val_loss: 0.2420 - val_accuracy: 0.9492\n",
      "Epoch 1056/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.2891 - accuracy: 0.8574 - val_loss: 0.2259 - val_accuracy: 0.9492\n",
      "Epoch 1057/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.2931 - accuracy: 0.8277 - val_loss: 0.2658 - val_accuracy: 0.8644\n",
      "Epoch 1058/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.2811 - accuracy: 0.8653 - val_loss: 0.2356 - val_accuracy: 0.9492\n",
      "Epoch 1059/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.3044 - accuracy: 0.8416 - val_loss: 0.2462 - val_accuracy: 0.9322\n",
      "Epoch 1060/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2811 - accuracy: 0.8574 - val_loss: 0.2478 - val_accuracy: 0.9153\n",
      "Epoch 1061/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.2858 - accuracy: 0.8455 - val_loss: 0.2624 - val_accuracy: 0.8814\n",
      "Epoch 1062/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.2882 - accuracy: 0.8515 - val_loss: 0.2309 - val_accuracy: 0.9492\n",
      "Epoch 1063/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.2969 - accuracy: 0.8436 - val_loss: 0.2542 - val_accuracy: 0.8814\n",
      "Epoch 1064/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2850 - accuracy: 0.8475 - val_loss: 0.2772 - val_accuracy: 0.8136\n",
      "Epoch 1065/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.2913 - accuracy: 0.8436 - val_loss: 0.2658 - val_accuracy: 0.8475\n",
      "Epoch 1066/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.2953 - accuracy: 0.8535 - val_loss: 0.2884 - val_accuracy: 0.7966\n",
      "Epoch 1067/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.2929 - accuracy: 0.8416 - val_loss: 0.2522 - val_accuracy: 0.8983\n",
      "Epoch 1068/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2711 - accuracy: 0.8792 - val_loss: 0.2392 - val_accuracy: 0.9322\n",
      "Epoch 1069/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.2905 - accuracy: 0.8376 - val_loss: 0.2547 - val_accuracy: 0.8983\n",
      "Epoch 1070/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.3040 - accuracy: 0.8238 - val_loss: 0.2256 - val_accuracy: 0.9492\n",
      "Epoch 1071/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2837 - accuracy: 0.8416 - val_loss: 0.2429 - val_accuracy: 0.9492\n",
      "Epoch 1072/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.2903 - accuracy: 0.8475 - val_loss: 0.2349 - val_accuracy: 0.9153\n",
      "Epoch 1073/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2890 - accuracy: 0.8475 - val_loss: 0.2244 - val_accuracy: 0.9322\n",
      "Epoch 1074/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2853 - accuracy: 0.8356 - val_loss: 0.2199 - val_accuracy: 0.9492\n",
      "Epoch 1075/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2861 - accuracy: 0.8594 - val_loss: 0.2196 - val_accuracy: 0.9322\n",
      "Epoch 1076/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.2924 - accuracy: 0.8574 - val_loss: 0.2238 - val_accuracy: 0.9492\n",
      "Epoch 1077/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.2849 - accuracy: 0.8475 - val_loss: 0.2332 - val_accuracy: 0.9322\n",
      "Epoch 1078/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.2750 - accuracy: 0.8515 - val_loss: 0.2219 - val_accuracy: 0.9492\n",
      "Epoch 1079/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.2866 - accuracy: 0.8297 - val_loss: 0.2222 - val_accuracy: 0.9492\n",
      "Epoch 1080/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.2851 - accuracy: 0.8416 - val_loss: 0.2468 - val_accuracy: 0.8983\n",
      "Epoch 1081/2000\n",
      "505/505 [==============================] - 0s 369us/step - loss: 0.2925 - accuracy: 0.8337 - val_loss: 0.2172 - val_accuracy: 0.9492\n",
      "Epoch 1082/2000\n",
      "505/505 [==============================] - 0s 381us/step - loss: 0.2911 - accuracy: 0.8337 - val_loss: 0.2443 - val_accuracy: 0.9492\n",
      "Epoch 1083/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.2829 - accuracy: 0.8515 - val_loss: 0.2755 - val_accuracy: 0.7966\n",
      "Epoch 1084/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.2805 - accuracy: 0.8515 - val_loss: 0.2152 - val_accuracy: 0.9492\n",
      "Epoch 1085/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.2816 - accuracy: 0.8535 - val_loss: 0.2229 - val_accuracy: 0.9492\n",
      "Epoch 1086/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2855 - accuracy: 0.8594 - val_loss: 0.2312 - val_accuracy: 0.9492\n",
      "Epoch 1087/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2828 - accuracy: 0.8495 - val_loss: 0.2183 - val_accuracy: 0.9492\n",
      "Epoch 1088/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2853 - accuracy: 0.8218 - val_loss: 0.2230 - val_accuracy: 0.9492\n",
      "Epoch 1089/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.2986 - accuracy: 0.8158 - val_loss: 0.3236 - val_accuracy: 0.7797\n",
      "Epoch 1090/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2861 - accuracy: 0.8356 - val_loss: 0.2190 - val_accuracy: 0.9492\n",
      "Epoch 1091/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2816 - accuracy: 0.8515 - val_loss: 0.2257 - val_accuracy: 0.9492\n",
      "Epoch 1092/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2930 - accuracy: 0.8257 - val_loss: 0.2331 - val_accuracy: 0.9153\n",
      "Epoch 1093/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2824 - accuracy: 0.8515 - val_loss: 0.2306 - val_accuracy: 0.9492\n",
      "Epoch 1094/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2849 - accuracy: 0.8515 - val_loss: 0.2496 - val_accuracy: 0.9153\n",
      "Epoch 1095/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.2911 - accuracy: 0.8337 - val_loss: 0.2499 - val_accuracy: 0.8814\n",
      "Epoch 1096/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.2963 - accuracy: 0.8297 - val_loss: 0.2203 - val_accuracy: 0.9492\n",
      "Epoch 1097/2000\n",
      "505/505 [==============================] - 0s 322us/step - loss: 0.2916 - accuracy: 0.8317 - val_loss: 0.2319 - val_accuracy: 0.9492\n",
      "Epoch 1098/2000\n",
      "505/505 [==============================] - 0s 318us/step - loss: 0.2822 - accuracy: 0.8475 - val_loss: 0.2231 - val_accuracy: 0.9492\n",
      "Epoch 1099/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.2745 - accuracy: 0.8554 - val_loss: 0.2275 - val_accuracy: 0.9492\n",
      "Epoch 1100/2000\n",
      "505/505 [==============================] - 0s 322us/step - loss: 0.2807 - accuracy: 0.8376 - val_loss: 0.2367 - val_accuracy: 0.9153\n",
      "Epoch 1101/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.2840 - accuracy: 0.8436 - val_loss: 0.2910 - val_accuracy: 0.8136\n",
      "Epoch 1102/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 328us/step - loss: 0.2974 - accuracy: 0.8396 - val_loss: 0.3149 - val_accuracy: 0.8136\n",
      "Epoch 1103/2000\n",
      "505/505 [==============================] - 0s 324us/step - loss: 0.2951 - accuracy: 0.8436 - val_loss: 0.2238 - val_accuracy: 0.9492\n",
      "Epoch 1104/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.2880 - accuracy: 0.8376 - val_loss: 0.2769 - val_accuracy: 0.8305\n",
      "Epoch 1105/2000\n",
      "505/505 [==============================] - 0s 322us/step - loss: 0.2901 - accuracy: 0.8594 - val_loss: 0.2211 - val_accuracy: 0.9492\n",
      "Epoch 1106/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.2832 - accuracy: 0.8495 - val_loss: 0.3405 - val_accuracy: 0.7797\n",
      "Epoch 1107/2000\n",
      "505/505 [==============================] - 0s 324us/step - loss: 0.2775 - accuracy: 0.8515 - val_loss: 0.2355 - val_accuracy: 0.9492\n",
      "Epoch 1108/2000\n",
      "505/505 [==============================] - 0s 322us/step - loss: 0.2782 - accuracy: 0.8495 - val_loss: 0.2490 - val_accuracy: 0.8983\n",
      "Epoch 1109/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.2770 - accuracy: 0.8495 - val_loss: 0.2359 - val_accuracy: 0.9492\n",
      "Epoch 1110/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.3072 - accuracy: 0.8218 - val_loss: 0.2259 - val_accuracy: 0.9492\n",
      "Epoch 1111/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.2815 - accuracy: 0.8535 - val_loss: 0.2507 - val_accuracy: 0.9153\n",
      "Epoch 1112/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.2923 - accuracy: 0.8376 - val_loss: 0.2288 - val_accuracy: 0.9492\n",
      "Epoch 1113/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.2958 - accuracy: 0.8416 - val_loss: 0.2566 - val_accuracy: 0.8644\n",
      "Epoch 1114/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.2956 - accuracy: 0.8317 - val_loss: 0.2544 - val_accuracy: 0.8983\n",
      "Epoch 1115/2000\n",
      "505/505 [==============================] - 0s 324us/step - loss: 0.2821 - accuracy: 0.8535 - val_loss: 0.2505 - val_accuracy: 0.8983\n",
      "Epoch 1116/2000\n",
      "505/505 [==============================] - 0s 322us/step - loss: 0.2849 - accuracy: 0.8475 - val_loss: 0.2389 - val_accuracy: 0.9492\n",
      "Epoch 1117/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.2863 - accuracy: 0.8436 - val_loss: 0.2314 - val_accuracy: 0.9492\n",
      "Epoch 1118/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2815 - accuracy: 0.8594 - val_loss: 0.2343 - val_accuracy: 0.9492\n",
      "Epoch 1119/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.2864 - accuracy: 0.8396 - val_loss: 0.2467 - val_accuracy: 0.9831\n",
      "Epoch 1120/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.2915 - accuracy: 0.8356 - val_loss: 0.2275 - val_accuracy: 0.9492\n",
      "Epoch 1121/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2758 - accuracy: 0.8574 - val_loss: 0.2732 - val_accuracy: 0.8136\n",
      "Epoch 1122/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2905 - accuracy: 0.8337 - val_loss: 0.2381 - val_accuracy: 0.9492\n",
      "Epoch 1123/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.2841 - accuracy: 0.8455 - val_loss: 0.2309 - val_accuracy: 0.9492\n",
      "Epoch 1124/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2784 - accuracy: 0.8614 - val_loss: 0.2292 - val_accuracy: 0.9322\n",
      "Epoch 1125/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.2739 - accuracy: 0.8436 - val_loss: 0.2293 - val_accuracy: 0.9492\n",
      "Epoch 1126/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.2872 - accuracy: 0.8455 - val_loss: 0.2396 - val_accuracy: 0.9492\n",
      "Epoch 1127/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2783 - accuracy: 0.8535 - val_loss: 0.2667 - val_accuracy: 0.8136\n",
      "Epoch 1128/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.3035 - accuracy: 0.8337 - val_loss: 0.2305 - val_accuracy: 0.9492\n",
      "Epoch 1129/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2861 - accuracy: 0.8416 - val_loss: 0.2363 - val_accuracy: 0.9492\n",
      "Epoch 1130/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.2751 - accuracy: 0.8653 - val_loss: 0.2592 - val_accuracy: 0.8475\n",
      "Epoch 1131/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2881 - accuracy: 0.8356 - val_loss: 0.2581 - val_accuracy: 0.8814\n",
      "Epoch 1132/2000\n",
      "505/505 [==============================] - 0s 318us/step - loss: 0.2894 - accuracy: 0.8257 - val_loss: 0.2291 - val_accuracy: 0.9492\n",
      "Epoch 1133/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2832 - accuracy: 0.8396 - val_loss: 0.2514 - val_accuracy: 0.8983\n",
      "Epoch 1134/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.2815 - accuracy: 0.8475 - val_loss: 0.2211 - val_accuracy: 0.9492\n",
      "Epoch 1135/2000\n",
      "505/505 [==============================] - 0s 314us/step - loss: 0.2875 - accuracy: 0.8238 - val_loss: 0.2270 - val_accuracy: 0.9492\n",
      "Epoch 1136/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.2970 - accuracy: 0.8317 - val_loss: 0.2830 - val_accuracy: 0.8136\n",
      "Epoch 1137/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2900 - accuracy: 0.8436 - val_loss: 0.2322 - val_accuracy: 0.9492\n",
      "Epoch 1138/2000\n",
      "505/505 [==============================] - 0s 312us/step - loss: 0.2758 - accuracy: 0.8614 - val_loss: 0.2619 - val_accuracy: 0.8136\n",
      "Epoch 1139/2000\n",
      "505/505 [==============================] - 0s 312us/step - loss: 0.2806 - accuracy: 0.8396 - val_loss: 0.2511 - val_accuracy: 0.9153\n",
      "Epoch 1140/2000\n",
      "505/505 [==============================] - 0s 312us/step - loss: 0.2811 - accuracy: 0.8554 - val_loss: 0.2220 - val_accuracy: 0.9492\n",
      "Epoch 1141/2000\n",
      "505/505 [==============================] - 0s 314us/step - loss: 0.2791 - accuracy: 0.8673 - val_loss: 0.2299 - val_accuracy: 0.9492\n",
      "Epoch 1142/2000\n",
      "505/505 [==============================] - 0s 324us/step - loss: 0.2952 - accuracy: 0.8376 - val_loss: 0.2285 - val_accuracy: 0.9492\n",
      "Epoch 1143/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2814 - accuracy: 0.8436 - val_loss: 0.2305 - val_accuracy: 0.9492\n",
      "Epoch 1144/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2859 - accuracy: 0.8554 - val_loss: 0.2439 - val_accuracy: 0.9153\n",
      "Epoch 1145/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2806 - accuracy: 0.8535 - val_loss: 0.2216 - val_accuracy: 0.9322\n",
      "Epoch 1146/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.2877 - accuracy: 0.8416 - val_loss: 0.2371 - val_accuracy: 0.9153\n",
      "Epoch 1147/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2742 - accuracy: 0.8574 - val_loss: 0.2275 - val_accuracy: 0.9492\n",
      "Epoch 1148/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2831 - accuracy: 0.8515 - val_loss: 0.2180 - val_accuracy: 0.9492\n",
      "Epoch 1149/2000\n",
      "505/505 [==============================] - 0s 312us/step - loss: 0.2864 - accuracy: 0.8455 - val_loss: 0.2178 - val_accuracy: 0.9492\n",
      "Epoch 1150/2000\n",
      "505/505 [==============================] - 0s 310us/step - loss: 0.2789 - accuracy: 0.8495 - val_loss: 0.2410 - val_accuracy: 0.9153\n",
      "Epoch 1151/2000\n",
      "505/505 [==============================] - 0s 312us/step - loss: 0.2898 - accuracy: 0.8257 - val_loss: 0.2203 - val_accuracy: 0.9492\n",
      "Epoch 1152/2000\n",
      "505/505 [==============================] - 0s 314us/step - loss: 0.2787 - accuracy: 0.8455 - val_loss: 0.2169 - val_accuracy: 0.9492\n",
      "Epoch 1153/2000\n",
      "505/505 [==============================] - 0s 322us/step - loss: 0.2880 - accuracy: 0.8416 - val_loss: 0.2315 - val_accuracy: 0.9322\n",
      "Epoch 1154/2000\n",
      "505/505 [==============================] - 0s 318us/step - loss: 0.2831 - accuracy: 0.8535 - val_loss: 0.2126 - val_accuracy: 0.9492\n",
      "Epoch 1155/2000\n",
      "505/505 [==============================] - 0s 312us/step - loss: 0.2807 - accuracy: 0.8356 - val_loss: 0.2317 - val_accuracy: 0.9153\n",
      "Epoch 1156/2000\n",
      "505/505 [==============================] - 0s 312us/step - loss: 0.2841 - accuracy: 0.8455 - val_loss: 0.2124 - val_accuracy: 0.9492\n",
      "Epoch 1157/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 308us/step - loss: 0.2798 - accuracy: 0.8455 - val_loss: 0.2179 - val_accuracy: 0.9492\n",
      "Epoch 1158/2000\n",
      "505/505 [==============================] - 0s 312us/step - loss: 0.2893 - accuracy: 0.8376 - val_loss: 0.2108 - val_accuracy: 0.9492\n",
      "Epoch 1159/2000\n",
      "505/505 [==============================] - 0s 314us/step - loss: 0.2825 - accuracy: 0.8376 - val_loss: 0.2546 - val_accuracy: 0.8644\n",
      "Epoch 1160/2000\n",
      "505/505 [==============================] - 0s 308us/step - loss: 0.2910 - accuracy: 0.8317 - val_loss: 0.2407 - val_accuracy: 0.9153\n",
      "Epoch 1161/2000\n",
      "505/505 [==============================] - 0s 310us/step - loss: 0.2866 - accuracy: 0.8475 - val_loss: 0.2506 - val_accuracy: 0.8475\n",
      "Epoch 1162/2000\n",
      "505/505 [==============================] - 0s 314us/step - loss: 0.2733 - accuracy: 0.8416 - val_loss: 0.2143 - val_accuracy: 0.9322\n",
      "Epoch 1163/2000\n",
      "505/505 [==============================] - 0s 312us/step - loss: 0.2718 - accuracy: 0.8713 - val_loss: 0.2298 - val_accuracy: 0.9831\n",
      "Epoch 1164/2000\n",
      "505/505 [==============================] - 0s 314us/step - loss: 0.2852 - accuracy: 0.8317 - val_loss: 0.2138 - val_accuracy: 0.9492\n",
      "Epoch 1165/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.2724 - accuracy: 0.8515 - val_loss: 0.2173 - val_accuracy: 0.9492\n",
      "Epoch 1166/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2805 - accuracy: 0.8396 - val_loss: 0.2159 - val_accuracy: 0.9492\n",
      "Epoch 1167/2000\n",
      "505/505 [==============================] - 0s 314us/step - loss: 0.2776 - accuracy: 0.8515 - val_loss: 0.2057 - val_accuracy: 0.9492\n",
      "Epoch 1168/2000\n",
      "505/505 [==============================] - 0s 312us/step - loss: 0.2759 - accuracy: 0.8594 - val_loss: 0.2163 - val_accuracy: 0.9492\n",
      "Epoch 1169/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2760 - accuracy: 0.8455 - val_loss: 0.2023 - val_accuracy: 0.9492\n",
      "Epoch 1170/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2771 - accuracy: 0.8436 - val_loss: 0.2118 - val_accuracy: 0.9492\n",
      "Epoch 1171/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.2823 - accuracy: 0.8257 - val_loss: 0.2168 - val_accuracy: 0.9153\n",
      "Epoch 1172/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.2682 - accuracy: 0.8574 - val_loss: 0.2248 - val_accuracy: 0.9153\n",
      "Epoch 1173/2000\n",
      "505/505 [==============================] - 0s 320us/step - loss: 0.2953 - accuracy: 0.8297 - val_loss: 0.2207 - val_accuracy: 0.9492\n",
      "Epoch 1174/2000\n",
      "505/505 [==============================] - 0s 322us/step - loss: 0.2753 - accuracy: 0.8535 - val_loss: 0.2145 - val_accuracy: 0.9492\n",
      "Epoch 1175/2000\n",
      "505/505 [==============================] - 0s 320us/step - loss: 0.2768 - accuracy: 0.8515 - val_loss: 0.2685 - val_accuracy: 0.8136\n",
      "Epoch 1176/2000\n",
      "505/505 [==============================] - 0s 324us/step - loss: 0.2817 - accuracy: 0.8475 - val_loss: 0.2077 - val_accuracy: 0.9492\n",
      "Epoch 1177/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2743 - accuracy: 0.8475 - val_loss: 0.2199 - val_accuracy: 0.9322\n",
      "Epoch 1178/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.2795 - accuracy: 0.8297 - val_loss: 0.2110 - val_accuracy: 0.9492\n",
      "Epoch 1179/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2762 - accuracy: 0.8455 - val_loss: 0.2116 - val_accuracy: 0.9492\n",
      "Epoch 1180/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.2830 - accuracy: 0.8297 - val_loss: 0.2274 - val_accuracy: 0.9322\n",
      "Epoch 1181/2000\n",
      "505/505 [==============================] - 0s 456us/step - loss: 0.2795 - accuracy: 0.8455 - val_loss: 0.2248 - val_accuracy: 0.9322\n",
      "Epoch 1182/2000\n",
      "505/505 [==============================] - 0s 632us/step - loss: 0.2881 - accuracy: 0.8495 - val_loss: 0.2110 - val_accuracy: 0.9492\n",
      "Epoch 1183/2000\n",
      "505/505 [==============================] - 0s 620us/step - loss: 0.2654 - accuracy: 0.8713 - val_loss: 0.2200 - val_accuracy: 0.9153\n",
      "Epoch 1184/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2695 - accuracy: 0.8673 - val_loss: 0.2117 - val_accuracy: 0.9153\n",
      "Epoch 1185/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2789 - accuracy: 0.8396 - val_loss: 0.2215 - val_accuracy: 0.9322\n",
      "Epoch 1186/2000\n",
      "505/505 [==============================] - 0s 590us/step - loss: 0.2710 - accuracy: 0.8436 - val_loss: 0.2000 - val_accuracy: 0.9492\n",
      "Epoch 1187/2000\n",
      "505/505 [==============================] - 0s 592us/step - loss: 0.2711 - accuracy: 0.8574 - val_loss: 0.2039 - val_accuracy: 0.9492\n",
      "Epoch 1188/2000\n",
      "505/505 [==============================] - 0s 575us/step - loss: 0.2718 - accuracy: 0.8475 - val_loss: 0.1981 - val_accuracy: 0.9492\n",
      "Epoch 1189/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2680 - accuracy: 0.8634 - val_loss: 0.1975 - val_accuracy: 0.9492\n",
      "Epoch 1190/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2679 - accuracy: 0.8455 - val_loss: 0.2126 - val_accuracy: 0.9492\n",
      "Epoch 1191/2000\n",
      "505/505 [==============================] - 0s 604us/step - loss: 0.2871 - accuracy: 0.8376 - val_loss: 0.2568 - val_accuracy: 0.8305\n",
      "Epoch 1192/2000\n",
      "505/505 [==============================] - 0s 662us/step - loss: 0.2887 - accuracy: 0.8376 - val_loss: 0.2744 - val_accuracy: 0.7797\n",
      "Epoch 1193/2000\n",
      "505/505 [==============================] - 0s 628us/step - loss: 0.2793 - accuracy: 0.8535 - val_loss: 0.2097 - val_accuracy: 0.9492\n",
      "Epoch 1194/2000\n",
      "505/505 [==============================] - 0s 608us/step - loss: 0.2646 - accuracy: 0.8614 - val_loss: 0.2672 - val_accuracy: 0.8136\n",
      "Epoch 1195/2000\n",
      "505/505 [==============================] - 0s 614us/step - loss: 0.2637 - accuracy: 0.8634 - val_loss: 0.1982 - val_accuracy: 0.9492\n",
      "Epoch 1196/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2705 - accuracy: 0.8495 - val_loss: 0.2006 - val_accuracy: 0.9492\n",
      "Epoch 1197/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2705 - accuracy: 0.8515 - val_loss: 0.2341 - val_accuracy: 0.9153\n",
      "Epoch 1198/2000\n",
      "505/505 [==============================] - 0s 569us/step - loss: 0.2646 - accuracy: 0.8713 - val_loss: 0.2008 - val_accuracy: 0.9153\n",
      "Epoch 1199/2000\n",
      "505/505 [==============================] - 0s 598us/step - loss: 0.2586 - accuracy: 0.8693 - val_loss: 0.2176 - val_accuracy: 0.9322\n",
      "Epoch 1200/2000\n",
      "505/505 [==============================] - 0s 622us/step - loss: 0.2759 - accuracy: 0.8515 - val_loss: 0.1985 - val_accuracy: 0.9492\n",
      "Epoch 1201/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2621 - accuracy: 0.8733 - val_loss: 0.2452 - val_accuracy: 0.8814\n",
      "Epoch 1202/2000\n",
      "505/505 [==============================] - 0s 602us/step - loss: 0.2803 - accuracy: 0.8416 - val_loss: 0.2020 - val_accuracy: 0.9322\n",
      "Epoch 1203/2000\n",
      "505/505 [==============================] - 0s 614us/step - loss: 0.2813 - accuracy: 0.8475 - val_loss: 0.1983 - val_accuracy: 0.9492\n",
      "Epoch 1204/2000\n",
      "505/505 [==============================] - 0s 610us/step - loss: 0.2726 - accuracy: 0.8416 - val_loss: 0.2342 - val_accuracy: 0.8983\n",
      "Epoch 1205/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2781 - accuracy: 0.8376 - val_loss: 0.2053 - val_accuracy: 0.9153\n",
      "Epoch 1206/2000\n",
      "505/505 [==============================] - 0s 602us/step - loss: 0.2764 - accuracy: 0.8455 - val_loss: 0.2095 - val_accuracy: 0.9322\n",
      "Epoch 1207/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2807 - accuracy: 0.8317 - val_loss: 0.2404 - val_accuracy: 0.8814\n",
      "Epoch 1208/2000\n",
      "505/505 [==============================] - 0s 598us/step - loss: 0.2901 - accuracy: 0.8277 - val_loss: 0.2112 - val_accuracy: 0.9492\n",
      "Epoch 1209/2000\n",
      "505/505 [==============================] - 0s 640us/step - loss: 0.2746 - accuracy: 0.8337 - val_loss: 0.2001 - val_accuracy: 0.9492\n",
      "Epoch 1210/2000\n",
      "505/505 [==============================] - 0s 610us/step - loss: 0.2784 - accuracy: 0.8416 - val_loss: 0.2651 - val_accuracy: 0.8136\n",
      "Epoch 1211/2000\n",
      "505/505 [==============================] - 0s 606us/step - loss: 0.2733 - accuracy: 0.8515 - val_loss: 0.1985 - val_accuracy: 0.9492\n",
      "Epoch 1212/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 596us/step - loss: 0.2667 - accuracy: 0.8455 - val_loss: 0.1953 - val_accuracy: 0.9492\n",
      "Epoch 1213/2000\n",
      "505/505 [==============================] - 0s 594us/step - loss: 0.2671 - accuracy: 0.8495 - val_loss: 0.3346 - val_accuracy: 0.8136\n",
      "Epoch 1214/2000\n",
      "505/505 [==============================] - 0s 591us/step - loss: 0.2727 - accuracy: 0.8554 - val_loss: 0.2305 - val_accuracy: 0.9153\n",
      "Epoch 1215/2000\n",
      "505/505 [==============================] - 0s 642us/step - loss: 0.2706 - accuracy: 0.8356 - val_loss: 0.1949 - val_accuracy: 0.9492\n",
      "Epoch 1216/2000\n",
      "505/505 [==============================] - 0s 733us/step - loss: 0.2696 - accuracy: 0.8455 - val_loss: 0.2660 - val_accuracy: 0.8136\n",
      "Epoch 1217/2000\n",
      "505/505 [==============================] - 0s 604us/step - loss: 0.2630 - accuracy: 0.8574 - val_loss: 0.1993 - val_accuracy: 0.9492\n",
      "Epoch 1218/2000\n",
      "505/505 [==============================] - 0s 636us/step - loss: 0.2629 - accuracy: 0.8614 - val_loss: 0.2114 - val_accuracy: 0.9322\n",
      "Epoch 1219/2000\n",
      "505/505 [==============================] - 0s 719us/step - loss: 0.2728 - accuracy: 0.8574 - val_loss: 0.1926 - val_accuracy: 0.9492\n",
      "Epoch 1220/2000\n",
      "505/505 [==============================] - 0s 622us/step - loss: 0.2716 - accuracy: 0.8475 - val_loss: 0.1957 - val_accuracy: 0.9492\n",
      "Epoch 1221/2000\n",
      "505/505 [==============================] - 0s 610us/step - loss: 0.2744 - accuracy: 0.8396 - val_loss: 0.2196 - val_accuracy: 0.9322\n",
      "Epoch 1222/2000\n",
      "505/505 [==============================] - 0s 592us/step - loss: 0.2693 - accuracy: 0.8554 - val_loss: 0.1900 - val_accuracy: 0.9492\n",
      "Epoch 1223/2000\n",
      "505/505 [==============================] - 0s 594us/step - loss: 0.2803 - accuracy: 0.8356 - val_loss: 0.1937 - val_accuracy: 0.9492\n",
      "Epoch 1224/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2829 - accuracy: 0.8317 - val_loss: 0.1918 - val_accuracy: 0.9322\n",
      "Epoch 1225/2000\n",
      "505/505 [==============================] - 0s 555us/step - loss: 0.2680 - accuracy: 0.8515 - val_loss: 0.2010 - val_accuracy: 0.9322\n",
      "Epoch 1226/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2613 - accuracy: 0.8733 - val_loss: 0.1924 - val_accuracy: 0.9492\n",
      "Epoch 1227/2000\n",
      "505/505 [==============================] - 0s 571us/step - loss: 0.2653 - accuracy: 0.8673 - val_loss: 0.2060 - val_accuracy: 0.9492\n",
      "Epoch 1228/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2680 - accuracy: 0.8594 - val_loss: 0.1962 - val_accuracy: 0.9492\n",
      "Epoch 1229/2000\n",
      "505/505 [==============================] - 0s 569us/step - loss: 0.2638 - accuracy: 0.8634 - val_loss: 0.2049 - val_accuracy: 0.9492\n",
      "Epoch 1230/2000\n",
      "505/505 [==============================] - 0s 565us/step - loss: 0.2744 - accuracy: 0.8416 - val_loss: 0.1944 - val_accuracy: 0.9492\n",
      "Epoch 1231/2000\n",
      "505/505 [==============================] - 0s 539us/step - loss: 0.2630 - accuracy: 0.8594 - val_loss: 0.2176 - val_accuracy: 0.9322\n",
      "Epoch 1232/2000\n",
      "505/505 [==============================] - 0s 575us/step - loss: 0.2830 - accuracy: 0.8337 - val_loss: 0.1949 - val_accuracy: 0.9492\n",
      "Epoch 1233/2000\n",
      "505/505 [==============================] - 0s 630us/step - loss: 0.2742 - accuracy: 0.8396 - val_loss: 0.2039 - val_accuracy: 0.9492\n",
      "Epoch 1234/2000\n",
      "505/505 [==============================] - 0s 604us/step - loss: 0.2756 - accuracy: 0.8356 - val_loss: 0.2048 - val_accuracy: 0.9492\n",
      "Epoch 1235/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2741 - accuracy: 0.8535 - val_loss: 0.2399 - val_accuracy: 0.8644\n",
      "Epoch 1236/2000\n",
      "505/505 [==============================] - 0s 571us/step - loss: 0.2672 - accuracy: 0.8495 - val_loss: 0.2024 - val_accuracy: 0.9492\n",
      "Epoch 1237/2000\n",
      "505/505 [==============================] - 0s 575us/step - loss: 0.2706 - accuracy: 0.8436 - val_loss: 0.2175 - val_accuracy: 0.9492\n",
      "Epoch 1238/2000\n",
      "505/505 [==============================] - 0s 571us/step - loss: 0.2683 - accuracy: 0.8455 - val_loss: 0.2067 - val_accuracy: 0.9322\n",
      "Epoch 1239/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2707 - accuracy: 0.8396 - val_loss: 0.1928 - val_accuracy: 0.9492\n",
      "Epoch 1240/2000\n",
      "505/505 [==============================] - 0s 567us/step - loss: 0.2653 - accuracy: 0.8554 - val_loss: 0.2025 - val_accuracy: 0.9492\n",
      "Epoch 1241/2000\n",
      "505/505 [==============================] - 0s 573us/step - loss: 0.2738 - accuracy: 0.8515 - val_loss: 0.1923 - val_accuracy: 0.9492\n",
      "Epoch 1242/2000\n",
      "505/505 [==============================] - 0s 575us/step - loss: 0.2722 - accuracy: 0.8436 - val_loss: 0.1952 - val_accuracy: 0.9492\n",
      "Epoch 1243/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2701 - accuracy: 0.8436 - val_loss: 0.1983 - val_accuracy: 0.9492\n",
      "Epoch 1244/2000\n",
      "505/505 [==============================] - 0s 616us/step - loss: 0.2767 - accuracy: 0.8614 - val_loss: 0.1974 - val_accuracy: 0.9153\n",
      "Epoch 1245/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2649 - accuracy: 0.8515 - val_loss: 0.2027 - val_accuracy: 0.9492\n",
      "Epoch 1246/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2630 - accuracy: 0.8772 - val_loss: 0.2250 - val_accuracy: 0.9153\n",
      "Epoch 1247/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2633 - accuracy: 0.8436 - val_loss: 0.1977 - val_accuracy: 0.9492\n",
      "Epoch 1248/2000\n",
      "505/505 [==============================] - 0s 571us/step - loss: 0.2687 - accuracy: 0.8495 - val_loss: 0.2066 - val_accuracy: 0.9322\n",
      "Epoch 1249/2000\n",
      "505/505 [==============================] - 0s 561us/step - loss: 0.2619 - accuracy: 0.8614 - val_loss: 0.1981 - val_accuracy: 0.9153\n",
      "Epoch 1250/2000\n",
      "505/505 [==============================] - 0s 567us/step - loss: 0.2711 - accuracy: 0.8535 - val_loss: 0.1853 - val_accuracy: 0.9492\n",
      "Epoch 1251/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2612 - accuracy: 0.8693 - val_loss: 0.2400 - val_accuracy: 0.8644\n",
      "Epoch 1252/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2770 - accuracy: 0.8535 - val_loss: 0.2254 - val_accuracy: 0.9322\n",
      "Epoch 1253/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2669 - accuracy: 0.8614 - val_loss: 0.2041 - val_accuracy: 0.9322\n",
      "Epoch 1254/2000\n",
      "505/505 [==============================] - 0s 616us/step - loss: 0.2735 - accuracy: 0.8495 - val_loss: 0.3238 - val_accuracy: 0.7797\n",
      "Epoch 1255/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2680 - accuracy: 0.8416 - val_loss: 0.2000 - val_accuracy: 0.9492\n",
      "Epoch 1256/2000\n",
      "505/505 [==============================] - 0s 571us/step - loss: 0.2838 - accuracy: 0.8455 - val_loss: 0.1913 - val_accuracy: 0.9492\n",
      "Epoch 1257/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2769 - accuracy: 0.8515 - val_loss: 0.2632 - val_accuracy: 0.8136\n",
      "Epoch 1258/2000\n",
      "505/505 [==============================] - 0s 559us/step - loss: 0.2569 - accuracy: 0.8733 - val_loss: 0.1939 - val_accuracy: 0.9492\n",
      "Epoch 1259/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2754 - accuracy: 0.8416 - val_loss: 0.1973 - val_accuracy: 0.9492\n",
      "Epoch 1260/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2668 - accuracy: 0.8495 - val_loss: 0.1968 - val_accuracy: 0.9492\n",
      "Epoch 1261/2000\n",
      "505/505 [==============================] - 0s 551us/step - loss: 0.2699 - accuracy: 0.8535 - val_loss: 0.2435 - val_accuracy: 0.8305\n",
      "Epoch 1262/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2659 - accuracy: 0.8614 - val_loss: 0.1917 - val_accuracy: 0.9322\n",
      "Epoch 1263/2000\n",
      "505/505 [==============================] - 0s 575us/step - loss: 0.2857 - accuracy: 0.8396 - val_loss: 0.1892 - val_accuracy: 0.9492\n",
      "Epoch 1264/2000\n",
      "505/505 [==============================] - 0s 557us/step - loss: 0.2702 - accuracy: 0.8495 - val_loss: 0.2053 - val_accuracy: 0.9492\n",
      "Epoch 1265/2000\n",
      "505/505 [==============================] - 0s 591us/step - loss: 0.2618 - accuracy: 0.8653 - val_loss: 0.1964 - val_accuracy: 0.9492\n",
      "Epoch 1266/2000\n",
      "505/505 [==============================] - 0s 565us/step - loss: 0.2704 - accuracy: 0.8455 - val_loss: 0.2155 - val_accuracy: 0.9322\n",
      "Epoch 1267/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 561us/step - loss: 0.2674 - accuracy: 0.8396 - val_loss: 0.2001 - val_accuracy: 0.9492\n",
      "Epoch 1268/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2764 - accuracy: 0.8653 - val_loss: 0.2005 - val_accuracy: 0.9492\n",
      "Epoch 1269/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2666 - accuracy: 0.8653 - val_loss: 0.1886 - val_accuracy: 0.9492\n",
      "Epoch 1270/2000\n",
      "505/505 [==============================] - 0s 555us/step - loss: 0.2722 - accuracy: 0.8554 - val_loss: 0.2064 - val_accuracy: 0.9492\n",
      "Epoch 1271/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2668 - accuracy: 0.8535 - val_loss: 0.2094 - val_accuracy: 0.9492\n",
      "Epoch 1272/2000\n",
      "505/505 [==============================] - 0s 559us/step - loss: 0.2681 - accuracy: 0.8317 - val_loss: 0.2481 - val_accuracy: 0.8305\n",
      "Epoch 1273/2000\n",
      "505/505 [==============================] - 0s 563us/step - loss: 0.2700 - accuracy: 0.8495 - val_loss: 0.1939 - val_accuracy: 0.9492\n",
      "Epoch 1274/2000\n",
      "505/505 [==============================] - 0s 583us/step - loss: 0.2755 - accuracy: 0.8436 - val_loss: 0.2006 - val_accuracy: 0.9492\n",
      "Epoch 1275/2000\n",
      "505/505 [==============================] - 0s 598us/step - loss: 0.2715 - accuracy: 0.8693 - val_loss: 0.2070 - val_accuracy: 0.9492\n",
      "Epoch 1276/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2769 - accuracy: 0.8337 - val_loss: 0.1941 - val_accuracy: 0.9492\n",
      "Epoch 1277/2000\n",
      "505/505 [==============================] - 0s 620us/step - loss: 0.2681 - accuracy: 0.8554 - val_loss: 0.1942 - val_accuracy: 0.9492\n",
      "Epoch 1278/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2608 - accuracy: 0.8574 - val_loss: 0.2300 - val_accuracy: 0.9153\n",
      "Epoch 1279/2000\n",
      "505/505 [==============================] - 0s 594us/step - loss: 0.2633 - accuracy: 0.8594 - val_loss: 0.1927 - val_accuracy: 0.9492\n",
      "Epoch 1280/2000\n",
      "505/505 [==============================] - 0s 642us/step - loss: 0.2662 - accuracy: 0.8614 - val_loss: 0.2116 - val_accuracy: 0.9322\n",
      "Epoch 1281/2000\n",
      "505/505 [==============================] - 0s 622us/step - loss: 0.2707 - accuracy: 0.8574 - val_loss: 0.1949 - val_accuracy: 0.9492\n",
      "Epoch 1282/2000\n",
      "505/505 [==============================] - 0s 642us/step - loss: 0.2725 - accuracy: 0.8574 - val_loss: 0.2347 - val_accuracy: 0.9153\n",
      "Epoch 1283/2000\n",
      "505/505 [==============================] - 0s 622us/step - loss: 0.2716 - accuracy: 0.8554 - val_loss: 0.1947 - val_accuracy: 0.9153\n",
      "Epoch 1284/2000\n",
      "505/505 [==============================] - 0s 636us/step - loss: 0.2665 - accuracy: 0.8713 - val_loss: 0.1860 - val_accuracy: 0.9492\n",
      "Epoch 1285/2000\n",
      "505/505 [==============================] - 0s 614us/step - loss: 0.2600 - accuracy: 0.8812 - val_loss: 0.1926 - val_accuracy: 0.9322\n",
      "Epoch 1286/2000\n",
      "505/505 [==============================] - 0s 638us/step - loss: 0.2742 - accuracy: 0.8436 - val_loss: 0.2178 - val_accuracy: 0.9153\n",
      "Epoch 1287/2000\n",
      "505/505 [==============================] - 0s 723us/step - loss: 0.2696 - accuracy: 0.8436 - val_loss: 0.2238 - val_accuracy: 0.9153\n",
      "Epoch 1288/2000\n",
      "505/505 [==============================] - 0s 689us/step - loss: 0.2624 - accuracy: 0.8634 - val_loss: 0.2228 - val_accuracy: 0.9153\n",
      "Epoch 1289/2000\n",
      "505/505 [==============================] - 0s 592us/step - loss: 0.2676 - accuracy: 0.8475 - val_loss: 0.1904 - val_accuracy: 0.9492\n",
      "Epoch 1290/2000\n",
      "505/505 [==============================] - 0s 590us/step - loss: 0.2653 - accuracy: 0.8475 - val_loss: 0.1852 - val_accuracy: 0.9492\n",
      "Epoch 1291/2000\n",
      "505/505 [==============================] - 0s 594us/step - loss: 0.2614 - accuracy: 0.8594 - val_loss: 0.2622 - val_accuracy: 0.8136\n",
      "Epoch 1292/2000\n",
      "505/505 [==============================] - 0s 614us/step - loss: 0.2606 - accuracy: 0.8515 - val_loss: 0.2062 - val_accuracy: 0.9492\n",
      "Epoch 1293/2000\n",
      "505/505 [==============================] - 0s 583us/step - loss: 0.2747 - accuracy: 0.8436 - val_loss: 0.2027 - val_accuracy: 0.9492\n",
      "Epoch 1294/2000\n",
      "505/505 [==============================] - 0s 567us/step - loss: 0.2735 - accuracy: 0.8634 - val_loss: 0.1998 - val_accuracy: 0.9492\n",
      "Epoch 1295/2000\n",
      "505/505 [==============================] - 0s 555us/step - loss: 0.2664 - accuracy: 0.8535 - val_loss: 0.1883 - val_accuracy: 0.9492\n",
      "Epoch 1296/2000\n",
      "505/505 [==============================] - 0s 630us/step - loss: 0.2758 - accuracy: 0.8535 - val_loss: 0.2246 - val_accuracy: 0.9153\n",
      "Epoch 1297/2000\n",
      "505/505 [==============================] - 0s 626us/step - loss: 0.2647 - accuracy: 0.8574 - val_loss: 0.2023 - val_accuracy: 0.9492\n",
      "Epoch 1298/2000\n",
      "505/505 [==============================] - 0s 606us/step - loss: 0.2655 - accuracy: 0.8515 - val_loss: 0.1917 - val_accuracy: 0.9492\n",
      "Epoch 1299/2000\n",
      "505/505 [==============================] - 0s 567us/step - loss: 0.2611 - accuracy: 0.8653 - val_loss: 0.1826 - val_accuracy: 0.9492\n",
      "Epoch 1300/2000\n",
      "505/505 [==============================] - 0s 565us/step - loss: 0.2715 - accuracy: 0.8594 - val_loss: 0.1802 - val_accuracy: 0.9492\n",
      "Epoch 1301/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2654 - accuracy: 0.8614 - val_loss: 0.1912 - val_accuracy: 0.9322\n",
      "Epoch 1302/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2663 - accuracy: 0.8535 - val_loss: 0.2043 - val_accuracy: 0.9322\n",
      "Epoch 1303/2000\n",
      "505/505 [==============================] - 0s 592us/step - loss: 0.2727 - accuracy: 0.8396 - val_loss: 0.2978 - val_accuracy: 0.8136\n",
      "Epoch 1304/2000\n",
      "505/505 [==============================] - 0s 594us/step - loss: 0.2469 - accuracy: 0.8772 - val_loss: 0.1862 - val_accuracy: 0.9492\n",
      "Epoch 1305/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2664 - accuracy: 0.8515 - val_loss: 0.1835 - val_accuracy: 0.9492\n",
      "Epoch 1306/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2640 - accuracy: 0.8594 - val_loss: 0.2919 - val_accuracy: 0.8136\n",
      "Epoch 1307/2000\n",
      "505/505 [==============================] - 0s 624us/step - loss: 0.2712 - accuracy: 0.8475 - val_loss: 0.2316 - val_accuracy: 0.8814\n",
      "Epoch 1308/2000\n",
      "505/505 [==============================] - 0s 573us/step - loss: 0.2717 - accuracy: 0.8495 - val_loss: 0.2493 - val_accuracy: 0.8305\n",
      "Epoch 1309/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2624 - accuracy: 0.8634 - val_loss: 0.2293 - val_accuracy: 0.8814\n",
      "Epoch 1310/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2789 - accuracy: 0.8416 - val_loss: 0.1961 - val_accuracy: 0.9153\n",
      "Epoch 1311/2000\n",
      "505/505 [==============================] - 0s 592us/step - loss: 0.2676 - accuracy: 0.8495 - val_loss: 0.2037 - val_accuracy: 0.9492\n",
      "Epoch 1312/2000\n",
      "505/505 [==============================] - 0s 594us/step - loss: 0.2744 - accuracy: 0.8495 - val_loss: 0.1841 - val_accuracy: 0.9492\n",
      "Epoch 1313/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2730 - accuracy: 0.8297 - val_loss: 0.2243 - val_accuracy: 0.9153\n",
      "Epoch 1314/2000\n",
      "505/505 [==============================] - 0s 591us/step - loss: 0.2762 - accuracy: 0.8337 - val_loss: 0.1897 - val_accuracy: 0.9492\n",
      "Epoch 1315/2000\n",
      "505/505 [==============================] - 0s 563us/step - loss: 0.2623 - accuracy: 0.8475 - val_loss: 0.2157 - val_accuracy: 0.9492\n",
      "Epoch 1316/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2577 - accuracy: 0.8614 - val_loss: 0.2078 - val_accuracy: 0.9153\n",
      "Epoch 1317/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2694 - accuracy: 0.8554 - val_loss: 0.2401 - val_accuracy: 0.8644\n",
      "Epoch 1318/2000\n",
      "505/505 [==============================] - 0s 565us/step - loss: 0.2658 - accuracy: 0.8515 - val_loss: 0.1838 - val_accuracy: 0.9492\n",
      "Epoch 1319/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2568 - accuracy: 0.8752 - val_loss: 0.1832 - val_accuracy: 0.9492\n",
      "Epoch 1320/2000\n",
      "505/505 [==============================] - 0s 592us/step - loss: 0.2644 - accuracy: 0.8475 - val_loss: 0.2123 - val_accuracy: 0.9322\n",
      "Epoch 1321/2000\n",
      "505/505 [==============================] - 0s 563us/step - loss: 0.2634 - accuracy: 0.8614 - val_loss: 0.1905 - val_accuracy: 0.9492\n",
      "Epoch 1322/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 569us/step - loss: 0.2632 - accuracy: 0.8614 - val_loss: 0.1901 - val_accuracy: 0.9492\n",
      "Epoch 1323/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2717 - accuracy: 0.8535 - val_loss: 0.2079 - val_accuracy: 0.9322\n",
      "Epoch 1324/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2624 - accuracy: 0.8594 - val_loss: 0.1864 - val_accuracy: 0.9492\n",
      "Epoch 1325/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2649 - accuracy: 0.8535 - val_loss: 0.1889 - val_accuracy: 0.9492\n",
      "Epoch 1326/2000\n",
      "505/505 [==============================] - 0s 571us/step - loss: 0.2642 - accuracy: 0.8634 - val_loss: 0.1856 - val_accuracy: 0.9492\n",
      "Epoch 1327/2000\n",
      "505/505 [==============================] - 0s 583us/step - loss: 0.2755 - accuracy: 0.8376 - val_loss: 0.1959 - val_accuracy: 0.9492\n",
      "Epoch 1328/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2735 - accuracy: 0.8475 - val_loss: 0.1963 - val_accuracy: 0.9492\n",
      "Epoch 1329/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2674 - accuracy: 0.8574 - val_loss: 0.2107 - val_accuracy: 0.9492\n",
      "Epoch 1330/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2481 - accuracy: 0.8832 - val_loss: 0.1840 - val_accuracy: 0.9492\n",
      "Epoch 1331/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2661 - accuracy: 0.8535 - val_loss: 0.1993 - val_accuracy: 0.9492\n",
      "Epoch 1332/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2605 - accuracy: 0.8634 - val_loss: 0.1817 - val_accuracy: 0.9492\n",
      "Epoch 1333/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2711 - accuracy: 0.8455 - val_loss: 0.2023 - val_accuracy: 0.9492\n",
      "Epoch 1334/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2733 - accuracy: 0.8396 - val_loss: 0.2207 - val_accuracy: 0.9153\n",
      "Epoch 1335/2000\n",
      "505/505 [==============================] - 0s 590us/step - loss: 0.2637 - accuracy: 0.8772 - val_loss: 0.1783 - val_accuracy: 0.9492\n",
      "Epoch 1336/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2641 - accuracy: 0.8455 - val_loss: 0.1907 - val_accuracy: 0.9492\n",
      "Epoch 1337/2000\n",
      "505/505 [==============================] - 0s 565us/step - loss: 0.2586 - accuracy: 0.8614 - val_loss: 0.1901 - val_accuracy: 0.9492\n",
      "Epoch 1338/2000\n",
      "505/505 [==============================] - 0s 569us/step - loss: 0.2553 - accuracy: 0.8614 - val_loss: 0.1772 - val_accuracy: 0.9492\n",
      "Epoch 1339/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2590 - accuracy: 0.8614 - val_loss: 0.1757 - val_accuracy: 0.9492\n",
      "Epoch 1340/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2676 - accuracy: 0.8416 - val_loss: 0.2100 - val_accuracy: 0.9322\n",
      "Epoch 1341/2000\n",
      "505/505 [==============================] - 0s 594us/step - loss: 0.2625 - accuracy: 0.8594 - val_loss: 0.1770 - val_accuracy: 0.9492\n",
      "Epoch 1342/2000\n",
      "505/505 [==============================] - 0s 569us/step - loss: 0.2636 - accuracy: 0.8535 - val_loss: 0.1759 - val_accuracy: 0.9492\n",
      "Epoch 1343/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2636 - accuracy: 0.8535 - val_loss: 0.1924 - val_accuracy: 0.9492\n",
      "Epoch 1344/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2720 - accuracy: 0.8416 - val_loss: 0.1903 - val_accuracy: 0.9492\n",
      "Epoch 1345/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2746 - accuracy: 0.8416 - val_loss: 0.1957 - val_accuracy: 0.9492\n",
      "Epoch 1346/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2603 - accuracy: 0.8673 - val_loss: 0.1736 - val_accuracy: 0.9492\n",
      "Epoch 1347/2000\n",
      "505/505 [==============================] - 0s 575us/step - loss: 0.2633 - accuracy: 0.8634 - val_loss: 0.1815 - val_accuracy: 0.9492\n",
      "Epoch 1348/2000\n",
      "505/505 [==============================] - 0s 573us/step - loss: 0.2608 - accuracy: 0.8614 - val_loss: 0.1757 - val_accuracy: 0.9492\n",
      "Epoch 1349/2000\n",
      "505/505 [==============================] - 0s 571us/step - loss: 0.2570 - accuracy: 0.8772 - val_loss: 0.1946 - val_accuracy: 0.9492\n",
      "Epoch 1350/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2625 - accuracy: 0.8594 - val_loss: 0.1860 - val_accuracy: 0.9492\n",
      "Epoch 1351/2000\n",
      "505/505 [==============================] - 0s 571us/step - loss: 0.2659 - accuracy: 0.8515 - val_loss: 0.2363 - val_accuracy: 0.8475\n",
      "Epoch 1352/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2567 - accuracy: 0.8614 - val_loss: 0.1740 - val_accuracy: 0.9492\n",
      "Epoch 1353/2000\n",
      "505/505 [==============================] - 0s 614us/step - loss: 0.2606 - accuracy: 0.8515 - val_loss: 0.1905 - val_accuracy: 0.9492\n",
      "Epoch 1354/2000\n",
      "505/505 [==============================] - 0s 590us/step - loss: 0.2576 - accuracy: 0.8752 - val_loss: 0.1865 - val_accuracy: 0.9492\n",
      "Epoch 1355/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2530 - accuracy: 0.8535 - val_loss: 0.1718 - val_accuracy: 0.9492\n",
      "Epoch 1356/2000\n",
      "505/505 [==============================] - 0s 592us/step - loss: 0.2579 - accuracy: 0.8653 - val_loss: 0.1676 - val_accuracy: 0.9492\n",
      "Epoch 1357/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2536 - accuracy: 0.8673 - val_loss: 0.1736 - val_accuracy: 0.9492\n",
      "Epoch 1358/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2508 - accuracy: 0.8574 - val_loss: 0.1875 - val_accuracy: 0.9153\n",
      "Epoch 1359/2000\n",
      "505/505 [==============================] - 0s 594us/step - loss: 0.2660 - accuracy: 0.8396 - val_loss: 0.3922 - val_accuracy: 0.8136\n",
      "Epoch 1360/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2687 - accuracy: 0.8594 - val_loss: 0.1856 - val_accuracy: 0.9492\n",
      "Epoch 1361/2000\n",
      "505/505 [==============================] - 0s 567us/step - loss: 0.2680 - accuracy: 0.8574 - val_loss: 0.1827 - val_accuracy: 0.9492\n",
      "Epoch 1362/2000\n",
      "505/505 [==============================] - 0s 602us/step - loss: 0.2460 - accuracy: 0.8752 - val_loss: 0.1725 - val_accuracy: 0.9492\n",
      "Epoch 1363/2000\n",
      "505/505 [==============================] - 0s 571us/step - loss: 0.2614 - accuracy: 0.8693 - val_loss: 0.3088 - val_accuracy: 0.8136\n",
      "Epoch 1364/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2562 - accuracy: 0.8614 - val_loss: 0.1870 - val_accuracy: 0.9492\n",
      "Epoch 1365/2000\n",
      "505/505 [==============================] - 0s 598us/step - loss: 0.2622 - accuracy: 0.8436 - val_loss: 0.1795 - val_accuracy: 0.9492\n",
      "Epoch 1366/2000\n",
      "505/505 [==============================] - 0s 583us/step - loss: 0.2519 - accuracy: 0.8673 - val_loss: 0.1789 - val_accuracy: 0.9492\n",
      "Epoch 1367/2000\n",
      "505/505 [==============================] - 0s 571us/step - loss: 0.2563 - accuracy: 0.8653 - val_loss: 0.1822 - val_accuracy: 0.9492\n",
      "Epoch 1368/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2602 - accuracy: 0.8515 - val_loss: 0.1795 - val_accuracy: 0.9492\n",
      "Epoch 1369/2000\n",
      "505/505 [==============================] - 0s 591us/step - loss: 0.2449 - accuracy: 0.8871 - val_loss: 0.1753 - val_accuracy: 0.9492\n",
      "Epoch 1370/2000\n",
      "505/505 [==============================] - 0s 618us/step - loss: 0.2505 - accuracy: 0.8772 - val_loss: 0.3009 - val_accuracy: 0.7966\n",
      "Epoch 1371/2000\n",
      "505/505 [==============================] - 0s 618us/step - loss: 0.2622 - accuracy: 0.8594 - val_loss: 0.1829 - val_accuracy: 0.9492\n",
      "Epoch 1372/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2690 - accuracy: 0.8455 - val_loss: 0.1982 - val_accuracy: 0.9322\n",
      "Epoch 1373/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2609 - accuracy: 0.8574 - val_loss: 0.1795 - val_accuracy: 0.9492\n",
      "Epoch 1374/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2524 - accuracy: 0.8653 - val_loss: 0.1793 - val_accuracy: 0.9492\n",
      "Epoch 1375/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2516 - accuracy: 0.8634 - val_loss: 0.2158 - val_accuracy: 0.8983\n",
      "Epoch 1376/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2516 - accuracy: 0.8653 - val_loss: 0.1768 - val_accuracy: 0.9492\n",
      "Epoch 1377/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 600us/step - loss: 0.2697 - accuracy: 0.8455 - val_loss: 0.1997 - val_accuracy: 0.9492\n",
      "Epoch 1378/2000\n",
      "505/505 [==============================] - 0s 598us/step - loss: 0.2744 - accuracy: 0.8396 - val_loss: 0.2056 - val_accuracy: 0.9322\n",
      "Epoch 1379/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2587 - accuracy: 0.8634 - val_loss: 0.1773 - val_accuracy: 0.9492\n",
      "Epoch 1380/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2688 - accuracy: 0.8535 - val_loss: 0.1801 - val_accuracy: 0.9492\n",
      "Epoch 1381/2000\n",
      "505/505 [==============================] - 0s 569us/step - loss: 0.2558 - accuracy: 0.8495 - val_loss: 0.1939 - val_accuracy: 0.9492\n",
      "Epoch 1382/2000\n",
      "505/505 [==============================] - 0s 573us/step - loss: 0.2644 - accuracy: 0.8475 - val_loss: 0.1979 - val_accuracy: 0.9492\n",
      "Epoch 1383/2000\n",
      "505/505 [==============================] - 0s 620us/step - loss: 0.2612 - accuracy: 0.8436 - val_loss: 0.1765 - val_accuracy: 0.9492\n",
      "Epoch 1384/2000\n",
      "505/505 [==============================] - 0s 591us/step - loss: 0.2609 - accuracy: 0.8297 - val_loss: 0.1826 - val_accuracy: 0.9492\n",
      "Epoch 1385/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2526 - accuracy: 0.8495 - val_loss: 0.1823 - val_accuracy: 0.9492\n",
      "Epoch 1386/2000\n",
      "505/505 [==============================] - 0s 612us/step - loss: 0.2642 - accuracy: 0.8436 - val_loss: 0.1833 - val_accuracy: 0.9492\n",
      "Epoch 1387/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2561 - accuracy: 0.8495 - val_loss: 0.1823 - val_accuracy: 0.9322\n",
      "Epoch 1388/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2507 - accuracy: 0.8574 - val_loss: 0.1746 - val_accuracy: 0.9492\n",
      "Epoch 1389/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2534 - accuracy: 0.8594 - val_loss: 0.1822 - val_accuracy: 0.9322\n",
      "Epoch 1390/2000\n",
      "505/505 [==============================] - 0s 602us/step - loss: 0.2520 - accuracy: 0.8574 - val_loss: 0.1742 - val_accuracy: 0.9492\n",
      "Epoch 1391/2000\n",
      "505/505 [==============================] - 0s 591us/step - loss: 0.2685 - accuracy: 0.8455 - val_loss: 0.1976 - val_accuracy: 0.9322\n",
      "Epoch 1392/2000\n",
      "505/505 [==============================] - 0s 602us/step - loss: 0.2570 - accuracy: 0.8713 - val_loss: 0.2076 - val_accuracy: 0.9492\n",
      "Epoch 1393/2000\n",
      "505/505 [==============================] - 0s 598us/step - loss: 0.2592 - accuracy: 0.8713 - val_loss: 0.1788 - val_accuracy: 0.9492\n",
      "Epoch 1394/2000\n",
      "505/505 [==============================] - 0s 575us/step - loss: 0.2543 - accuracy: 0.8614 - val_loss: 0.1761 - val_accuracy: 0.9492\n",
      "Epoch 1395/2000\n",
      "505/505 [==============================] - 0s 583us/step - loss: 0.2670 - accuracy: 0.8475 - val_loss: 0.1761 - val_accuracy: 0.9322\n",
      "Epoch 1396/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2554 - accuracy: 0.8535 - val_loss: 0.1858 - val_accuracy: 0.9492\n",
      "Epoch 1397/2000\n",
      "505/505 [==============================] - 0s 573us/step - loss: 0.2571 - accuracy: 0.8574 - val_loss: 0.1742 - val_accuracy: 0.9492\n",
      "Epoch 1398/2000\n",
      "505/505 [==============================] - 0s 573us/step - loss: 0.2598 - accuracy: 0.8634 - val_loss: 0.1799 - val_accuracy: 0.9492\n",
      "Epoch 1399/2000\n",
      "505/505 [==============================] - 0s 594us/step - loss: 0.2451 - accuracy: 0.8752 - val_loss: 0.1904 - val_accuracy: 0.9492\n",
      "Epoch 1400/2000\n",
      "505/505 [==============================] - 0s 592us/step - loss: 0.2557 - accuracy: 0.8554 - val_loss: 0.1843 - val_accuracy: 0.9492\n",
      "Epoch 1401/2000\n",
      "505/505 [==============================] - 0s 624us/step - loss: 0.2645 - accuracy: 0.8475 - val_loss: 0.1852 - val_accuracy: 0.9492\n",
      "Epoch 1402/2000\n",
      "505/505 [==============================] - 0s 602us/step - loss: 0.2544 - accuracy: 0.8614 - val_loss: 0.1828 - val_accuracy: 0.9322\n",
      "Epoch 1403/2000\n",
      "505/505 [==============================] - 0s 624us/step - loss: 0.2529 - accuracy: 0.8673 - val_loss: 0.1772 - val_accuracy: 0.9492\n",
      "Epoch 1404/2000\n",
      "505/505 [==============================] - 0s 592us/step - loss: 0.2522 - accuracy: 0.8653 - val_loss: 0.1729 - val_accuracy: 0.9492\n",
      "Epoch 1405/2000\n",
      "505/505 [==============================] - 0s 561us/step - loss: 0.2557 - accuracy: 0.8653 - val_loss: 0.1741 - val_accuracy: 0.9492\n",
      "Epoch 1406/2000\n",
      "505/505 [==============================] - 0s 606us/step - loss: 0.2415 - accuracy: 0.8851 - val_loss: 0.1685 - val_accuracy: 0.9492\n",
      "Epoch 1407/2000\n",
      "505/505 [==============================] - 0s 583us/step - loss: 0.2591 - accuracy: 0.8693 - val_loss: 0.1826 - val_accuracy: 0.9492\n",
      "Epoch 1408/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2635 - accuracy: 0.8515 - val_loss: 0.1738 - val_accuracy: 0.9492\n",
      "Epoch 1409/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2604 - accuracy: 0.8653 - val_loss: 0.1799 - val_accuracy: 0.9492\n",
      "Epoch 1410/2000\n",
      "505/505 [==============================] - 0s 610us/step - loss: 0.2562 - accuracy: 0.8634 - val_loss: 0.1867 - val_accuracy: 0.9492\n",
      "Epoch 1411/2000\n",
      "505/505 [==============================] - 0s 624us/step - loss: 0.2540 - accuracy: 0.8614 - val_loss: 0.1826 - val_accuracy: 0.9492\n",
      "Epoch 1412/2000\n",
      "505/505 [==============================] - 0s 604us/step - loss: 0.2615 - accuracy: 0.8554 - val_loss: 0.1908 - val_accuracy: 0.9492\n",
      "Epoch 1413/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2608 - accuracy: 0.8475 - val_loss: 0.1724 - val_accuracy: 0.9322\n",
      "Epoch 1414/2000\n",
      "505/505 [==============================] - 0s 602us/step - loss: 0.2566 - accuracy: 0.8614 - val_loss: 0.1677 - val_accuracy: 0.9492\n",
      "Epoch 1415/2000\n",
      "505/505 [==============================] - 0s 624us/step - loss: 0.2576 - accuracy: 0.8574 - val_loss: 0.2329 - val_accuracy: 0.8644\n",
      "Epoch 1416/2000\n",
      "505/505 [==============================] - 0s 594us/step - loss: 0.2579 - accuracy: 0.8554 - val_loss: 0.1751 - val_accuracy: 0.9492\n",
      "Epoch 1417/2000\n",
      "505/505 [==============================] - 0s 590us/step - loss: 0.2571 - accuracy: 0.8614 - val_loss: 0.1890 - val_accuracy: 0.9492\n",
      "Epoch 1418/2000\n",
      "505/505 [==============================] - 0s 592us/step - loss: 0.2611 - accuracy: 0.8416 - val_loss: 0.1691 - val_accuracy: 0.9492\n",
      "Epoch 1419/2000\n",
      "505/505 [==============================] - 0s 634us/step - loss: 0.2575 - accuracy: 0.8653 - val_loss: 0.1671 - val_accuracy: 0.9492\n",
      "Epoch 1420/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2632 - accuracy: 0.8554 - val_loss: 0.1885 - val_accuracy: 0.9492\n",
      "Epoch 1421/2000\n",
      "505/505 [==============================] - 0s 606us/step - loss: 0.2586 - accuracy: 0.8554 - val_loss: 0.2274 - val_accuracy: 0.8814\n",
      "Epoch 1422/2000\n",
      "505/505 [==============================] - 0s 591us/step - loss: 0.2558 - accuracy: 0.8673 - val_loss: 0.1772 - val_accuracy: 0.9492\n",
      "Epoch 1423/2000\n",
      "505/505 [==============================] - 0s 567us/step - loss: 0.2641 - accuracy: 0.8495 - val_loss: 0.1762 - val_accuracy: 0.9492\n",
      "Epoch 1424/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2570 - accuracy: 0.8535 - val_loss: 0.1698 - val_accuracy: 0.9492\n",
      "Epoch 1425/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2554 - accuracy: 0.8614 - val_loss: 0.1696 - val_accuracy: 0.9492\n",
      "Epoch 1426/2000\n",
      "505/505 [==============================] - 0s 608us/step - loss: 0.2640 - accuracy: 0.8475 - val_loss: 0.1666 - val_accuracy: 0.9492\n",
      "Epoch 1427/2000\n",
      "505/505 [==============================] - 0s 608us/step - loss: 0.2529 - accuracy: 0.8693 - val_loss: 0.1681 - val_accuracy: 0.9492\n",
      "Epoch 1428/2000\n",
      "505/505 [==============================] - 0s 583us/step - loss: 0.2526 - accuracy: 0.8475 - val_loss: 0.1647 - val_accuracy: 0.9492\n",
      "Epoch 1429/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2555 - accuracy: 0.8455 - val_loss: 0.1636 - val_accuracy: 0.9492\n",
      "Epoch 1430/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2584 - accuracy: 0.8574 - val_loss: 0.2000 - val_accuracy: 0.9153\n",
      "Epoch 1431/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2521 - accuracy: 0.8475 - val_loss: 0.1905 - val_accuracy: 0.9492\n",
      "Epoch 1432/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 602us/step - loss: 0.2588 - accuracy: 0.8653 - val_loss: 0.1648 - val_accuracy: 0.9492\n",
      "Epoch 1433/2000\n",
      "505/505 [==============================] - 0s 583us/step - loss: 0.2595 - accuracy: 0.8535 - val_loss: 0.1627 - val_accuracy: 0.9492\n",
      "Epoch 1434/2000\n",
      "505/505 [==============================] - 0s 563us/step - loss: 0.2650 - accuracy: 0.8436 - val_loss: 0.1639 - val_accuracy: 0.9322\n",
      "Epoch 1435/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2575 - accuracy: 0.8475 - val_loss: 0.1625 - val_accuracy: 0.9492\n",
      "Epoch 1436/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2606 - accuracy: 0.8574 - val_loss: 0.1611 - val_accuracy: 0.9492\n",
      "Epoch 1437/2000\n",
      "505/505 [==============================] - 0s 592us/step - loss: 0.2555 - accuracy: 0.8515 - val_loss: 0.1706 - val_accuracy: 0.9492\n",
      "Epoch 1438/2000\n",
      "505/505 [==============================] - 0s 598us/step - loss: 0.2541 - accuracy: 0.8693 - val_loss: 0.1738 - val_accuracy: 0.9492\n",
      "Epoch 1439/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2584 - accuracy: 0.8634 - val_loss: 0.2013 - val_accuracy: 0.9153\n",
      "Epoch 1440/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2631 - accuracy: 0.8455 - val_loss: 0.1685 - val_accuracy: 0.9492\n",
      "Epoch 1441/2000\n",
      "505/505 [==============================] - 0s 608us/step - loss: 0.2542 - accuracy: 0.8634 - val_loss: 0.1720 - val_accuracy: 0.9492\n",
      "Epoch 1442/2000\n",
      "505/505 [==============================] - 0s 614us/step - loss: 0.2583 - accuracy: 0.8574 - val_loss: 0.1685 - val_accuracy: 0.9492\n",
      "Epoch 1443/2000\n",
      "505/505 [==============================] - 0s 590us/step - loss: 0.2606 - accuracy: 0.8475 - val_loss: 0.1723 - val_accuracy: 0.9492\n",
      "Epoch 1444/2000\n",
      "505/505 [==============================] - 0s 630us/step - loss: 0.2417 - accuracy: 0.8812 - val_loss: 0.1653 - val_accuracy: 0.9492\n",
      "Epoch 1445/2000\n",
      "505/505 [==============================] - 0s 612us/step - loss: 0.2623 - accuracy: 0.8515 - val_loss: 0.1745 - val_accuracy: 0.9492\n",
      "Epoch 1446/2000\n",
      "505/505 [==============================] - 0s 606us/step - loss: 0.2633 - accuracy: 0.8416 - val_loss: 0.1966 - val_accuracy: 0.9492\n",
      "Epoch 1447/2000\n",
      "505/505 [==============================] - 0s 623us/step - loss: 0.2715 - accuracy: 0.8574 - val_loss: 0.1628 - val_accuracy: 0.9492\n",
      "Epoch 1448/2000\n",
      "505/505 [==============================] - 0s 594us/step - loss: 0.2636 - accuracy: 0.8614 - val_loss: 0.1638 - val_accuracy: 0.9492\n",
      "Epoch 1449/2000\n",
      "505/505 [==============================] - 0s 616us/step - loss: 0.2576 - accuracy: 0.8495 - val_loss: 0.1643 - val_accuracy: 0.9492\n",
      "Epoch 1450/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2567 - accuracy: 0.8594 - val_loss: 0.1748 - val_accuracy: 0.9492\n",
      "Epoch 1451/2000\n",
      "505/505 [==============================] - 0s 594us/step - loss: 0.2541 - accuracy: 0.8594 - val_loss: 0.1757 - val_accuracy: 0.9492\n",
      "Epoch 1452/2000\n",
      "505/505 [==============================] - 0s 575us/step - loss: 0.2625 - accuracy: 0.8515 - val_loss: 0.1664 - val_accuracy: 0.9492\n",
      "Epoch 1453/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2655 - accuracy: 0.8396 - val_loss: 0.1710 - val_accuracy: 0.9322\n",
      "Epoch 1454/2000\n",
      "505/505 [==============================] - 0s 598us/step - loss: 0.2562 - accuracy: 0.8455 - val_loss: 0.1697 - val_accuracy: 0.9492\n",
      "Epoch 1455/2000\n",
      "505/505 [==============================] - 0s 575us/step - loss: 0.2533 - accuracy: 0.8554 - val_loss: 0.1695 - val_accuracy: 0.9492\n",
      "Epoch 1456/2000\n",
      "505/505 [==============================] - 0s 563us/step - loss: 0.2562 - accuracy: 0.8554 - val_loss: 0.1591 - val_accuracy: 0.9492\n",
      "Epoch 1457/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2491 - accuracy: 0.8594 - val_loss: 0.1640 - val_accuracy: 0.9492\n",
      "Epoch 1458/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2506 - accuracy: 0.8594 - val_loss: 0.1618 - val_accuracy: 0.9492\n",
      "Epoch 1459/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2533 - accuracy: 0.8554 - val_loss: 0.1593 - val_accuracy: 0.9492\n",
      "Epoch 1460/2000\n",
      "505/505 [==============================] - 0s 561us/step - loss: 0.2544 - accuracy: 0.8495 - val_loss: 0.1677 - val_accuracy: 0.9492\n",
      "Epoch 1461/2000\n",
      "505/505 [==============================] - 0s 594us/step - loss: 0.2572 - accuracy: 0.8614 - val_loss: 0.1668 - val_accuracy: 0.9492\n",
      "Epoch 1462/2000\n",
      "505/505 [==============================] - 0s 573us/step - loss: 0.2610 - accuracy: 0.8614 - val_loss: 0.1604 - val_accuracy: 0.9492\n",
      "Epoch 1463/2000\n",
      "505/505 [==============================] - 0s 590us/step - loss: 0.2601 - accuracy: 0.8594 - val_loss: 0.1563 - val_accuracy: 0.9492\n",
      "Epoch 1464/2000\n",
      "505/505 [==============================] - 0s 571us/step - loss: 0.2542 - accuracy: 0.8634 - val_loss: 0.1721 - val_accuracy: 0.9322\n",
      "Epoch 1465/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2678 - accuracy: 0.8396 - val_loss: 0.1573 - val_accuracy: 0.9492\n",
      "Epoch 1466/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2589 - accuracy: 0.8475 - val_loss: 0.1552 - val_accuracy: 0.9492\n",
      "Epoch 1467/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2553 - accuracy: 0.8614 - val_loss: 0.1603 - val_accuracy: 0.9492\n",
      "Epoch 1468/2000\n",
      "505/505 [==============================] - 0s 569us/step - loss: 0.2512 - accuracy: 0.8634 - val_loss: 0.1595 - val_accuracy: 0.9492\n",
      "Epoch 1469/2000\n",
      "505/505 [==============================] - 0s 598us/step - loss: 0.2538 - accuracy: 0.8554 - val_loss: 0.1647 - val_accuracy: 0.9492\n",
      "Epoch 1470/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2563 - accuracy: 0.8535 - val_loss: 0.1606 - val_accuracy: 0.9492\n",
      "Epoch 1471/2000\n",
      "505/505 [==============================] - 0s 602us/step - loss: 0.2511 - accuracy: 0.8713 - val_loss: 0.1748 - val_accuracy: 0.9322\n",
      "Epoch 1472/2000\n",
      "505/505 [==============================] - 0s 563us/step - loss: 0.2526 - accuracy: 0.8574 - val_loss: 0.1651 - val_accuracy: 0.9492\n",
      "Epoch 1473/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2468 - accuracy: 0.8693 - val_loss: 0.1651 - val_accuracy: 0.9492\n",
      "Epoch 1474/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2471 - accuracy: 0.8614 - val_loss: 0.1572 - val_accuracy: 0.9492\n",
      "Epoch 1475/2000\n",
      "505/505 [==============================] - 0s 592us/step - loss: 0.2506 - accuracy: 0.8535 - val_loss: 0.1783 - val_accuracy: 0.9492\n",
      "Epoch 1476/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2590 - accuracy: 0.8614 - val_loss: 0.1737 - val_accuracy: 0.9492\n",
      "Epoch 1477/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2473 - accuracy: 0.8634 - val_loss: 0.1595 - val_accuracy: 0.9492\n",
      "Epoch 1478/2000\n",
      "505/505 [==============================] - 0s 573us/step - loss: 0.2608 - accuracy: 0.8574 - val_loss: 0.1607 - val_accuracy: 0.9492\n",
      "Epoch 1479/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2511 - accuracy: 0.8733 - val_loss: 0.1536 - val_accuracy: 0.9492\n",
      "Epoch 1480/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2531 - accuracy: 0.8653 - val_loss: 0.1519 - val_accuracy: 0.9492\n",
      "Epoch 1481/2000\n",
      "505/505 [==============================] - 0s 565us/step - loss: 0.2508 - accuracy: 0.8634 - val_loss: 0.1541 - val_accuracy: 0.9492\n",
      "Epoch 1482/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2517 - accuracy: 0.8535 - val_loss: 0.1571 - val_accuracy: 0.9492\n",
      "Epoch 1483/2000\n",
      "505/505 [==============================] - 0s 583us/step - loss: 0.2551 - accuracy: 0.8614 - val_loss: 0.1926 - val_accuracy: 0.9322\n",
      "Epoch 1484/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2509 - accuracy: 0.8653 - val_loss: 0.1556 - val_accuracy: 0.9492\n",
      "Epoch 1485/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2448 - accuracy: 0.8752 - val_loss: 0.1578 - val_accuracy: 0.9492\n",
      "Epoch 1486/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2585 - accuracy: 0.8535 - val_loss: 0.1568 - val_accuracy: 0.9492\n",
      "Epoch 1487/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 579us/step - loss: 0.2672 - accuracy: 0.8455 - val_loss: 0.1581 - val_accuracy: 0.9492\n",
      "Epoch 1488/2000\n",
      "505/505 [==============================] - 0s 573us/step - loss: 0.2493 - accuracy: 0.8752 - val_loss: 0.1583 - val_accuracy: 0.9492\n",
      "Epoch 1489/2000\n",
      "505/505 [==============================] - 0s 575us/step - loss: 0.2539 - accuracy: 0.8495 - val_loss: 0.1561 - val_accuracy: 0.9492\n",
      "Epoch 1490/2000\n",
      "505/505 [==============================] - 0s 575us/step - loss: 0.2596 - accuracy: 0.8614 - val_loss: 0.1536 - val_accuracy: 0.9492\n",
      "Epoch 1491/2000\n",
      "505/505 [==============================] - 0s 569us/step - loss: 0.2483 - accuracy: 0.8693 - val_loss: 0.1566 - val_accuracy: 0.9492\n",
      "Epoch 1492/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2615 - accuracy: 0.8515 - val_loss: 0.1556 - val_accuracy: 0.9492\n",
      "Epoch 1493/2000\n",
      "505/505 [==============================] - 0s 592us/step - loss: 0.2536 - accuracy: 0.8455 - val_loss: 0.1589 - val_accuracy: 0.9492\n",
      "Epoch 1494/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2517 - accuracy: 0.8594 - val_loss: 0.1620 - val_accuracy: 0.9492\n",
      "Epoch 1495/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2513 - accuracy: 0.8653 - val_loss: 0.1506 - val_accuracy: 0.9492\n",
      "Epoch 1496/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2517 - accuracy: 0.8495 - val_loss: 0.1525 - val_accuracy: 0.9492\n",
      "Epoch 1497/2000\n",
      "505/505 [==============================] - 0s 614us/step - loss: 0.2552 - accuracy: 0.8574 - val_loss: 0.1598 - val_accuracy: 0.9492\n",
      "Epoch 1498/2000\n",
      "505/505 [==============================] - 0s 618us/step - loss: 0.2413 - accuracy: 0.8752 - val_loss: 0.1497 - val_accuracy: 0.9492\n",
      "Epoch 1499/2000\n",
      "505/505 [==============================] - 0s 573us/step - loss: 0.2442 - accuracy: 0.8554 - val_loss: 0.1879 - val_accuracy: 0.9492\n",
      "Epoch 1500/2000\n",
      "505/505 [==============================] - 0s 571us/step - loss: 0.2511 - accuracy: 0.8554 - val_loss: 0.1588 - val_accuracy: 0.9492\n",
      "Epoch 1501/2000\n",
      "505/505 [==============================] - 0s 571us/step - loss: 0.2537 - accuracy: 0.8772 - val_loss: 0.1681 - val_accuracy: 0.9492\n",
      "Epoch 1502/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2564 - accuracy: 0.8653 - val_loss: 0.1514 - val_accuracy: 0.9492\n",
      "Epoch 1503/2000\n",
      "505/505 [==============================] - 0s 618us/step - loss: 0.2396 - accuracy: 0.8634 - val_loss: 0.1503 - val_accuracy: 0.9492\n",
      "Epoch 1504/2000\n",
      "505/505 [==============================] - 0s 612us/step - loss: 0.2515 - accuracy: 0.8574 - val_loss: 0.1703 - val_accuracy: 0.9492\n",
      "Epoch 1505/2000\n",
      "505/505 [==============================] - 0s 705us/step - loss: 0.2463 - accuracy: 0.8634 - val_loss: 0.1521 - val_accuracy: 0.9492\n",
      "Epoch 1506/2000\n",
      "505/505 [==============================] - 0s 638us/step - loss: 0.2520 - accuracy: 0.8594 - val_loss: 0.1787 - val_accuracy: 0.9492\n",
      "Epoch 1507/2000\n",
      "505/505 [==============================] - 0s 610us/step - loss: 0.2511 - accuracy: 0.8653 - val_loss: 0.1616 - val_accuracy: 0.9492\n",
      "Epoch 1508/2000\n",
      "505/505 [==============================] - 0s 563us/step - loss: 0.2535 - accuracy: 0.8594 - val_loss: 0.1525 - val_accuracy: 0.9492\n",
      "Epoch 1509/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2513 - accuracy: 0.8535 - val_loss: 0.1473 - val_accuracy: 0.9492\n",
      "Epoch 1510/2000\n",
      "505/505 [==============================] - 0s 569us/step - loss: 0.2602 - accuracy: 0.8515 - val_loss: 0.1517 - val_accuracy: 0.9322\n",
      "Epoch 1511/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2484 - accuracy: 0.8594 - val_loss: 0.1521 - val_accuracy: 0.9492\n",
      "Epoch 1512/2000\n",
      "505/505 [==============================] - 0s 592us/step - loss: 0.2442 - accuracy: 0.8653 - val_loss: 0.1506 - val_accuracy: 0.9492\n",
      "Epoch 1513/2000\n",
      "505/505 [==============================] - 0s 573us/step - loss: 0.2567 - accuracy: 0.8574 - val_loss: 0.1707 - val_accuracy: 0.9492\n",
      "Epoch 1514/2000\n",
      "505/505 [==============================] - 0s 547us/step - loss: 0.2484 - accuracy: 0.8535 - val_loss: 0.1555 - val_accuracy: 0.9492\n",
      "Epoch 1515/2000\n",
      "505/505 [==============================] - 0s 610us/step - loss: 0.2569 - accuracy: 0.8535 - val_loss: 0.1509 - val_accuracy: 0.9322\n",
      "Epoch 1516/2000\n",
      "505/505 [==============================] - 0s 583us/step - loss: 0.2587 - accuracy: 0.8416 - val_loss: 0.1537 - val_accuracy: 0.9492\n",
      "Epoch 1517/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2443 - accuracy: 0.8653 - val_loss: 0.1524 - val_accuracy: 0.9492\n",
      "Epoch 1518/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2555 - accuracy: 0.8495 - val_loss: 0.1461 - val_accuracy: 0.9492\n",
      "Epoch 1519/2000\n",
      "505/505 [==============================] - 0s 608us/step - loss: 0.2491 - accuracy: 0.8574 - val_loss: 0.1534 - val_accuracy: 0.9492\n",
      "Epoch 1520/2000\n",
      "505/505 [==============================] - 0s 634us/step - loss: 0.2401 - accuracy: 0.8713 - val_loss: 0.1544 - val_accuracy: 0.9492\n",
      "Epoch 1521/2000\n",
      "505/505 [==============================] - 0s 713us/step - loss: 0.2541 - accuracy: 0.8614 - val_loss: 0.1508 - val_accuracy: 0.9492\n",
      "Epoch 1522/2000\n",
      "505/505 [==============================] - 0s 616us/step - loss: 0.2512 - accuracy: 0.8772 - val_loss: 0.2078 - val_accuracy: 0.9153\n",
      "Epoch 1523/2000\n",
      "505/505 [==============================] - 0s 634us/step - loss: 0.2567 - accuracy: 0.8673 - val_loss: 0.1554 - val_accuracy: 0.9492\n",
      "Epoch 1524/2000\n",
      "505/505 [==============================] - 0s 610us/step - loss: 0.2509 - accuracy: 0.8554 - val_loss: 0.1568 - val_accuracy: 0.9492\n",
      "Epoch 1525/2000\n",
      "505/505 [==============================] - 0s 646us/step - loss: 0.2473 - accuracy: 0.8752 - val_loss: 0.1649 - val_accuracy: 0.9322\n",
      "Epoch 1526/2000\n",
      "505/505 [==============================] - 0s 652us/step - loss: 0.2584 - accuracy: 0.8554 - val_loss: 0.1549 - val_accuracy: 0.9492\n",
      "Epoch 1527/2000\n",
      "505/505 [==============================] - 0s 650us/step - loss: 0.2509 - accuracy: 0.8614 - val_loss: 0.2008 - val_accuracy: 0.9322\n",
      "Epoch 1528/2000\n",
      "505/505 [==============================] - 0s 591us/step - loss: 0.2465 - accuracy: 0.8693 - val_loss: 0.1526 - val_accuracy: 0.9492\n",
      "Epoch 1529/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2489 - accuracy: 0.8455 - val_loss: 0.1491 - val_accuracy: 0.9492\n",
      "Epoch 1530/2000\n",
      "505/505 [==============================] - 0s 608us/step - loss: 0.2560 - accuracy: 0.8515 - val_loss: 0.1548 - val_accuracy: 0.9492\n",
      "Epoch 1531/2000\n",
      "505/505 [==============================] - 0s 583us/step - loss: 0.2471 - accuracy: 0.8515 - val_loss: 0.1462 - val_accuracy: 0.9492\n",
      "Epoch 1532/2000\n",
      "505/505 [==============================] - 0s 612us/step - loss: 0.2356 - accuracy: 0.8851 - val_loss: 0.1577 - val_accuracy: 0.9492\n",
      "Epoch 1533/2000\n",
      "505/505 [==============================] - 0s 594us/step - loss: 0.2472 - accuracy: 0.8693 - val_loss: 0.1494 - val_accuracy: 0.9492\n",
      "Epoch 1534/2000\n",
      "505/505 [==============================] - 0s 573us/step - loss: 0.2522 - accuracy: 0.8653 - val_loss: 0.1499 - val_accuracy: 0.9492\n",
      "Epoch 1535/2000\n",
      "505/505 [==============================] - 0s 573us/step - loss: 0.2470 - accuracy: 0.8614 - val_loss: 0.1588 - val_accuracy: 0.9492\n",
      "Epoch 1536/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2451 - accuracy: 0.8653 - val_loss: 0.1437 - val_accuracy: 0.9492\n",
      "Epoch 1537/2000\n",
      "505/505 [==============================] - 0s 608us/step - loss: 0.2492 - accuracy: 0.8475 - val_loss: 0.1520 - val_accuracy: 0.9492\n",
      "Epoch 1538/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2418 - accuracy: 0.8653 - val_loss: 0.1588 - val_accuracy: 0.9153\n",
      "Epoch 1539/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2509 - accuracy: 0.8653 - val_loss: 0.1490 - val_accuracy: 0.9492\n",
      "Epoch 1540/2000\n",
      "505/505 [==============================] - 0s 569us/step - loss: 0.2381 - accuracy: 0.8851 - val_loss: 0.1451 - val_accuracy: 0.9492\n",
      "Epoch 1541/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2606 - accuracy: 0.8356 - val_loss: 0.1759 - val_accuracy: 0.9492\n",
      "Epoch 1542/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 575us/step - loss: 0.2501 - accuracy: 0.8475 - val_loss: 0.1563 - val_accuracy: 0.9492\n",
      "Epoch 1543/2000\n",
      "505/505 [==============================] - 0s 583us/step - loss: 0.2537 - accuracy: 0.8554 - val_loss: 0.1442 - val_accuracy: 0.9492\n",
      "Epoch 1544/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2474 - accuracy: 0.8535 - val_loss: 0.1521 - val_accuracy: 0.9492\n",
      "Epoch 1545/2000\n",
      "505/505 [==============================] - 0s 602us/step - loss: 0.2538 - accuracy: 0.8653 - val_loss: 0.1430 - val_accuracy: 0.9492\n",
      "Epoch 1546/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2583 - accuracy: 0.8515 - val_loss: 0.1536 - val_accuracy: 0.9492\n",
      "Epoch 1547/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2494 - accuracy: 0.8574 - val_loss: 0.1437 - val_accuracy: 0.9492\n",
      "Epoch 1548/2000\n",
      "505/505 [==============================] - 0s 610us/step - loss: 0.2457 - accuracy: 0.8554 - val_loss: 0.1437 - val_accuracy: 0.9492\n",
      "Epoch 1549/2000\n",
      "505/505 [==============================] - 0s 695us/step - loss: 0.2505 - accuracy: 0.8634 - val_loss: 0.1440 - val_accuracy: 0.9492\n",
      "Epoch 1550/2000\n",
      "505/505 [==============================] - 0s 640us/step - loss: 0.2491 - accuracy: 0.8634 - val_loss: 0.1436 - val_accuracy: 0.9492\n",
      "Epoch 1551/2000\n",
      "505/505 [==============================] - 0s 622us/step - loss: 0.2433 - accuracy: 0.8673 - val_loss: 0.1443 - val_accuracy: 0.9492\n",
      "Epoch 1552/2000\n",
      "505/505 [==============================] - 0s 654us/step - loss: 0.2531 - accuracy: 0.8535 - val_loss: 0.1429 - val_accuracy: 0.9492\n",
      "Epoch 1553/2000\n",
      "505/505 [==============================] - 0s 620us/step - loss: 0.2476 - accuracy: 0.8653 - val_loss: 0.1457 - val_accuracy: 0.9492\n",
      "Epoch 1554/2000\n",
      "505/505 [==============================] - 0s 592us/step - loss: 0.2529 - accuracy: 0.8436 - val_loss: 0.1421 - val_accuracy: 0.9492\n",
      "Epoch 1555/2000\n",
      "505/505 [==============================] - 0s 628us/step - loss: 0.2508 - accuracy: 0.8594 - val_loss: 0.1433 - val_accuracy: 0.9492\n",
      "Epoch 1556/2000\n",
      "505/505 [==============================] - 0s 646us/step - loss: 0.2444 - accuracy: 0.8554 - val_loss: 0.1759 - val_accuracy: 0.9492\n",
      "Epoch 1557/2000\n",
      "505/505 [==============================] - 0s 666us/step - loss: 0.2480 - accuracy: 0.8653 - val_loss: 0.1480 - val_accuracy: 0.9492\n",
      "Epoch 1558/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2522 - accuracy: 0.8495 - val_loss: 0.1518 - val_accuracy: 0.9492\n",
      "Epoch 1559/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2539 - accuracy: 0.8554 - val_loss: 0.1417 - val_accuracy: 0.9492\n",
      "Epoch 1560/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2446 - accuracy: 0.8693 - val_loss: 0.1456 - val_accuracy: 0.9492\n",
      "Epoch 1561/2000\n",
      "505/505 [==============================] - 0s 622us/step - loss: 0.2357 - accuracy: 0.8752 - val_loss: 0.1427 - val_accuracy: 0.9492\n",
      "Epoch 1562/2000\n",
      "505/505 [==============================] - 0s 640us/step - loss: 0.2496 - accuracy: 0.8475 - val_loss: 0.1439 - val_accuracy: 0.9492\n",
      "Epoch 1563/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2478 - accuracy: 0.8554 - val_loss: 0.1409 - val_accuracy: 0.9492\n",
      "Epoch 1564/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2569 - accuracy: 0.8337 - val_loss: 0.1596 - val_accuracy: 0.9492\n",
      "Epoch 1565/2000\n",
      "505/505 [==============================] - 0s 567us/step - loss: 0.2502 - accuracy: 0.8455 - val_loss: 0.1467 - val_accuracy: 0.9492\n",
      "Epoch 1566/2000\n",
      "505/505 [==============================] - 0s 565us/step - loss: 0.2416 - accuracy: 0.8614 - val_loss: 0.1588 - val_accuracy: 0.9492\n",
      "Epoch 1567/2000\n",
      "505/505 [==============================] - 0s 571us/step - loss: 0.2425 - accuracy: 0.8634 - val_loss: 0.1441 - val_accuracy: 0.9492\n",
      "Epoch 1568/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2428 - accuracy: 0.8554 - val_loss: 0.1547 - val_accuracy: 0.9492\n",
      "Epoch 1569/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2560 - accuracy: 0.8653 - val_loss: 0.1542 - val_accuracy: 0.9492\n",
      "Epoch 1570/2000\n",
      "505/505 [==============================] - 0s 602us/step - loss: 0.2586 - accuracy: 0.8515 - val_loss: 0.1484 - val_accuracy: 0.9492\n",
      "Epoch 1571/2000\n",
      "505/505 [==============================] - 0s 583us/step - loss: 0.2589 - accuracy: 0.8396 - val_loss: 0.1406 - val_accuracy: 0.9492\n",
      "Epoch 1572/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2470 - accuracy: 0.8634 - val_loss: 0.1600 - val_accuracy: 0.9492\n",
      "Epoch 1573/2000\n",
      "505/505 [==============================] - 0s 567us/step - loss: 0.2555 - accuracy: 0.8535 - val_loss: 0.1508 - val_accuracy: 0.9492\n",
      "Epoch 1574/2000\n",
      "505/505 [==============================] - 0s 592us/step - loss: 0.2584 - accuracy: 0.8475 - val_loss: 0.1534 - val_accuracy: 0.9492\n",
      "Epoch 1575/2000\n",
      "505/505 [==============================] - 0s 683us/step - loss: 0.2468 - accuracy: 0.8673 - val_loss: 0.1437 - val_accuracy: 0.9492\n",
      "Epoch 1576/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2524 - accuracy: 0.8515 - val_loss: 0.1504 - val_accuracy: 0.9492\n",
      "Epoch 1577/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2429 - accuracy: 0.8594 - val_loss: 0.1487 - val_accuracy: 0.9492\n",
      "Epoch 1578/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2387 - accuracy: 0.8733 - val_loss: 0.1425 - val_accuracy: 0.9492\n",
      "Epoch 1579/2000\n",
      "505/505 [==============================] - 0s 606us/step - loss: 0.2503 - accuracy: 0.8475 - val_loss: 0.1527 - val_accuracy: 0.9492\n",
      "Epoch 1580/2000\n",
      "505/505 [==============================] - 0s 616us/step - loss: 0.2512 - accuracy: 0.8515 - val_loss: 0.1394 - val_accuracy: 0.9492\n",
      "Epoch 1581/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2562 - accuracy: 0.8594 - val_loss: 0.1535 - val_accuracy: 0.9492\n",
      "Epoch 1582/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2529 - accuracy: 0.8574 - val_loss: 0.1402 - val_accuracy: 0.9492\n",
      "Epoch 1583/2000\n",
      "505/505 [==============================] - 0s 632us/step - loss: 0.2485 - accuracy: 0.8693 - val_loss: 0.1433 - val_accuracy: 0.9492\n",
      "Epoch 1584/2000\n",
      "505/505 [==============================] - 0s 675us/step - loss: 0.2431 - accuracy: 0.8693 - val_loss: 0.1500 - val_accuracy: 0.9492\n",
      "Epoch 1585/2000\n",
      "505/505 [==============================] - 0s 632us/step - loss: 0.2551 - accuracy: 0.8495 - val_loss: 0.1482 - val_accuracy: 0.9492\n",
      "Epoch 1586/2000\n",
      "505/505 [==============================] - 0s 608us/step - loss: 0.2589 - accuracy: 0.8376 - val_loss: 0.1393 - val_accuracy: 0.9492\n",
      "Epoch 1587/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2462 - accuracy: 0.8673 - val_loss: 0.1416 - val_accuracy: 0.9492\n",
      "Epoch 1588/2000\n",
      "505/505 [==============================] - 0s 598us/step - loss: 0.2397 - accuracy: 0.8851 - val_loss: 0.1438 - val_accuracy: 0.9492\n",
      "Epoch 1589/2000\n",
      "505/505 [==============================] - 0s 691us/step - loss: 0.2480 - accuracy: 0.8554 - val_loss: 0.1445 - val_accuracy: 0.9492\n",
      "Epoch 1590/2000\n",
      "505/505 [==============================] - 0s 636us/step - loss: 0.2542 - accuracy: 0.8594 - val_loss: 0.1402 - val_accuracy: 0.9492\n",
      "Epoch 1591/2000\n",
      "505/505 [==============================] - 0s 616us/step - loss: 0.2498 - accuracy: 0.8574 - val_loss: 0.1413 - val_accuracy: 0.9492\n",
      "Epoch 1592/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2568 - accuracy: 0.8535 - val_loss: 0.1451 - val_accuracy: 0.9492\n",
      "Epoch 1593/2000\n",
      "505/505 [==============================] - 0s 612us/step - loss: 0.2512 - accuracy: 0.8614 - val_loss: 0.1492 - val_accuracy: 0.9492\n",
      "Epoch 1594/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2460 - accuracy: 0.8554 - val_loss: 0.1403 - val_accuracy: 0.9492\n",
      "Epoch 1595/2000\n",
      "505/505 [==============================] - 0s 648us/step - loss: 0.2408 - accuracy: 0.8772 - val_loss: 0.1504 - val_accuracy: 0.9492\n",
      "Epoch 1596/2000\n",
      "505/505 [==============================] - 0s 606us/step - loss: 0.2572 - accuracy: 0.8515 - val_loss: 0.1425 - val_accuracy: 0.9492\n",
      "Epoch 1597/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 622us/step - loss: 0.2539 - accuracy: 0.8475 - val_loss: 0.1490 - val_accuracy: 0.9492\n",
      "Epoch 1598/2000\n",
      "505/505 [==============================] - 0s 636us/step - loss: 0.2535 - accuracy: 0.8634 - val_loss: 0.1504 - val_accuracy: 0.9492\n",
      "Epoch 1599/2000\n",
      "505/505 [==============================] - 0s 640us/step - loss: 0.2549 - accuracy: 0.8574 - val_loss: 0.1587 - val_accuracy: 0.9492\n",
      "Epoch 1600/2000\n",
      "505/505 [==============================] - 0s 590us/step - loss: 0.2501 - accuracy: 0.8574 - val_loss: 0.1412 - val_accuracy: 0.9492\n",
      "Epoch 1601/2000\n",
      "505/505 [==============================] - 0s 656us/step - loss: 0.2463 - accuracy: 0.8455 - val_loss: 0.1498 - val_accuracy: 0.9492\n",
      "Epoch 1602/2000\n",
      "505/505 [==============================] - 0s 608us/step - loss: 0.2505 - accuracy: 0.8515 - val_loss: 0.1488 - val_accuracy: 0.9492\n",
      "Epoch 1603/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2509 - accuracy: 0.8436 - val_loss: 0.1401 - val_accuracy: 0.9492\n",
      "Epoch 1604/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2381 - accuracy: 0.8772 - val_loss: 0.1391 - val_accuracy: 0.9492\n",
      "Epoch 1605/2000\n",
      "505/505 [==============================] - 0s 575us/step - loss: 0.2521 - accuracy: 0.8495 - val_loss: 0.1529 - val_accuracy: 0.9492\n",
      "Epoch 1606/2000\n",
      "505/505 [==============================] - 0s 571us/step - loss: 0.2474 - accuracy: 0.8574 - val_loss: 0.1450 - val_accuracy: 0.9492\n",
      "Epoch 1607/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2447 - accuracy: 0.8693 - val_loss: 0.1581 - val_accuracy: 0.9153\n",
      "Epoch 1608/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2523 - accuracy: 0.8574 - val_loss: 0.1556 - val_accuracy: 0.9492\n",
      "Epoch 1609/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2469 - accuracy: 0.8594 - val_loss: 0.1561 - val_accuracy: 0.9492\n",
      "Epoch 1610/2000\n",
      "505/505 [==============================] - 0s 618us/step - loss: 0.2462 - accuracy: 0.8634 - val_loss: 0.1409 - val_accuracy: 0.9492\n",
      "Epoch 1611/2000\n",
      "505/505 [==============================] - 0s 612us/step - loss: 0.2448 - accuracy: 0.8495 - val_loss: 0.1422 - val_accuracy: 0.9492\n",
      "Epoch 1612/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2482 - accuracy: 0.8554 - val_loss: 0.1479 - val_accuracy: 0.9492\n",
      "Epoch 1613/2000\n",
      "505/505 [==============================] - 0s 565us/step - loss: 0.2470 - accuracy: 0.8594 - val_loss: 0.1535 - val_accuracy: 0.9492\n",
      "Epoch 1614/2000\n",
      "505/505 [==============================] - 0s 596us/step - loss: 0.2516 - accuracy: 0.8515 - val_loss: 0.1408 - val_accuracy: 0.9492\n",
      "Epoch 1615/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2500 - accuracy: 0.8574 - val_loss: 0.1431 - val_accuracy: 0.9492\n",
      "Epoch 1616/2000\n",
      "505/505 [==============================] - 0s 715us/step - loss: 0.2461 - accuracy: 0.8634 - val_loss: 0.1406 - val_accuracy: 0.9492\n",
      "Epoch 1617/2000\n",
      "505/505 [==============================] - 0s 654us/step - loss: 0.2363 - accuracy: 0.8812 - val_loss: 0.1513 - val_accuracy: 0.9153\n",
      "Epoch 1618/2000\n",
      "505/505 [==============================] - 0s 833us/step - loss: 0.2584 - accuracy: 0.8515 - val_loss: 0.1384 - val_accuracy: 0.9492\n",
      "Epoch 1619/2000\n",
      "505/505 [==============================] - 0s 711us/step - loss: 0.2469 - accuracy: 0.8713 - val_loss: 0.1407 - val_accuracy: 0.9492\n",
      "Epoch 1620/2000\n",
      "505/505 [==============================] - 0s 642us/step - loss: 0.2469 - accuracy: 0.8634 - val_loss: 0.1408 - val_accuracy: 0.9492\n",
      "Epoch 1621/2000\n",
      "505/505 [==============================] - 0s 677us/step - loss: 0.2410 - accuracy: 0.8653 - val_loss: 0.1395 - val_accuracy: 0.9492\n",
      "Epoch 1622/2000\n",
      "505/505 [==============================] - 0s 626us/step - loss: 0.2535 - accuracy: 0.8515 - val_loss: 0.1375 - val_accuracy: 0.9492\n",
      "Epoch 1623/2000\n",
      "505/505 [==============================] - 0s 666us/step - loss: 0.2492 - accuracy: 0.8594 - val_loss: 0.1409 - val_accuracy: 0.9492\n",
      "Epoch 1624/2000\n",
      "505/505 [==============================] - 0s 808us/step - loss: 0.2528 - accuracy: 0.8475 - val_loss: 0.1451 - val_accuracy: 0.9492\n",
      "Epoch 1625/2000\n",
      "505/505 [==============================] - 0s 709us/step - loss: 0.2486 - accuracy: 0.8594 - val_loss: 0.1550 - val_accuracy: 0.9492\n",
      "Epoch 1626/2000\n",
      "505/505 [==============================] - 0s 717us/step - loss: 0.2428 - accuracy: 0.8673 - val_loss: 0.1375 - val_accuracy: 0.9492\n",
      "Epoch 1627/2000\n",
      "505/505 [==============================] - 0s 612us/step - loss: 0.2453 - accuracy: 0.8713 - val_loss: 0.1487 - val_accuracy: 0.9492\n",
      "Epoch 1628/2000\n",
      "505/505 [==============================] - 0s 590us/step - loss: 0.2549 - accuracy: 0.8614 - val_loss: 0.1466 - val_accuracy: 0.9492\n",
      "Epoch 1629/2000\n",
      "505/505 [==============================] - 0s 634us/step - loss: 0.2514 - accuracy: 0.8574 - val_loss: 0.1605 - val_accuracy: 0.9492\n",
      "Epoch 1630/2000\n",
      "505/505 [==============================] - 0s 636us/step - loss: 0.2486 - accuracy: 0.8535 - val_loss: 0.1397 - val_accuracy: 0.9492\n",
      "Epoch 1631/2000\n",
      "505/505 [==============================] - 0s 660us/step - loss: 0.2558 - accuracy: 0.8495 - val_loss: 0.1423 - val_accuracy: 0.9492\n",
      "Epoch 1632/2000\n",
      "505/505 [==============================] - 0s 666us/step - loss: 0.2551 - accuracy: 0.8495 - val_loss: 0.1396 - val_accuracy: 0.9492\n",
      "Epoch 1633/2000\n",
      "505/505 [==============================] - 0s 624us/step - loss: 0.2450 - accuracy: 0.8574 - val_loss: 0.1381 - val_accuracy: 0.9492\n",
      "Epoch 1634/2000\n",
      "505/505 [==============================] - 0s 626us/step - loss: 0.2330 - accuracy: 0.8832 - val_loss: 0.1452 - val_accuracy: 0.9492\n",
      "Epoch 1635/2000\n",
      "505/505 [==============================] - 0s 735us/step - loss: 0.2456 - accuracy: 0.8673 - val_loss: 0.1402 - val_accuracy: 0.9492\n",
      "Epoch 1636/2000\n",
      "505/505 [==============================] - 0s 650us/step - loss: 0.2485 - accuracy: 0.8515 - val_loss: 0.1531 - val_accuracy: 0.9492\n",
      "Epoch 1637/2000\n",
      "505/505 [==============================] - 0s 632us/step - loss: 0.2487 - accuracy: 0.8396 - val_loss: 0.1417 - val_accuracy: 0.9492\n",
      "Epoch 1638/2000\n",
      "505/505 [==============================] - 0s 628us/step - loss: 0.2590 - accuracy: 0.8416 - val_loss: 0.1374 - val_accuracy: 0.9492\n",
      "Epoch 1639/2000\n",
      "505/505 [==============================] - 0s 632us/step - loss: 0.2471 - accuracy: 0.8475 - val_loss: 0.1402 - val_accuracy: 0.9492\n",
      "Epoch 1640/2000\n",
      "505/505 [==============================] - 0s 608us/step - loss: 0.2510 - accuracy: 0.8634 - val_loss: 0.1550 - val_accuracy: 0.9153\n",
      "Epoch 1641/2000\n",
      "505/505 [==============================] - 0s 630us/step - loss: 0.2493 - accuracy: 0.8614 - val_loss: 0.1466 - val_accuracy: 0.9492\n",
      "Epoch 1642/2000\n",
      "505/505 [==============================] - 0s 591us/step - loss: 0.2554 - accuracy: 0.8337 - val_loss: 0.1552 - val_accuracy: 0.9492\n",
      "Epoch 1643/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2549 - accuracy: 0.8614 - val_loss: 0.1399 - val_accuracy: 0.9492\n",
      "Epoch 1644/2000\n",
      "505/505 [==============================] - 0s 618us/step - loss: 0.2483 - accuracy: 0.8574 - val_loss: 0.1374 - val_accuracy: 0.9492\n",
      "Epoch 1645/2000\n",
      "505/505 [==============================] - 0s 624us/step - loss: 0.2453 - accuracy: 0.8693 - val_loss: 0.1465 - val_accuracy: 0.9492\n",
      "Epoch 1646/2000\n",
      "505/505 [==============================] - 0s 608us/step - loss: 0.2445 - accuracy: 0.8574 - val_loss: 0.1363 - val_accuracy: 0.9492\n",
      "Epoch 1647/2000\n",
      "505/505 [==============================] - 0s 608us/step - loss: 0.2516 - accuracy: 0.8317 - val_loss: 0.1372 - val_accuracy: 0.9492\n",
      "Epoch 1648/2000\n",
      "505/505 [==============================] - 0s 709us/step - loss: 0.2510 - accuracy: 0.8614 - val_loss: 0.1403 - val_accuracy: 0.9492\n",
      "Epoch 1649/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2567 - accuracy: 0.8475 - val_loss: 0.1376 - val_accuracy: 0.9492\n",
      "Epoch 1650/2000\n",
      "505/505 [==============================] - 0s 630us/step - loss: 0.2465 - accuracy: 0.8396 - val_loss: 0.1420 - val_accuracy: 0.9492\n",
      "Epoch 1651/2000\n",
      "505/505 [==============================] - 0s 598us/step - loss: 0.2473 - accuracy: 0.8436 - val_loss: 0.1360 - val_accuracy: 0.9492\n",
      "Epoch 1652/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 614us/step - loss: 0.2496 - accuracy: 0.8554 - val_loss: 0.1448 - val_accuracy: 0.9492\n",
      "Epoch 1653/2000\n",
      "505/505 [==============================] - 0s 606us/step - loss: 0.2536 - accuracy: 0.8515 - val_loss: 0.1371 - val_accuracy: 0.9492\n",
      "Epoch 1654/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2380 - accuracy: 0.8554 - val_loss: 0.1404 - val_accuracy: 0.9492\n",
      "Epoch 1655/2000\n",
      "505/505 [==============================] - 0s 594us/step - loss: 0.2513 - accuracy: 0.8594 - val_loss: 0.1384 - val_accuracy: 0.9492\n",
      "Epoch 1656/2000\n",
      "505/505 [==============================] - 0s 569us/step - loss: 0.2550 - accuracy: 0.8475 - val_loss: 0.1407 - val_accuracy: 0.9492\n",
      "Epoch 1657/2000\n",
      "505/505 [==============================] - 0s 567us/step - loss: 0.2522 - accuracy: 0.8416 - val_loss: 0.1486 - val_accuracy: 0.9492\n",
      "Epoch 1658/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2533 - accuracy: 0.8535 - val_loss: 0.1369 - val_accuracy: 0.9492\n",
      "Epoch 1659/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2572 - accuracy: 0.8416 - val_loss: 0.1362 - val_accuracy: 0.9492\n",
      "Epoch 1660/2000\n",
      "505/505 [==============================] - 0s 565us/step - loss: 0.2502 - accuracy: 0.8554 - val_loss: 0.1364 - val_accuracy: 0.9492\n",
      "Epoch 1661/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2489 - accuracy: 0.8673 - val_loss: 0.1473 - val_accuracy: 0.8983\n",
      "Epoch 1662/2000\n",
      "505/505 [==============================] - 0s 573us/step - loss: 0.2620 - accuracy: 0.8436 - val_loss: 0.1346 - val_accuracy: 0.9492\n",
      "Epoch 1663/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2509 - accuracy: 0.8594 - val_loss: 0.1356 - val_accuracy: 0.9492\n",
      "Epoch 1664/2000\n",
      "505/505 [==============================] - 0s 569us/step - loss: 0.2407 - accuracy: 0.8653 - val_loss: 0.1403 - val_accuracy: 0.9492\n",
      "Epoch 1665/2000\n",
      "505/505 [==============================] - 0s 571us/step - loss: 0.2552 - accuracy: 0.8475 - val_loss: 0.1395 - val_accuracy: 0.9492\n",
      "Epoch 1666/2000\n",
      "505/505 [==============================] - 0s 575us/step - loss: 0.2419 - accuracy: 0.8673 - val_loss: 0.1347 - val_accuracy: 0.9492\n",
      "Epoch 1667/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2416 - accuracy: 0.8574 - val_loss: 0.1424 - val_accuracy: 0.9492\n",
      "Epoch 1668/2000\n",
      "505/505 [==============================] - 0s 567us/step - loss: 0.2544 - accuracy: 0.8495 - val_loss: 0.1426 - val_accuracy: 0.9492\n",
      "Epoch 1669/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2513 - accuracy: 0.8475 - val_loss: 0.1489 - val_accuracy: 0.9492\n",
      "Epoch 1670/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2527 - accuracy: 0.8554 - val_loss: 0.1366 - val_accuracy: 0.9492\n",
      "Epoch 1671/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2491 - accuracy: 0.8653 - val_loss: 0.1405 - val_accuracy: 0.9492\n",
      "Epoch 1672/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2452 - accuracy: 0.8455 - val_loss: 0.1368 - val_accuracy: 0.9492\n",
      "Epoch 1673/2000\n",
      "505/505 [==============================] - 0s 604us/step - loss: 0.2536 - accuracy: 0.8495 - val_loss: 0.1466 - val_accuracy: 0.9492\n",
      "Epoch 1674/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2537 - accuracy: 0.8356 - val_loss: 0.1366 - val_accuracy: 0.9492\n",
      "Epoch 1675/2000\n",
      "505/505 [==============================] - 0s 571us/step - loss: 0.2484 - accuracy: 0.8634 - val_loss: 0.1390 - val_accuracy: 0.9492\n",
      "Epoch 1676/2000\n",
      "505/505 [==============================] - 0s 557us/step - loss: 0.2483 - accuracy: 0.8634 - val_loss: 0.1554 - val_accuracy: 0.9492\n",
      "Epoch 1677/2000\n",
      "505/505 [==============================] - 0s 583us/step - loss: 0.2550 - accuracy: 0.8356 - val_loss: 0.1415 - val_accuracy: 0.9492\n",
      "Epoch 1678/2000\n",
      "505/505 [==============================] - 0s 591us/step - loss: 0.2399 - accuracy: 0.8673 - val_loss: 0.1508 - val_accuracy: 0.9492\n",
      "Epoch 1679/2000\n",
      "505/505 [==============================] - 0s 561us/step - loss: 0.2495 - accuracy: 0.8535 - val_loss: 0.1444 - val_accuracy: 0.9492\n",
      "Epoch 1680/2000\n",
      "505/505 [==============================] - 0s 575us/step - loss: 0.2499 - accuracy: 0.8495 - val_loss: 0.1352 - val_accuracy: 0.9492\n",
      "Epoch 1681/2000\n",
      "505/505 [==============================] - 0s 561us/step - loss: 0.2434 - accuracy: 0.8594 - val_loss: 0.1339 - val_accuracy: 0.9492\n",
      "Epoch 1682/2000\n",
      "505/505 [==============================] - 0s 575us/step - loss: 0.2473 - accuracy: 0.8455 - val_loss: 0.1341 - val_accuracy: 0.9492\n",
      "Epoch 1683/2000\n",
      "505/505 [==============================] - 0s 563us/step - loss: 0.2447 - accuracy: 0.8733 - val_loss: 0.1373 - val_accuracy: 0.9492\n",
      "Epoch 1684/2000\n",
      "505/505 [==============================] - 0s 565us/step - loss: 0.2494 - accuracy: 0.8416 - val_loss: 0.1382 - val_accuracy: 0.9492\n",
      "Epoch 1685/2000\n",
      "505/505 [==============================] - 0s 559us/step - loss: 0.2480 - accuracy: 0.8436 - val_loss: 0.1422 - val_accuracy: 0.9492\n",
      "Epoch 1686/2000\n",
      "505/505 [==============================] - 0s 577us/step - loss: 0.2548 - accuracy: 0.8436 - val_loss: 0.1328 - val_accuracy: 0.9492\n",
      "Epoch 1687/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2431 - accuracy: 0.8574 - val_loss: 0.1318 - val_accuracy: 0.9492\n",
      "Epoch 1688/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2537 - accuracy: 0.8416 - val_loss: 0.1342 - val_accuracy: 0.9492\n",
      "Epoch 1689/2000\n",
      "505/505 [==============================] - 0s 589us/step - loss: 0.2486 - accuracy: 0.8475 - val_loss: 0.1389 - val_accuracy: 0.9492\n",
      "Epoch 1690/2000\n",
      "505/505 [==============================] - 0s 573us/step - loss: 0.2456 - accuracy: 0.8535 - val_loss: 0.1445 - val_accuracy: 0.9492\n",
      "Epoch 1691/2000\n",
      "505/505 [==============================] - 0s 610us/step - loss: 0.2493 - accuracy: 0.8574 - val_loss: 0.1359 - val_accuracy: 0.9492\n",
      "Epoch 1692/2000\n",
      "505/505 [==============================] - 0s 610us/step - loss: 0.2507 - accuracy: 0.8535 - val_loss: 0.1359 - val_accuracy: 0.9492\n",
      "Epoch 1693/2000\n",
      "505/505 [==============================] - 0s 583us/step - loss: 0.2619 - accuracy: 0.8416 - val_loss: 0.1366 - val_accuracy: 0.9492\n",
      "Epoch 1694/2000\n",
      "505/505 [==============================] - 0s 563us/step - loss: 0.2544 - accuracy: 0.8515 - val_loss: 0.1347 - val_accuracy: 0.9492\n",
      "Epoch 1695/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2480 - accuracy: 0.8594 - val_loss: 0.1361 - val_accuracy: 0.9492\n",
      "Epoch 1696/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2502 - accuracy: 0.8495 - val_loss: 0.1364 - val_accuracy: 0.9492\n",
      "Epoch 1697/2000\n",
      "505/505 [==============================] - 0s 604us/step - loss: 0.2409 - accuracy: 0.8673 - val_loss: 0.1380 - val_accuracy: 0.9492\n",
      "Epoch 1698/2000\n",
      "505/505 [==============================] - 0s 565us/step - loss: 0.2578 - accuracy: 0.8376 - val_loss: 0.1321 - val_accuracy: 0.9492\n",
      "Epoch 1699/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2359 - accuracy: 0.8733 - val_loss: 0.1367 - val_accuracy: 0.9492\n",
      "Epoch 1700/2000\n",
      "505/505 [==============================] - 0s 555us/step - loss: 0.2467 - accuracy: 0.8515 - val_loss: 0.1380 - val_accuracy: 0.9492\n",
      "Epoch 1701/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2521 - accuracy: 0.8515 - val_loss: 0.1346 - val_accuracy: 0.9492\n",
      "Epoch 1702/2000\n",
      "505/505 [==============================] - 0s 591us/step - loss: 0.2481 - accuracy: 0.8455 - val_loss: 0.1331 - val_accuracy: 0.9492\n",
      "Epoch 1703/2000\n",
      "505/505 [==============================] - 0s 622us/step - loss: 0.2570 - accuracy: 0.8455 - val_loss: 0.1374 - val_accuracy: 0.9492\n",
      "Epoch 1704/2000\n",
      "505/505 [==============================] - 0s 573us/step - loss: 0.2506 - accuracy: 0.8416 - val_loss: 0.1491 - val_accuracy: 0.9492\n",
      "Epoch 1705/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2551 - accuracy: 0.8416 - val_loss: 0.1341 - val_accuracy: 0.9492\n",
      "Epoch 1706/2000\n",
      "505/505 [==============================] - 0s 650us/step - loss: 0.2447 - accuracy: 0.8574 - val_loss: 0.1341 - val_accuracy: 0.9492\n",
      "Epoch 1707/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 616us/step - loss: 0.2447 - accuracy: 0.8416 - val_loss: 0.1321 - val_accuracy: 0.9492\n",
      "Epoch 1708/2000\n",
      "505/505 [==============================] - 0s 610us/step - loss: 0.2544 - accuracy: 0.8475 - val_loss: 0.1335 - val_accuracy: 0.9492\n",
      "Epoch 1709/2000\n",
      "505/505 [==============================] - 0s 612us/step - loss: 0.2530 - accuracy: 0.8436 - val_loss: 0.1345 - val_accuracy: 0.9492\n",
      "Epoch 1710/2000\n",
      "505/505 [==============================] - 0s 644us/step - loss: 0.2465 - accuracy: 0.8574 - val_loss: 0.1329 - val_accuracy: 0.9492\n",
      "Epoch 1711/2000\n",
      "505/505 [==============================] - 0s 662us/step - loss: 0.2477 - accuracy: 0.8475 - val_loss: 0.1360 - val_accuracy: 0.9492\n",
      "Epoch 1712/2000\n",
      "505/505 [==============================] - 0s 590us/step - loss: 0.2473 - accuracy: 0.8554 - val_loss: 0.1345 - val_accuracy: 0.9492\n",
      "Epoch 1713/2000\n",
      "505/505 [==============================] - 0s 591us/step - loss: 0.2505 - accuracy: 0.8475 - val_loss: 0.1346 - val_accuracy: 0.9492\n",
      "Epoch 1714/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2573 - accuracy: 0.8436 - val_loss: 0.1329 - val_accuracy: 0.9492\n",
      "Epoch 1715/2000\n",
      "505/505 [==============================] - 0s 648us/step - loss: 0.2451 - accuracy: 0.8515 - val_loss: 0.1456 - val_accuracy: 0.9492\n",
      "Epoch 1716/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2480 - accuracy: 0.8535 - val_loss: 0.1400 - val_accuracy: 0.9492\n",
      "Epoch 1717/2000\n",
      "505/505 [==============================] - 0s 571us/step - loss: 0.2520 - accuracy: 0.8396 - val_loss: 0.1328 - val_accuracy: 0.9492\n",
      "Epoch 1718/2000\n",
      "505/505 [==============================] - 0s 567us/step - loss: 0.2407 - accuracy: 0.8693 - val_loss: 0.1648 - val_accuracy: 0.9492\n",
      "Epoch 1719/2000\n",
      "505/505 [==============================] - 0s 573us/step - loss: 0.2482 - accuracy: 0.8594 - val_loss: 0.1350 - val_accuracy: 0.9492\n",
      "Epoch 1720/2000\n",
      "505/505 [==============================] - 0s 583us/step - loss: 0.2461 - accuracy: 0.8594 - val_loss: 0.1334 - val_accuracy: 0.9492\n",
      "Epoch 1721/2000\n",
      "505/505 [==============================] - 0s 585us/step - loss: 0.2491 - accuracy: 0.8594 - val_loss: 0.1420 - val_accuracy: 0.9492\n",
      "Epoch 1722/2000\n",
      "505/505 [==============================] - 0s 561us/step - loss: 0.2482 - accuracy: 0.8455 - val_loss: 0.1359 - val_accuracy: 0.9492\n",
      "Epoch 1723/2000\n",
      "505/505 [==============================] - 0s 592us/step - loss: 0.2502 - accuracy: 0.8475 - val_loss: 0.1373 - val_accuracy: 0.9492\n",
      "Epoch 1724/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2507 - accuracy: 0.8396 - val_loss: 0.1329 - val_accuracy: 0.9492\n",
      "Epoch 1725/2000\n",
      "505/505 [==============================] - 0s 616us/step - loss: 0.2538 - accuracy: 0.8198 - val_loss: 0.1374 - val_accuracy: 0.9492\n",
      "Epoch 1726/2000\n",
      "505/505 [==============================] - 0s 662us/step - loss: 0.2399 - accuracy: 0.8574 - val_loss: 0.1317 - val_accuracy: 0.9492\n",
      "Epoch 1727/2000\n",
      "505/505 [==============================] - 0s 614us/step - loss: 0.2559 - accuracy: 0.8535 - val_loss: 0.1379 - val_accuracy: 0.9492\n",
      "Epoch 1728/2000\n",
      "505/505 [==============================] - 0s 579us/step - loss: 0.2435 - accuracy: 0.8653 - val_loss: 0.1412 - val_accuracy: 0.9492\n",
      "Epoch 1729/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2483 - accuracy: 0.8614 - val_loss: 0.1301 - val_accuracy: 0.9492\n",
      "Epoch 1730/2000\n",
      "505/505 [==============================] - 0s 598us/step - loss: 0.2505 - accuracy: 0.8396 - val_loss: 0.1314 - val_accuracy: 0.9492\n",
      "Epoch 1731/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2467 - accuracy: 0.8554 - val_loss: 0.1336 - val_accuracy: 0.9492\n",
      "Epoch 1732/2000\n",
      "505/505 [==============================] - 0s 557us/step - loss: 0.2554 - accuracy: 0.8317 - val_loss: 0.1357 - val_accuracy: 0.9492\n",
      "Epoch 1733/2000\n",
      "505/505 [==============================] - 0s 602us/step - loss: 0.2499 - accuracy: 0.8634 - val_loss: 0.1350 - val_accuracy: 0.9492\n",
      "Epoch 1734/2000\n",
      "505/505 [==============================] - 0s 600us/step - loss: 0.2450 - accuracy: 0.8673 - val_loss: 0.1311 - val_accuracy: 0.9492\n",
      "Epoch 1735/2000\n",
      "505/505 [==============================] - 0s 587us/step - loss: 0.2367 - accuracy: 0.8653 - val_loss: 0.1311 - val_accuracy: 0.9492\n",
      "Epoch 1736/2000\n",
      "505/505 [==============================] - 0s 581us/step - loss: 0.2492 - accuracy: 0.8436 - val_loss: 0.1323 - val_accuracy: 0.9492\n",
      "Epoch 1737/2000\n",
      "505/505 [==============================] - 0s 413us/step - loss: 0.2538 - accuracy: 0.8436 - val_loss: 0.1325 - val_accuracy: 0.9492\n",
      "Epoch 1738/2000\n",
      "505/505 [==============================] - 0s 379us/step - loss: 0.2509 - accuracy: 0.8535 - val_loss: 0.1339 - val_accuracy: 0.9492\n",
      "Epoch 1739/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.2533 - accuracy: 0.8515 - val_loss: 0.1331 - val_accuracy: 0.9492\n",
      "Epoch 1740/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.2384 - accuracy: 0.8733 - val_loss: 0.1328 - val_accuracy: 0.9492\n",
      "Epoch 1741/2000\n",
      "505/505 [==============================] - 0s 364us/step - loss: 0.2528 - accuracy: 0.8535 - val_loss: 0.1339 - val_accuracy: 0.9492\n",
      "Epoch 1742/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.2426 - accuracy: 0.8495 - val_loss: 0.1438 - val_accuracy: 0.9492\n",
      "Epoch 1743/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2479 - accuracy: 0.8653 - val_loss: 0.1352 - val_accuracy: 0.9492\n",
      "Epoch 1744/2000\n",
      "505/505 [==============================] - 0s 324us/step - loss: 0.2602 - accuracy: 0.8396 - val_loss: 0.1320 - val_accuracy: 0.9492\n",
      "Epoch 1745/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2422 - accuracy: 0.8634 - val_loss: 0.1319 - val_accuracy: 0.9492\n",
      "Epoch 1746/2000\n",
      "505/505 [==============================] - 0s 375us/step - loss: 0.2330 - accuracy: 0.8752 - val_loss: 0.1314 - val_accuracy: 0.9492\n",
      "Epoch 1747/2000\n",
      "505/505 [==============================] - 0s 409us/step - loss: 0.2429 - accuracy: 0.8653 - val_loss: 0.1347 - val_accuracy: 0.9492\n",
      "Epoch 1748/2000\n",
      "505/505 [==============================] - 0s 436us/step - loss: 0.2538 - accuracy: 0.8455 - val_loss: 0.1344 - val_accuracy: 0.9492\n",
      "Epoch 1749/2000\n",
      "505/505 [==============================] - 0s 433us/step - loss: 0.2490 - accuracy: 0.8495 - val_loss: 0.1335 - val_accuracy: 0.9492\n",
      "Epoch 1750/2000\n",
      "505/505 [==============================] - 0s 377us/step - loss: 0.2469 - accuracy: 0.8574 - val_loss: 0.1319 - val_accuracy: 0.9492\n",
      "Epoch 1751/2000\n",
      "505/505 [==============================] - 0s 415us/step - loss: 0.2494 - accuracy: 0.8515 - val_loss: 0.1327 - val_accuracy: 0.9492\n",
      "Epoch 1752/2000\n",
      "505/505 [==============================] - 0s 381us/step - loss: 0.2508 - accuracy: 0.8317 - val_loss: 0.1314 - val_accuracy: 0.9492\n",
      "Epoch 1753/2000\n",
      "505/505 [==============================] - 0s 385us/step - loss: 0.2439 - accuracy: 0.8554 - val_loss: 0.1317 - val_accuracy: 0.9492\n",
      "Epoch 1754/2000\n",
      "505/505 [==============================] - 0s 381us/step - loss: 0.2418 - accuracy: 0.8653 - val_loss: 0.1326 - val_accuracy: 0.9492\n",
      "Epoch 1755/2000\n",
      "505/505 [==============================] - 0s 379us/step - loss: 0.2524 - accuracy: 0.8475 - val_loss: 0.1437 - val_accuracy: 0.9492\n",
      "Epoch 1756/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2471 - accuracy: 0.8495 - val_loss: 0.1344 - val_accuracy: 0.9492\n",
      "Epoch 1757/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2421 - accuracy: 0.8495 - val_loss: 0.1377 - val_accuracy: 0.9492\n",
      "Epoch 1758/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2512 - accuracy: 0.8535 - val_loss: 0.1354 - val_accuracy: 0.9492\n",
      "Epoch 1759/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2436 - accuracy: 0.8634 - val_loss: 0.1385 - val_accuracy: 0.9492\n",
      "Epoch 1760/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.2458 - accuracy: 0.8614 - val_loss: 0.1314 - val_accuracy: 0.9492\n",
      "Epoch 1761/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2419 - accuracy: 0.8535 - val_loss: 0.1411 - val_accuracy: 0.9492\n",
      "Epoch 1762/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 332us/step - loss: 0.2504 - accuracy: 0.8475 - val_loss: 0.1320 - val_accuracy: 0.9492\n",
      "Epoch 1763/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2414 - accuracy: 0.8495 - val_loss: 0.1324 - val_accuracy: 0.9492\n",
      "Epoch 1764/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.2492 - accuracy: 0.8515 - val_loss: 0.1325 - val_accuracy: 0.9492\n",
      "Epoch 1765/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2396 - accuracy: 0.8574 - val_loss: 0.1342 - val_accuracy: 0.9492\n",
      "Epoch 1766/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2422 - accuracy: 0.8574 - val_loss: 0.1348 - val_accuracy: 0.9492\n",
      "Epoch 1767/2000\n",
      "505/505 [==============================] - 0s 370us/step - loss: 0.2555 - accuracy: 0.8614 - val_loss: 0.1304 - val_accuracy: 0.9492\n",
      "Epoch 1768/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.2465 - accuracy: 0.8535 - val_loss: 0.1329 - val_accuracy: 0.9492\n",
      "Epoch 1769/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.2519 - accuracy: 0.8495 - val_loss: 0.1373 - val_accuracy: 0.9492\n",
      "Epoch 1770/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.2380 - accuracy: 0.8634 - val_loss: 0.1286 - val_accuracy: 0.9492\n",
      "Epoch 1771/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.2575 - accuracy: 0.8475 - val_loss: 0.1553 - val_accuracy: 0.9492\n",
      "Epoch 1772/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2496 - accuracy: 0.8416 - val_loss: 0.1341 - val_accuracy: 0.9492\n",
      "Epoch 1773/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.2548 - accuracy: 0.8436 - val_loss: 0.1325 - val_accuracy: 0.9492\n",
      "Epoch 1774/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.2477 - accuracy: 0.8475 - val_loss: 0.1288 - val_accuracy: 0.9492\n",
      "Epoch 1775/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.2521 - accuracy: 0.8455 - val_loss: 0.1301 - val_accuracy: 0.9492\n",
      "Epoch 1776/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.2463 - accuracy: 0.8475 - val_loss: 0.1298 - val_accuracy: 0.9492\n",
      "Epoch 1777/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.2452 - accuracy: 0.8634 - val_loss: 0.1353 - val_accuracy: 0.9492\n",
      "Epoch 1778/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2460 - accuracy: 0.8614 - val_loss: 0.1327 - val_accuracy: 0.9492\n",
      "Epoch 1779/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.2428 - accuracy: 0.8535 - val_loss: 0.1289 - val_accuracy: 0.9492\n",
      "Epoch 1780/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.2516 - accuracy: 0.8356 - val_loss: 0.1283 - val_accuracy: 0.9492\n",
      "Epoch 1781/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.2357 - accuracy: 0.8733 - val_loss: 0.1461 - val_accuracy: 0.9492\n",
      "Epoch 1782/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2519 - accuracy: 0.8634 - val_loss: 0.1264 - val_accuracy: 0.9492\n",
      "Epoch 1783/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.2444 - accuracy: 0.8475 - val_loss: 0.1262 - val_accuracy: 0.9492\n",
      "Epoch 1784/2000\n",
      "505/505 [==============================] - 0s 369us/step - loss: 0.2525 - accuracy: 0.8337 - val_loss: 0.1281 - val_accuracy: 0.9492\n",
      "Epoch 1785/2000\n",
      "505/505 [==============================] - 0s 385us/step - loss: 0.2510 - accuracy: 0.8614 - val_loss: 0.1344 - val_accuracy: 0.9492\n",
      "Epoch 1786/2000\n",
      "505/505 [==============================] - 0s 381us/step - loss: 0.2475 - accuracy: 0.8455 - val_loss: 0.1318 - val_accuracy: 0.9322\n",
      "Epoch 1787/2000\n",
      "505/505 [==============================] - 0s 369us/step - loss: 0.2464 - accuracy: 0.8574 - val_loss: 0.1311 - val_accuracy: 0.9492\n",
      "Epoch 1788/2000\n",
      "505/505 [==============================] - 0s 369us/step - loss: 0.2453 - accuracy: 0.8574 - val_loss: 0.1276 - val_accuracy: 0.9492\n",
      "Epoch 1789/2000\n",
      "505/505 [==============================] - 0s 367us/step - loss: 0.2468 - accuracy: 0.8495 - val_loss: 0.1301 - val_accuracy: 0.9492\n",
      "Epoch 1790/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.2534 - accuracy: 0.8436 - val_loss: 0.1287 - val_accuracy: 0.9492\n",
      "Epoch 1791/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.2421 - accuracy: 0.8653 - val_loss: 0.1300 - val_accuracy: 0.9492\n",
      "Epoch 1792/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.2500 - accuracy: 0.8614 - val_loss: 0.1277 - val_accuracy: 0.9492\n",
      "Epoch 1793/2000\n",
      "505/505 [==============================] - 0s 383us/step - loss: 0.2443 - accuracy: 0.8634 - val_loss: 0.1367 - val_accuracy: 0.8983\n",
      "Epoch 1794/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.2533 - accuracy: 0.8356 - val_loss: 0.1282 - val_accuracy: 0.9492\n",
      "Epoch 1795/2000\n",
      "505/505 [==============================] - 0s 367us/step - loss: 0.2451 - accuracy: 0.8475 - val_loss: 0.1287 - val_accuracy: 0.9492\n",
      "Epoch 1796/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.2446 - accuracy: 0.8515 - val_loss: 0.1318 - val_accuracy: 0.9492\n",
      "Epoch 1797/2000\n",
      "505/505 [==============================] - 0s 367us/step - loss: 0.2385 - accuracy: 0.8614 - val_loss: 0.1287 - val_accuracy: 0.9492\n",
      "Epoch 1798/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2497 - accuracy: 0.8376 - val_loss: 0.1264 - val_accuracy: 0.9492\n",
      "Epoch 1799/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2574 - accuracy: 0.8475 - val_loss: 0.1343 - val_accuracy: 0.9322\n",
      "Epoch 1800/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.2502 - accuracy: 0.8475 - val_loss: 0.1265 - val_accuracy: 0.9492\n",
      "Epoch 1801/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.2533 - accuracy: 0.8535 - val_loss: 0.1300 - val_accuracy: 0.9492\n",
      "Epoch 1802/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2462 - accuracy: 0.8554 - val_loss: 0.1334 - val_accuracy: 0.9492\n",
      "Epoch 1803/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.2525 - accuracy: 0.8495 - val_loss: 0.1298 - val_accuracy: 0.9492\n",
      "Epoch 1804/2000\n",
      "505/505 [==============================] - 0s 343us/step - loss: 0.2554 - accuracy: 0.8396 - val_loss: 0.1301 - val_accuracy: 0.9492\n",
      "Epoch 1805/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2501 - accuracy: 0.8455 - val_loss: 0.1277 - val_accuracy: 0.9492\n",
      "Epoch 1806/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.2539 - accuracy: 0.8495 - val_loss: 0.1281 - val_accuracy: 0.9492\n",
      "Epoch 1807/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.2461 - accuracy: 0.8634 - val_loss: 0.1301 - val_accuracy: 0.9492\n",
      "Epoch 1808/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.2463 - accuracy: 0.8495 - val_loss: 0.1275 - val_accuracy: 0.9492\n",
      "Epoch 1809/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.2447 - accuracy: 0.8554 - val_loss: 0.1317 - val_accuracy: 0.9322\n",
      "Epoch 1810/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.2401 - accuracy: 0.8713 - val_loss: 0.1285 - val_accuracy: 0.9492\n",
      "Epoch 1811/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2481 - accuracy: 0.8614 - val_loss: 0.1257 - val_accuracy: 0.9492\n",
      "Epoch 1812/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.2508 - accuracy: 0.8396 - val_loss: 0.1265 - val_accuracy: 0.9492\n",
      "Epoch 1813/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2486 - accuracy: 0.8535 - val_loss: 0.1263 - val_accuracy: 0.9492\n",
      "Epoch 1814/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2455 - accuracy: 0.8653 - val_loss: 0.1287 - val_accuracy: 0.9492\n",
      "Epoch 1815/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.2525 - accuracy: 0.8416 - val_loss: 0.1299 - val_accuracy: 0.9492\n",
      "Epoch 1816/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.2498 - accuracy: 0.8495 - val_loss: 0.1271 - val_accuracy: 0.9492\n",
      "Epoch 1817/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 359us/step - loss: 0.2536 - accuracy: 0.8396 - val_loss: 0.1296 - val_accuracy: 0.9492\n",
      "Epoch 1818/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.2510 - accuracy: 0.8396 - val_loss: 0.1276 - val_accuracy: 0.9492\n",
      "Epoch 1819/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.2577 - accuracy: 0.8337 - val_loss: 0.1349 - val_accuracy: 0.9492\n",
      "Epoch 1820/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2481 - accuracy: 0.8614 - val_loss: 0.1336 - val_accuracy: 0.9492\n",
      "Epoch 1821/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.2480 - accuracy: 0.8574 - val_loss: 0.1254 - val_accuracy: 0.9492\n",
      "Epoch 1822/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.2525 - accuracy: 0.8416 - val_loss: 0.1249 - val_accuracy: 0.9492\n",
      "Epoch 1823/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2464 - accuracy: 0.8574 - val_loss: 0.1257 - val_accuracy: 0.9492\n",
      "Epoch 1824/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2443 - accuracy: 0.8634 - val_loss: 0.1251 - val_accuracy: 0.9492\n",
      "Epoch 1825/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2452 - accuracy: 0.8554 - val_loss: 0.1279 - val_accuracy: 0.9492\n",
      "Epoch 1826/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2498 - accuracy: 0.8416 - val_loss: 0.1244 - val_accuracy: 0.9492\n",
      "Epoch 1827/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2531 - accuracy: 0.8416 - val_loss: 0.1287 - val_accuracy: 0.9492\n",
      "Epoch 1828/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2399 - accuracy: 0.8535 - val_loss: 0.1292 - val_accuracy: 0.9492\n",
      "Epoch 1829/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2424 - accuracy: 0.8554 - val_loss: 0.1247 - val_accuracy: 0.9492\n",
      "Epoch 1830/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2524 - accuracy: 0.8337 - val_loss: 0.1239 - val_accuracy: 0.9492\n",
      "Epoch 1831/2000\n",
      "505/505 [==============================] - 0s 377us/step - loss: 0.2454 - accuracy: 0.8475 - val_loss: 0.1250 - val_accuracy: 0.9492\n",
      "Epoch 1832/2000\n",
      "505/505 [==============================] - 0s 381us/step - loss: 0.2370 - accuracy: 0.8673 - val_loss: 0.1250 - val_accuracy: 0.9492\n",
      "Epoch 1833/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.2545 - accuracy: 0.8475 - val_loss: 0.1253 - val_accuracy: 0.9492\n",
      "Epoch 1834/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2440 - accuracy: 0.8515 - val_loss: 0.1233 - val_accuracy: 0.9492\n",
      "Epoch 1835/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2471 - accuracy: 0.8594 - val_loss: 0.1283 - val_accuracy: 0.9492\n",
      "Epoch 1836/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.2368 - accuracy: 0.8673 - val_loss: 0.1230 - val_accuracy: 0.9492\n",
      "Epoch 1837/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.2438 - accuracy: 0.8475 - val_loss: 0.1242 - val_accuracy: 0.9492\n",
      "Epoch 1838/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.2445 - accuracy: 0.8535 - val_loss: 0.1275 - val_accuracy: 0.9492\n",
      "Epoch 1839/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.2492 - accuracy: 0.8495 - val_loss: 0.1239 - val_accuracy: 0.9492\n",
      "Epoch 1840/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.2471 - accuracy: 0.8554 - val_loss: 0.1320 - val_accuracy: 0.9492\n",
      "Epoch 1841/2000\n",
      "505/505 [==============================] - 0s 352us/step - loss: 0.2456 - accuracy: 0.8475 - val_loss: 0.1246 - val_accuracy: 0.9492\n",
      "Epoch 1842/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.2487 - accuracy: 0.8455 - val_loss: 0.1235 - val_accuracy: 0.9492\n",
      "Epoch 1843/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.2490 - accuracy: 0.8475 - val_loss: 0.1250 - val_accuracy: 0.9492\n",
      "Epoch 1844/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.2497 - accuracy: 0.8554 - val_loss: 0.1230 - val_accuracy: 0.9492\n",
      "Epoch 1845/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.2573 - accuracy: 0.8356 - val_loss: 0.1228 - val_accuracy: 0.9492\n",
      "Epoch 1846/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2368 - accuracy: 0.8713 - val_loss: 0.1250 - val_accuracy: 0.9492\n",
      "Epoch 1847/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2517 - accuracy: 0.8455 - val_loss: 0.1269 - val_accuracy: 0.9492\n",
      "Epoch 1848/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2523 - accuracy: 0.8416 - val_loss: 0.1276 - val_accuracy: 0.9492\n",
      "Epoch 1849/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2386 - accuracy: 0.8832 - val_loss: 0.1234 - val_accuracy: 0.9492\n",
      "Epoch 1850/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.2513 - accuracy: 0.8396 - val_loss: 0.1238 - val_accuracy: 0.9492\n",
      "Epoch 1851/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2413 - accuracy: 0.8594 - val_loss: 0.1232 - val_accuracy: 0.9492\n",
      "Epoch 1852/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2426 - accuracy: 0.8574 - val_loss: 0.1233 - val_accuracy: 0.9492\n",
      "Epoch 1853/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2576 - accuracy: 0.8396 - val_loss: 0.1268 - val_accuracy: 0.9492\n",
      "Epoch 1854/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2454 - accuracy: 0.8475 - val_loss: 0.1375 - val_accuracy: 0.9492\n",
      "Epoch 1855/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.2436 - accuracy: 0.8653 - val_loss: 0.1229 - val_accuracy: 0.9492\n",
      "Epoch 1856/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2511 - accuracy: 0.8475 - val_loss: 0.1230 - val_accuracy: 0.9492\n",
      "Epoch 1857/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2492 - accuracy: 0.8515 - val_loss: 0.1224 - val_accuracy: 0.9492\n",
      "Epoch 1858/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2490 - accuracy: 0.8396 - val_loss: 0.1239 - val_accuracy: 0.9492\n",
      "Epoch 1859/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2431 - accuracy: 0.8475 - val_loss: 0.1223 - val_accuracy: 0.9492\n",
      "Epoch 1860/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2449 - accuracy: 0.8673 - val_loss: 0.1262 - val_accuracy: 0.9492\n",
      "Epoch 1861/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.2479 - accuracy: 0.8554 - val_loss: 0.1250 - val_accuracy: 0.9492\n",
      "Epoch 1862/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2535 - accuracy: 0.8455 - val_loss: 0.1223 - val_accuracy: 0.9492\n",
      "Epoch 1863/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2455 - accuracy: 0.8495 - val_loss: 0.1234 - val_accuracy: 0.9492\n",
      "Epoch 1864/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2479 - accuracy: 0.8554 - val_loss: 0.1227 - val_accuracy: 0.9492\n",
      "Epoch 1865/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.2463 - accuracy: 0.8653 - val_loss: 0.1209 - val_accuracy: 0.9492\n",
      "Epoch 1866/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.2381 - accuracy: 0.8614 - val_loss: 0.1248 - val_accuracy: 0.9492\n",
      "Epoch 1867/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.2530 - accuracy: 0.8495 - val_loss: 0.1241 - val_accuracy: 0.9492\n",
      "Epoch 1868/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2510 - accuracy: 0.8535 - val_loss: 0.1225 - val_accuracy: 0.9492\n",
      "Epoch 1869/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.2456 - accuracy: 0.8594 - val_loss: 0.1235 - val_accuracy: 0.9492\n",
      "Epoch 1870/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.2430 - accuracy: 0.8634 - val_loss: 0.1254 - val_accuracy: 0.9492\n",
      "Epoch 1871/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2466 - accuracy: 0.8634 - val_loss: 0.1226 - val_accuracy: 0.9492\n",
      "Epoch 1872/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 344us/step - loss: 0.2470 - accuracy: 0.8475 - val_loss: 0.1237 - val_accuracy: 0.9492\n",
      "Epoch 1873/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.2487 - accuracy: 0.8535 - val_loss: 0.1282 - val_accuracy: 0.9492\n",
      "Epoch 1874/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2472 - accuracy: 0.8436 - val_loss: 0.1262 - val_accuracy: 0.9492\n",
      "Epoch 1875/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.2488 - accuracy: 0.8535 - val_loss: 0.1247 - val_accuracy: 0.9492\n",
      "Epoch 1876/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.2485 - accuracy: 0.8356 - val_loss: 0.1221 - val_accuracy: 0.9492\n",
      "Epoch 1877/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.2526 - accuracy: 0.8495 - val_loss: 0.1244 - val_accuracy: 0.9492\n",
      "Epoch 1878/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.2468 - accuracy: 0.8515 - val_loss: 0.1236 - val_accuracy: 0.9492\n",
      "Epoch 1879/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.2529 - accuracy: 0.8416 - val_loss: 0.1219 - val_accuracy: 0.9492\n",
      "Epoch 1880/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2433 - accuracy: 0.8495 - val_loss: 0.1274 - val_accuracy: 0.9492\n",
      "Epoch 1881/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.2521 - accuracy: 0.8475 - val_loss: 0.1245 - val_accuracy: 0.9492\n",
      "Epoch 1882/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.2460 - accuracy: 0.8376 - val_loss: 0.1283 - val_accuracy: 0.9492\n",
      "Epoch 1883/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.2500 - accuracy: 0.8475 - val_loss: 0.1277 - val_accuracy: 0.9492\n",
      "Epoch 1884/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2468 - accuracy: 0.8614 - val_loss: 0.1240 - val_accuracy: 0.9492\n",
      "Epoch 1885/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.2495 - accuracy: 0.8436 - val_loss: 0.1245 - val_accuracy: 0.9492\n",
      "Epoch 1886/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.2465 - accuracy: 0.8436 - val_loss: 0.1238 - val_accuracy: 0.9492\n",
      "Epoch 1887/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.2457 - accuracy: 0.8594 - val_loss: 0.1245 - val_accuracy: 0.9492\n",
      "Epoch 1888/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.2506 - accuracy: 0.8257 - val_loss: 0.1241 - val_accuracy: 0.9492\n",
      "Epoch 1889/2000\n",
      "505/505 [==============================] - 0s 361us/step - loss: 0.2469 - accuracy: 0.8455 - val_loss: 0.1264 - val_accuracy: 0.9492\n",
      "Epoch 1890/2000\n",
      "505/505 [==============================] - 0s 357us/step - loss: 0.2501 - accuracy: 0.8455 - val_loss: 0.1293 - val_accuracy: 0.9492\n",
      "Epoch 1891/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.2506 - accuracy: 0.8475 - val_loss: 0.1239 - val_accuracy: 0.9492\n",
      "Epoch 1892/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2400 - accuracy: 0.8574 - val_loss: 0.1277 - val_accuracy: 0.9492\n",
      "Epoch 1893/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2456 - accuracy: 0.8416 - val_loss: 0.1234 - val_accuracy: 0.9492\n",
      "Epoch 1894/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.2495 - accuracy: 0.8436 - val_loss: 0.1247 - val_accuracy: 0.9492\n",
      "Epoch 1895/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.2485 - accuracy: 0.8436 - val_loss: 0.1255 - val_accuracy: 0.9492\n",
      "Epoch 1896/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2528 - accuracy: 0.8416 - val_loss: 0.1279 - val_accuracy: 0.9492\n",
      "Epoch 1897/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2452 - accuracy: 0.8495 - val_loss: 0.1244 - val_accuracy: 0.9492\n",
      "Epoch 1898/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.2446 - accuracy: 0.8614 - val_loss: 0.1199 - val_accuracy: 0.9492\n",
      "Epoch 1899/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.2517 - accuracy: 0.8574 - val_loss: 0.1242 - val_accuracy: 0.9492\n",
      "Epoch 1900/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2592 - accuracy: 0.8297 - val_loss: 0.1223 - val_accuracy: 0.9492\n",
      "Epoch 1901/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2455 - accuracy: 0.8574 - val_loss: 0.1226 - val_accuracy: 0.9492\n",
      "Epoch 1902/2000\n",
      "505/505 [==============================] - 0s 355us/step - loss: 0.2510 - accuracy: 0.8396 - val_loss: 0.1255 - val_accuracy: 0.9492\n",
      "Epoch 1903/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.2485 - accuracy: 0.8554 - val_loss: 0.1249 - val_accuracy: 0.9492\n",
      "Epoch 1904/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2473 - accuracy: 0.8495 - val_loss: 0.1248 - val_accuracy: 0.9492\n",
      "Epoch 1905/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2493 - accuracy: 0.8594 - val_loss: 0.1245 - val_accuracy: 0.9492\n",
      "Epoch 1906/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2431 - accuracy: 0.8554 - val_loss: 0.1267 - val_accuracy: 0.9492\n",
      "Epoch 1907/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.2405 - accuracy: 0.8495 - val_loss: 0.1243 - val_accuracy: 0.9492\n",
      "Epoch 1908/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2544 - accuracy: 0.8356 - val_loss: 0.1228 - val_accuracy: 0.9492\n",
      "Epoch 1909/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2553 - accuracy: 0.8396 - val_loss: 0.1232 - val_accuracy: 0.9492\n",
      "Epoch 1910/2000\n",
      "505/505 [==============================] - 0s 369us/step - loss: 0.2439 - accuracy: 0.8554 - val_loss: 0.1239 - val_accuracy: 0.9492\n",
      "Epoch 1911/2000\n",
      "505/505 [==============================] - 0s 417us/step - loss: 0.2483 - accuracy: 0.8515 - val_loss: 0.1241 - val_accuracy: 0.9492\n",
      "Epoch 1912/2000\n",
      "505/505 [==============================] - 0s 365us/step - loss: 0.2527 - accuracy: 0.8436 - val_loss: 0.1236 - val_accuracy: 0.9492\n",
      "Epoch 1913/2000\n",
      "505/505 [==============================] - 0s 354us/step - loss: 0.2573 - accuracy: 0.8436 - val_loss: 0.1222 - val_accuracy: 0.9492\n",
      "Epoch 1914/2000\n",
      "505/505 [==============================] - 0s 324us/step - loss: 0.2547 - accuracy: 0.8515 - val_loss: 0.1209 - val_accuracy: 0.9492\n",
      "Epoch 1915/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.2537 - accuracy: 0.8416 - val_loss: 0.1226 - val_accuracy: 0.9492\n",
      "Epoch 1916/2000\n",
      "505/505 [==============================] - 0s 320us/step - loss: 0.2453 - accuracy: 0.8574 - val_loss: 0.1236 - val_accuracy: 0.9492\n",
      "Epoch 1917/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2479 - accuracy: 0.8495 - val_loss: 0.1242 - val_accuracy: 0.9492\n",
      "Epoch 1918/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.2536 - accuracy: 0.8535 - val_loss: 0.1261 - val_accuracy: 0.9492\n",
      "Epoch 1919/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.2536 - accuracy: 0.8376 - val_loss: 0.1207 - val_accuracy: 0.9492\n",
      "Epoch 1920/2000\n",
      "505/505 [==============================] - 0s 321us/step - loss: 0.2422 - accuracy: 0.8614 - val_loss: 0.1198 - val_accuracy: 0.9492\n",
      "Epoch 1921/2000\n",
      "505/505 [==============================] - 0s 317us/step - loss: 0.2442 - accuracy: 0.8574 - val_loss: 0.1218 - val_accuracy: 0.9492\n",
      "Epoch 1922/2000\n",
      "505/505 [==============================] - 0s 324us/step - loss: 0.2504 - accuracy: 0.8574 - val_loss: 0.1214 - val_accuracy: 0.9492\n",
      "Epoch 1923/2000\n",
      "505/505 [==============================] - 0s 318us/step - loss: 0.2468 - accuracy: 0.8416 - val_loss: 0.1212 - val_accuracy: 0.9492\n",
      "Epoch 1924/2000\n",
      "505/505 [==============================] - 0s 318us/step - loss: 0.2446 - accuracy: 0.8495 - val_loss: 0.1215 - val_accuracy: 0.9492\n",
      "Epoch 1925/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.2358 - accuracy: 0.8713 - val_loss: 0.1218 - val_accuracy: 0.9492\n",
      "Epoch 1926/2000\n",
      "505/505 [==============================] - 0s 322us/step - loss: 0.2498 - accuracy: 0.8455 - val_loss: 0.1215 - val_accuracy: 0.9492\n",
      "Epoch 1927/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 320us/step - loss: 0.2488 - accuracy: 0.8535 - val_loss: 0.1232 - val_accuracy: 0.9492\n",
      "Epoch 1928/2000\n",
      "505/505 [==============================] - 0s 322us/step - loss: 0.2434 - accuracy: 0.8653 - val_loss: 0.1221 - val_accuracy: 0.9492\n",
      "Epoch 1929/2000\n",
      "505/505 [==============================] - 0s 318us/step - loss: 0.2445 - accuracy: 0.8396 - val_loss: 0.1211 - val_accuracy: 0.9492\n",
      "Epoch 1930/2000\n",
      "505/505 [==============================] - 0s 322us/step - loss: 0.2440 - accuracy: 0.8535 - val_loss: 0.1226 - val_accuracy: 0.9492\n",
      "Epoch 1931/2000\n",
      "505/505 [==============================] - 0s 318us/step - loss: 0.2541 - accuracy: 0.8475 - val_loss: 0.1218 - val_accuracy: 0.9492\n",
      "Epoch 1932/2000\n",
      "505/505 [==============================] - 0s 316us/step - loss: 0.2435 - accuracy: 0.8594 - val_loss: 0.1212 - val_accuracy: 0.9492\n",
      "Epoch 1933/2000\n",
      "505/505 [==============================] - 0s 316us/step - loss: 0.2413 - accuracy: 0.8554 - val_loss: 0.1244 - val_accuracy: 0.9492\n",
      "Epoch 1934/2000\n",
      "505/505 [==============================] - 0s 314us/step - loss: 0.2457 - accuracy: 0.8535 - val_loss: 0.1199 - val_accuracy: 0.9492\n",
      "Epoch 1935/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2504 - accuracy: 0.8396 - val_loss: 0.1203 - val_accuracy: 0.9492\n",
      "Epoch 1936/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2530 - accuracy: 0.8356 - val_loss: 0.1192 - val_accuracy: 0.9492\n",
      "Epoch 1937/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2410 - accuracy: 0.8535 - val_loss: 0.1209 - val_accuracy: 0.9492\n",
      "Epoch 1938/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2444 - accuracy: 0.8535 - val_loss: 0.1214 - val_accuracy: 0.9492\n",
      "Epoch 1939/2000\n",
      "505/505 [==============================] - 0s 334us/step - loss: 0.2463 - accuracy: 0.8554 - val_loss: 0.1206 - val_accuracy: 0.9492\n",
      "Epoch 1940/2000\n",
      "505/505 [==============================] - 0s 324us/step - loss: 0.2477 - accuracy: 0.8574 - val_loss: 0.1225 - val_accuracy: 0.9492\n",
      "Epoch 1941/2000\n",
      "505/505 [==============================] - 0s 318us/step - loss: 0.2454 - accuracy: 0.8634 - val_loss: 0.1211 - val_accuracy: 0.9492\n",
      "Epoch 1942/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2445 - accuracy: 0.8515 - val_loss: 0.1208 - val_accuracy: 0.9492\n",
      "Epoch 1943/2000\n",
      "505/505 [==============================] - 0s 324us/step - loss: 0.2467 - accuracy: 0.8752 - val_loss: 0.1244 - val_accuracy: 0.9492\n",
      "Epoch 1944/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.2509 - accuracy: 0.8535 - val_loss: 0.1223 - val_accuracy: 0.9492\n",
      "Epoch 1945/2000\n",
      "505/505 [==============================] - 0s 320us/step - loss: 0.2395 - accuracy: 0.8535 - val_loss: 0.1222 - val_accuracy: 0.9492\n",
      "Epoch 1946/2000\n",
      "505/505 [==============================] - 0s 324us/step - loss: 0.2577 - accuracy: 0.8277 - val_loss: 0.1228 - val_accuracy: 0.9492\n",
      "Epoch 1947/2000\n",
      "505/505 [==============================] - 0s 322us/step - loss: 0.2387 - accuracy: 0.8653 - val_loss: 0.1220 - val_accuracy: 0.9492\n",
      "Epoch 1948/2000\n",
      "505/505 [==============================] - 0s 340us/step - loss: 0.2498 - accuracy: 0.8475 - val_loss: 0.1244 - val_accuracy: 0.9492\n",
      "Epoch 1949/2000\n",
      "505/505 [==============================] - 0s 375us/step - loss: 0.2426 - accuracy: 0.8634 - val_loss: 0.1207 - val_accuracy: 0.9492\n",
      "Epoch 1950/2000\n",
      "505/505 [==============================] - 0s 371us/step - loss: 0.2449 - accuracy: 0.8455 - val_loss: 0.1198 - val_accuracy: 0.9492\n",
      "Epoch 1951/2000\n",
      "505/505 [==============================] - 0s 387us/step - loss: 0.2446 - accuracy: 0.8574 - val_loss: 0.1199 - val_accuracy: 0.9492\n",
      "Epoch 1952/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2451 - accuracy: 0.8594 - val_loss: 0.1365 - val_accuracy: 0.9492\n",
      "Epoch 1953/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.2434 - accuracy: 0.8653 - val_loss: 0.1251 - val_accuracy: 0.9492\n",
      "Epoch 1954/2000\n",
      "505/505 [==============================] - 0s 322us/step - loss: 0.2485 - accuracy: 0.8475 - val_loss: 0.1210 - val_accuracy: 0.9492\n",
      "Epoch 1955/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.2425 - accuracy: 0.8634 - val_loss: 0.1263 - val_accuracy: 0.9492\n",
      "Epoch 1956/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2432 - accuracy: 0.8475 - val_loss: 0.1253 - val_accuracy: 0.9492\n",
      "Epoch 1957/2000\n",
      "505/505 [==============================] - 0s 320us/step - loss: 0.2502 - accuracy: 0.8535 - val_loss: 0.1228 - val_accuracy: 0.9492\n",
      "Epoch 1958/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.2481 - accuracy: 0.8475 - val_loss: 0.1213 - val_accuracy: 0.9492\n",
      "Epoch 1959/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2469 - accuracy: 0.8574 - val_loss: 0.1212 - val_accuracy: 0.9492\n",
      "Epoch 1960/2000\n",
      "505/505 [==============================] - 0s 324us/step - loss: 0.2480 - accuracy: 0.8515 - val_loss: 0.1198 - val_accuracy: 0.9492\n",
      "Epoch 1961/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.2566 - accuracy: 0.8356 - val_loss: 0.1259 - val_accuracy: 0.9492\n",
      "Epoch 1962/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.2494 - accuracy: 0.8495 - val_loss: 0.1214 - val_accuracy: 0.9492\n",
      "Epoch 1963/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2522 - accuracy: 0.8376 - val_loss: 0.1232 - val_accuracy: 0.9492\n",
      "Epoch 1964/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2518 - accuracy: 0.8515 - val_loss: 0.1219 - val_accuracy: 0.9492\n",
      "Epoch 1965/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.2457 - accuracy: 0.8317 - val_loss: 0.1239 - val_accuracy: 0.9492\n",
      "Epoch 1966/2000\n",
      "505/505 [==============================] - 0s 322us/step - loss: 0.2471 - accuracy: 0.8554 - val_loss: 0.1207 - val_accuracy: 0.9492\n",
      "Epoch 1967/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2464 - accuracy: 0.8673 - val_loss: 0.1237 - val_accuracy: 0.9492\n",
      "Epoch 1968/2000\n",
      "505/505 [==============================] - 0s 363us/step - loss: 0.2480 - accuracy: 0.8455 - val_loss: 0.1207 - val_accuracy: 0.9492\n",
      "Epoch 1969/2000\n",
      "505/505 [==============================] - 0s 359us/step - loss: 0.2358 - accuracy: 0.8673 - val_loss: 0.1221 - val_accuracy: 0.9492\n",
      "Epoch 1970/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.2507 - accuracy: 0.8455 - val_loss: 0.1194 - val_accuracy: 0.9492\n",
      "Epoch 1971/2000\n",
      "505/505 [==============================] - 0s 324us/step - loss: 0.2414 - accuracy: 0.8634 - val_loss: 0.1209 - val_accuracy: 0.9492\n",
      "Epoch 1972/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2520 - accuracy: 0.8535 - val_loss: 0.1245 - val_accuracy: 0.9492\n",
      "Epoch 1973/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2467 - accuracy: 0.8475 - val_loss: 0.1218 - val_accuracy: 0.9492\n",
      "Epoch 1974/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.2472 - accuracy: 0.8475 - val_loss: 0.1228 - val_accuracy: 0.9492\n",
      "Epoch 1975/2000\n",
      "505/505 [==============================] - 0s 330us/step - loss: 0.2508 - accuracy: 0.8455 - val_loss: 0.1208 - val_accuracy: 0.9492\n",
      "Epoch 1976/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.2469 - accuracy: 0.8535 - val_loss: 0.1212 - val_accuracy: 0.9492\n",
      "Epoch 1977/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.2482 - accuracy: 0.8535 - val_loss: 0.1214 - val_accuracy: 0.9492\n",
      "Epoch 1978/2000\n",
      "505/505 [==============================] - 0s 326us/step - loss: 0.2500 - accuracy: 0.8475 - val_loss: 0.1231 - val_accuracy: 0.9492\n",
      "Epoch 1979/2000\n",
      "505/505 [==============================] - 0s 324us/step - loss: 0.2513 - accuracy: 0.8376 - val_loss: 0.1215 - val_accuracy: 0.9492\n",
      "Epoch 1980/2000\n",
      "505/505 [==============================] - 0s 324us/step - loss: 0.2498 - accuracy: 0.8317 - val_loss: 0.1216 - val_accuracy: 0.9492\n",
      "Epoch 1981/2000\n",
      "505/505 [==============================] - 0s 348us/step - loss: 0.2502 - accuracy: 0.8455 - val_loss: 0.1214 - val_accuracy: 0.9492\n",
      "Epoch 1982/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 363us/step - loss: 0.2529 - accuracy: 0.8416 - val_loss: 0.1236 - val_accuracy: 0.9492\n",
      "Epoch 1983/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.2554 - accuracy: 0.8436 - val_loss: 0.1205 - val_accuracy: 0.9492\n",
      "Epoch 1984/2000\n",
      "505/505 [==============================] - 0s 324us/step - loss: 0.2505 - accuracy: 0.8455 - val_loss: 0.1201 - val_accuracy: 0.9492\n",
      "Epoch 1985/2000\n",
      "505/505 [==============================] - 0s 324us/step - loss: 0.2452 - accuracy: 0.8436 - val_loss: 0.1205 - val_accuracy: 0.9492\n",
      "Epoch 1986/2000\n",
      "505/505 [==============================] - 0s 324us/step - loss: 0.2475 - accuracy: 0.8495 - val_loss: 0.1210 - val_accuracy: 0.9492\n",
      "Epoch 1987/2000\n",
      "505/505 [==============================] - 0s 367us/step - loss: 0.2466 - accuracy: 0.8455 - val_loss: 0.1209 - val_accuracy: 0.9492\n",
      "Epoch 1988/2000\n",
      "505/505 [==============================] - 0s 350us/step - loss: 0.2497 - accuracy: 0.8535 - val_loss: 0.1240 - val_accuracy: 0.9492\n",
      "Epoch 1989/2000\n",
      "505/505 [==============================] - 0s 342us/step - loss: 0.2450 - accuracy: 0.8614 - val_loss: 0.1228 - val_accuracy: 0.9492\n",
      "Epoch 1990/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2433 - accuracy: 0.8554 - val_loss: 0.1230 - val_accuracy: 0.9492\n",
      "Epoch 1991/2000\n",
      "505/505 [==============================] - 0s 346us/step - loss: 0.2467 - accuracy: 0.8535 - val_loss: 0.1209 - val_accuracy: 0.9492\n",
      "Epoch 1992/2000\n",
      "505/505 [==============================] - 0s 344us/step - loss: 0.2533 - accuracy: 0.8455 - val_loss: 0.1215 - val_accuracy: 0.9492\n",
      "Epoch 1993/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2431 - accuracy: 0.8574 - val_loss: 0.1215 - val_accuracy: 0.9492\n",
      "Epoch 1994/2000\n",
      "505/505 [==============================] - 0s 328us/step - loss: 0.2461 - accuracy: 0.8455 - val_loss: 0.1253 - val_accuracy: 0.9492\n",
      "Epoch 1995/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2480 - accuracy: 0.8495 - val_loss: 0.1240 - val_accuracy: 0.9492\n",
      "Epoch 1996/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2437 - accuracy: 0.8535 - val_loss: 0.1212 - val_accuracy: 0.9492\n",
      "Epoch 1997/2000\n",
      "505/505 [==============================] - 0s 338us/step - loss: 0.2422 - accuracy: 0.8733 - val_loss: 0.1202 - val_accuracy: 0.9492\n",
      "Epoch 1998/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2541 - accuracy: 0.8436 - val_loss: 0.1198 - val_accuracy: 0.9492\n",
      "Epoch 1999/2000\n",
      "505/505 [==============================] - 0s 332us/step - loss: 0.2506 - accuracy: 0.8634 - val_loss: 0.1298 - val_accuracy: 0.9492\n",
      "Epoch 2000/2000\n",
      "505/505 [==============================] - 0s 336us/step - loss: 0.2442 - accuracy: 0.8376 - val_loss: 0.1263 - val_accuracy: 0.9492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Dropout, Activation, MaxPooling1D\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, label, test_size=0.2)\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.model_selection import learning_curve\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# mlps = []\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=(1000,200), max_iter=2000, alpha=1e-4,\n",
    "#                     solver='sgd', verbose=100,\n",
    "#                     learning_rate_init=0.01, n_iter_no_change=1000)\n",
    "\n",
    "# mlp.fit(x_train, y_train)\n",
    "# mlp.score(x_test, y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_dim=2000))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(256, activation='relu'))\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "sgd = SGD()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "his = model.fit(x=x_train, y=y_train, batch_size=32, epochs=2000, shuffle=True, verbose=1, \n",
    "               validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(his.history['accuracy'])\n",
    "plt.plot(his.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 绘制训练 & 验证的损失值\n",
    "plt.plot(his.history['loss'])\n",
    "plt.plot(his.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
